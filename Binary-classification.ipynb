{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symptom1</th>\n",
       "      <th>symptom2</th>\n",
       "      <th>symptom3</th>\n",
       "      <th>symptom4</th>\n",
       "      <th>symptom5</th>\n",
       "      <th>symptom6</th>\n",
       "      <th>symptom7</th>\n",
       "      <th>symptom8</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symptom1  symptom2  symptom3  symptom4  symptom5  symptom6  symptom7  \\\n",
       "0       6.0     148.0      72.0      35.0       0.0      33.6     0.627   \n",
       "1       1.0      85.0      66.0      29.0       0.0      26.6     0.351   \n",
       "2       8.0     183.0      64.0       0.0       0.0      23.3     0.672   \n",
       "3       1.0      89.0      66.0      23.0      94.0      28.1     0.167   \n",
       "4       0.0     137.0      40.0      35.0     168.0      43.1     2.288   \n",
       "\n",
       "   symptom8  results  \n",
       "0      50.0      1.0  \n",
       "1      31.0      0.0  \n",
       "2      32.0      1.0  \n",
       "3      21.0      0.0  \n",
       "4      33.0      1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#read dataset\n",
    "df = pd.read_csv('sample_disease_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#min-max normalization \n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into input (X) and output (y) variables\n",
    "X = x_scaled[:,0:8]\n",
    "y = x_scaled[:,8]\n",
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size=0.2, random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing library \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.plot_model(model, to_file='model.jpg',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 392 samples, validate on 98 samples\n",
      "Epoch 1/1500\n",
      "392/392 [==============================] - 0s 512us/step - loss: 0.7140 - acc: 0.6633 - val_loss: 0.7224 - val_acc: 0.6327\n",
      "Epoch 2/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.7117 - acc: 0.6633 - val_loss: 0.7201 - val_acc: 0.6327\n",
      "Epoch 3/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.7097 - acc: 0.6633 - val_loss: 0.7179 - val_acc: 0.6327\n",
      "Epoch 4/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.7075 - acc: 0.6633 - val_loss: 0.7162 - val_acc: 0.6327\n",
      "Epoch 5/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.7062 - acc: 0.6633 - val_loss: 0.7149 - val_acc: 0.6327\n",
      "Epoch 6/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.7051 - acc: 0.6633 - val_loss: 0.7139 - val_acc: 0.6327\n",
      "Epoch 7/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.7041 - acc: 0.6633 - val_loss: 0.7126 - val_acc: 0.6327\n",
      "Epoch 8/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.7029 - acc: 0.6633 - val_loss: 0.7113 - val_acc: 0.6327\n",
      "Epoch 9/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.7018 - acc: 0.6633 - val_loss: 0.7101 - val_acc: 0.6327\n",
      "Epoch 10/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.7005 - acc: 0.6633 - val_loss: 0.7090 - val_acc: 0.6327\n",
      "Epoch 11/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6996 - acc: 0.6633 - val_loss: 0.7080 - val_acc: 0.6327\n",
      "Epoch 12/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6987 - acc: 0.6658 - val_loss: 0.7068 - val_acc: 0.6429\n",
      "Epoch 13/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6976 - acc: 0.6658 - val_loss: 0.7057 - val_acc: 0.6429\n",
      "Epoch 14/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6966 - acc: 0.6658 - val_loss: 0.7047 - val_acc: 0.6429\n",
      "Epoch 15/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6956 - acc: 0.6658 - val_loss: 0.7036 - val_acc: 0.6429\n",
      "Epoch 16/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6946 - acc: 0.6658 - val_loss: 0.7027 - val_acc: 0.6429\n",
      "Epoch 17/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6939 - acc: 0.6684 - val_loss: 0.7017 - val_acc: 0.6429\n",
      "Epoch 18/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6929 - acc: 0.6709 - val_loss: 0.7009 - val_acc: 0.6429\n",
      "Epoch 19/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6920 - acc: 0.6709 - val_loss: 0.7000 - val_acc: 0.6429\n",
      "Epoch 20/1500\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.6913 - acc: 0.6709 - val_loss: 0.6990 - val_acc: 0.6429\n",
      "Epoch 21/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6904 - acc: 0.6684 - val_loss: 0.6982 - val_acc: 0.6429\n",
      "Epoch 22/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6898 - acc: 0.6709 - val_loss: 0.6974 - val_acc: 0.6429\n",
      "Epoch 23/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6891 - acc: 0.6709 - val_loss: 0.6964 - val_acc: 0.6429\n",
      "Epoch 24/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6884 - acc: 0.6709 - val_loss: 0.6956 - val_acc: 0.6429\n",
      "Epoch 25/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6876 - acc: 0.6684 - val_loss: 0.6947 - val_acc: 0.6429\n",
      "Epoch 26/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6870 - acc: 0.6709 - val_loss: 0.6938 - val_acc: 0.6429\n",
      "Epoch 27/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6864 - acc: 0.6709 - val_loss: 0.6929 - val_acc: 0.6429\n",
      "Epoch 28/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6858 - acc: 0.6709 - val_loss: 0.6920 - val_acc: 0.6429\n",
      "Epoch 29/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6852 - acc: 0.6709 - val_loss: 0.6912 - val_acc: 0.6429\n",
      "Epoch 30/1500\n",
      "392/392 [==============================] - 0s 22us/step - loss: 0.6845 - acc: 0.6709 - val_loss: 0.6904 - val_acc: 0.6429\n",
      "Epoch 31/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6839 - acc: 0.6709 - val_loss: 0.6896 - val_acc: 0.6429\n",
      "Epoch 32/1500\n",
      "392/392 [==============================] - 0s 22us/step - loss: 0.6834 - acc: 0.6709 - val_loss: 0.6889 - val_acc: 0.6429\n",
      "Epoch 33/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6828 - acc: 0.6709 - val_loss: 0.6882 - val_acc: 0.6429\n",
      "Epoch 34/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6823 - acc: 0.6709 - val_loss: 0.6875 - val_acc: 0.6429\n",
      "Epoch 35/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6818 - acc: 0.6709 - val_loss: 0.6869 - val_acc: 0.6429\n",
      "Epoch 36/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6814 - acc: 0.6709 - val_loss: 0.6862 - val_acc: 0.6429\n",
      "Epoch 37/1500\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.6810 - acc: 0.6709 - val_loss: 0.6856 - val_acc: 0.6429\n",
      "Epoch 38/1500\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6805 - acc: 0.6709 - val_loss: 0.6850 - val_acc: 0.6429\n",
      "Epoch 39/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6801 - acc: 0.6709 - val_loss: 0.6846 - val_acc: 0.6429\n",
      "Epoch 40/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6798 - acc: 0.6709 - val_loss: 0.6839 - val_acc: 0.6429\n",
      "Epoch 41/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6794 - acc: 0.6684 - val_loss: 0.6833 - val_acc: 0.6429\n",
      "Epoch 42/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6791 - acc: 0.6684 - val_loss: 0.6828 - val_acc: 0.6429\n",
      "Epoch 43/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6788 - acc: 0.6684 - val_loss: 0.6824 - val_acc: 0.6429\n",
      "Epoch 44/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6785 - acc: 0.6684 - val_loss: 0.6820 - val_acc: 0.6429\n",
      "Epoch 45/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6782 - acc: 0.6684 - val_loss: 0.6814 - val_acc: 0.6429\n",
      "Epoch 46/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6778 - acc: 0.6684 - val_loss: 0.6806 - val_acc: 0.6429\n",
      "Epoch 47/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6773 - acc: 0.6684 - val_loss: 0.6800 - val_acc: 0.6429\n",
      "Epoch 48/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6770 - acc: 0.6684 - val_loss: 0.6795 - val_acc: 0.6429\n",
      "Epoch 49/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6766 - acc: 0.6684 - val_loss: 0.6790 - val_acc: 0.6429\n",
      "Epoch 50/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6763 - acc: 0.6684 - val_loss: 0.6787 - val_acc: 0.6429\n",
      "Epoch 51/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6760 - acc: 0.6684 - val_loss: 0.6782 - val_acc: 0.6429\n",
      "Epoch 52/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6756 - acc: 0.6684 - val_loss: 0.6779 - val_acc: 0.6429\n",
      "Epoch 53/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6753 - acc: 0.6684 - val_loss: 0.6775 - val_acc: 0.6429\n",
      "Epoch 54/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 18us/step - loss: 0.6751 - acc: 0.6684 - val_loss: 0.6771 - val_acc: 0.6429\n",
      "Epoch 55/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6749 - acc: 0.6684 - val_loss: 0.6766 - val_acc: 0.6429\n",
      "Epoch 56/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6745 - acc: 0.6684 - val_loss: 0.6762 - val_acc: 0.6429\n",
      "Epoch 57/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6741 - acc: 0.6684 - val_loss: 0.6758 - val_acc: 0.6429\n",
      "Epoch 58/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6738 - acc: 0.6684 - val_loss: 0.6752 - val_acc: 0.6429\n",
      "Epoch 59/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6734 - acc: 0.6684 - val_loss: 0.6747 - val_acc: 0.6429\n",
      "Epoch 60/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6730 - acc: 0.6684 - val_loss: 0.6741 - val_acc: 0.6429\n",
      "Epoch 61/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6727 - acc: 0.6684 - val_loss: 0.6736 - val_acc: 0.6429\n",
      "Epoch 62/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6723 - acc: 0.6684 - val_loss: 0.6731 - val_acc: 0.6429\n",
      "Epoch 63/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6720 - acc: 0.6684 - val_loss: 0.6727 - val_acc: 0.6429\n",
      "Epoch 64/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6717 - acc: 0.6684 - val_loss: 0.6724 - val_acc: 0.6429\n",
      "Epoch 65/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6714 - acc: 0.6684 - val_loss: 0.6721 - val_acc: 0.6429\n",
      "Epoch 66/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6712 - acc: 0.6684 - val_loss: 0.6719 - val_acc: 0.6429\n",
      "Epoch 67/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6711 - acc: 0.6684 - val_loss: 0.6716 - val_acc: 0.6429\n",
      "Epoch 68/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6709 - acc: 0.6684 - val_loss: 0.6712 - val_acc: 0.6429\n",
      "Epoch 69/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6706 - acc: 0.6684 - val_loss: 0.6707 - val_acc: 0.6429\n",
      "Epoch 70/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6702 - acc: 0.6684 - val_loss: 0.6704 - val_acc: 0.6531\n",
      "Epoch 71/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6699 - acc: 0.6684 - val_loss: 0.6701 - val_acc: 0.6531\n",
      "Epoch 72/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6695 - acc: 0.6684 - val_loss: 0.6699 - val_acc: 0.6531\n",
      "Epoch 73/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6692 - acc: 0.6709 - val_loss: 0.6697 - val_acc: 0.6531\n",
      "Epoch 74/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6690 - acc: 0.6709 - val_loss: 0.6695 - val_acc: 0.6531\n",
      "Epoch 75/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6688 - acc: 0.6709 - val_loss: 0.6692 - val_acc: 0.6531\n",
      "Epoch 76/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6685 - acc: 0.6709 - val_loss: 0.6690 - val_acc: 0.6531\n",
      "Epoch 77/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6684 - acc: 0.6709 - val_loss: 0.6687 - val_acc: 0.6531\n",
      "Epoch 78/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6682 - acc: 0.6709 - val_loss: 0.6684 - val_acc: 0.6531\n",
      "Epoch 79/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6679 - acc: 0.6709 - val_loss: 0.6681 - val_acc: 0.6531\n",
      "Epoch 80/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6677 - acc: 0.6709 - val_loss: 0.6678 - val_acc: 0.6531\n",
      "Epoch 81/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6674 - acc: 0.6684 - val_loss: 0.6676 - val_acc: 0.6531\n",
      "Epoch 82/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6672 - acc: 0.6684 - val_loss: 0.6674 - val_acc: 0.6531\n",
      "Epoch 83/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6670 - acc: 0.6709 - val_loss: 0.6672 - val_acc: 0.6531\n",
      "Epoch 84/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6667 - acc: 0.6709 - val_loss: 0.6670 - val_acc: 0.6531\n",
      "Epoch 85/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6665 - acc: 0.6709 - val_loss: 0.6669 - val_acc: 0.6531\n",
      "Epoch 86/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6664 - acc: 0.6709 - val_loss: 0.6667 - val_acc: 0.6531\n",
      "Epoch 87/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6662 - acc: 0.6709 - val_loss: 0.6665 - val_acc: 0.6531\n",
      "Epoch 88/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6660 - acc: 0.6709 - val_loss: 0.6663 - val_acc: 0.6531\n",
      "Epoch 89/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6658 - acc: 0.6709 - val_loss: 0.6661 - val_acc: 0.6633\n",
      "Epoch 90/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6655 - acc: 0.6709 - val_loss: 0.6660 - val_acc: 0.6633\n",
      "Epoch 91/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6650 - acc: 0.6709 - val_loss: 0.6658 - val_acc: 0.6633\n",
      "Epoch 92/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6648 - acc: 0.6709 - val_loss: 0.6658 - val_acc: 0.6633\n",
      "Epoch 93/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6645 - acc: 0.6709 - val_loss: 0.6658 - val_acc: 0.6633\n",
      "Epoch 94/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6642 - acc: 0.6684 - val_loss: 0.6657 - val_acc: 0.6633\n",
      "Epoch 95/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6639 - acc: 0.6684 - val_loss: 0.6656 - val_acc: 0.6633\n",
      "Epoch 96/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6638 - acc: 0.6684 - val_loss: 0.6656 - val_acc: 0.6633\n",
      "Epoch 97/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6635 - acc: 0.6633 - val_loss: 0.6655 - val_acc: 0.6633\n",
      "Epoch 98/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6633 - acc: 0.6633 - val_loss: 0.6653 - val_acc: 0.6633\n",
      "Epoch 99/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6631 - acc: 0.6633 - val_loss: 0.6650 - val_acc: 0.6633\n",
      "Epoch 100/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6629 - acc: 0.6633 - val_loss: 0.6646 - val_acc: 0.6633\n",
      "Epoch 101/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6626 - acc: 0.6633 - val_loss: 0.6642 - val_acc: 0.6633\n",
      "Epoch 102/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6624 - acc: 0.6658 - val_loss: 0.6638 - val_acc: 0.6633\n",
      "Epoch 103/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6621 - acc: 0.6658 - val_loss: 0.6637 - val_acc: 0.6633\n",
      "Epoch 104/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6618 - acc: 0.6658 - val_loss: 0.6636 - val_acc: 0.6633\n",
      "Epoch 105/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6616 - acc: 0.6658 - val_loss: 0.6636 - val_acc: 0.6633\n",
      "Epoch 106/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6614 - acc: 0.6658 - val_loss: 0.6636 - val_acc: 0.6633\n",
      "Epoch 107/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6613 - acc: 0.6607 - val_loss: 0.6635 - val_acc: 0.6633\n",
      "Epoch 108/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6610 - acc: 0.6607 - val_loss: 0.6632 - val_acc: 0.6633\n",
      "Epoch 109/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6607 - acc: 0.6607 - val_loss: 0.6628 - val_acc: 0.6633\n",
      "Epoch 110/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6603 - acc: 0.6633 - val_loss: 0.6623 - val_acc: 0.6633\n",
      "Epoch 111/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6601 - acc: 0.6658 - val_loss: 0.6619 - val_acc: 0.6633\n",
      "Epoch 112/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6599 - acc: 0.6658 - val_loss: 0.6618 - val_acc: 0.6633\n",
      "Epoch 113/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6595 - acc: 0.6658 - val_loss: 0.6614 - val_acc: 0.6633\n",
      "Epoch 114/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 14us/step - loss: 0.6593 - acc: 0.6658 - val_loss: 0.6611 - val_acc: 0.6633\n",
      "Epoch 115/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6590 - acc: 0.6658 - val_loss: 0.6608 - val_acc: 0.6633\n",
      "Epoch 116/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6588 - acc: 0.6658 - val_loss: 0.6606 - val_acc: 0.6633\n",
      "Epoch 117/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6586 - acc: 0.6684 - val_loss: 0.6603 - val_acc: 0.6633\n",
      "Epoch 118/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6584 - acc: 0.6684 - val_loss: 0.6600 - val_acc: 0.6633\n",
      "Epoch 119/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6582 - acc: 0.6684 - val_loss: 0.6599 - val_acc: 0.6633\n",
      "Epoch 120/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6580 - acc: 0.6684 - val_loss: 0.6598 - val_acc: 0.6633\n",
      "Epoch 121/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6578 - acc: 0.6684 - val_loss: 0.6597 - val_acc: 0.6633\n",
      "Epoch 122/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6576 - acc: 0.6684 - val_loss: 0.6596 - val_acc: 0.6633\n",
      "Epoch 123/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6574 - acc: 0.6684 - val_loss: 0.6594 - val_acc: 0.6633\n",
      "Epoch 124/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6571 - acc: 0.6684 - val_loss: 0.6592 - val_acc: 0.6633\n",
      "Epoch 125/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6569 - acc: 0.6709 - val_loss: 0.6591 - val_acc: 0.6633\n",
      "Epoch 126/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6566 - acc: 0.6684 - val_loss: 0.6589 - val_acc: 0.6633\n",
      "Epoch 127/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6563 - acc: 0.6658 - val_loss: 0.6588 - val_acc: 0.6633\n",
      "Epoch 128/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6560 - acc: 0.6658 - val_loss: 0.6587 - val_acc: 0.6633\n",
      "Epoch 129/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6558 - acc: 0.6633 - val_loss: 0.6585 - val_acc: 0.6633\n",
      "Epoch 130/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6556 - acc: 0.6633 - val_loss: 0.6584 - val_acc: 0.6735\n",
      "Epoch 131/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6554 - acc: 0.6633 - val_loss: 0.6582 - val_acc: 0.6735\n",
      "Epoch 132/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6551 - acc: 0.6633 - val_loss: 0.6577 - val_acc: 0.6633\n",
      "Epoch 133/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6548 - acc: 0.6633 - val_loss: 0.6572 - val_acc: 0.6633\n",
      "Epoch 134/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6545 - acc: 0.6633 - val_loss: 0.6566 - val_acc: 0.6633\n",
      "Epoch 135/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6543 - acc: 0.6633 - val_loss: 0.6562 - val_acc: 0.6633\n",
      "Epoch 136/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6541 - acc: 0.6633 - val_loss: 0.6559 - val_acc: 0.6633\n",
      "Epoch 137/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6538 - acc: 0.6633 - val_loss: 0.6557 - val_acc: 0.6633\n",
      "Epoch 138/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6536 - acc: 0.6633 - val_loss: 0.6557 - val_acc: 0.6633\n",
      "Epoch 139/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6534 - acc: 0.6633 - val_loss: 0.6557 - val_acc: 0.6633\n",
      "Epoch 140/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6531 - acc: 0.6633 - val_loss: 0.6556 - val_acc: 0.6633\n",
      "Epoch 141/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6529 - acc: 0.6658 - val_loss: 0.6554 - val_acc: 0.6633\n",
      "Epoch 142/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6526 - acc: 0.6658 - val_loss: 0.6551 - val_acc: 0.6633\n",
      "Epoch 143/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6525 - acc: 0.6633 - val_loss: 0.6549 - val_acc: 0.6633\n",
      "Epoch 144/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6522 - acc: 0.6633 - val_loss: 0.6546 - val_acc: 0.6633\n",
      "Epoch 145/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6521 - acc: 0.6658 - val_loss: 0.6543 - val_acc: 0.6633\n",
      "Epoch 146/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6518 - acc: 0.6658 - val_loss: 0.6541 - val_acc: 0.6633\n",
      "Epoch 147/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6517 - acc: 0.6658 - val_loss: 0.6539 - val_acc: 0.6633\n",
      "Epoch 148/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6515 - acc: 0.6658 - val_loss: 0.6536 - val_acc: 0.6633\n",
      "Epoch 149/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6513 - acc: 0.6658 - val_loss: 0.6534 - val_acc: 0.6633\n",
      "Epoch 150/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6511 - acc: 0.6684 - val_loss: 0.6532 - val_acc: 0.6633\n",
      "Epoch 151/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6510 - acc: 0.6684 - val_loss: 0.6530 - val_acc: 0.6633\n",
      "Epoch 152/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.6684 - val_loss: 0.6528 - val_acc: 0.6633\n",
      "Epoch 153/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6505 - acc: 0.6684 - val_loss: 0.6527 - val_acc: 0.6633\n",
      "Epoch 154/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6503 - acc: 0.6684 - val_loss: 0.6526 - val_acc: 0.6633\n",
      "Epoch 155/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6500 - acc: 0.6658 - val_loss: 0.6525 - val_acc: 0.6633\n",
      "Epoch 156/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6497 - acc: 0.6684 - val_loss: 0.6523 - val_acc: 0.6633\n",
      "Epoch 157/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.6684 - val_loss: 0.6521 - val_acc: 0.6633\n",
      "Epoch 158/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.6684 - val_loss: 0.6518 - val_acc: 0.6633\n",
      "Epoch 159/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6489 - acc: 0.6684 - val_loss: 0.6516 - val_acc: 0.6633\n",
      "Epoch 160/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6486 - acc: 0.6684 - val_loss: 0.6514 - val_acc: 0.6633\n",
      "Epoch 161/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6483 - acc: 0.6684 - val_loss: 0.6513 - val_acc: 0.6633\n",
      "Epoch 162/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6480 - acc: 0.6684 - val_loss: 0.6510 - val_acc: 0.6633\n",
      "Epoch 163/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6478 - acc: 0.6684 - val_loss: 0.6508 - val_acc: 0.6633\n",
      "Epoch 164/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6475 - acc: 0.6684 - val_loss: 0.6506 - val_acc: 0.6633\n",
      "Epoch 165/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6472 - acc: 0.6684 - val_loss: 0.6507 - val_acc: 0.6633\n",
      "Epoch 166/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6468 - acc: 0.6684 - val_loss: 0.6507 - val_acc: 0.6633\n",
      "Epoch 167/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6463 - acc: 0.6684 - val_loss: 0.6506 - val_acc: 0.6735\n",
      "Epoch 168/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6459 - acc: 0.6684 - val_loss: 0.6504 - val_acc: 0.6735\n",
      "Epoch 169/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6456 - acc: 0.6684 - val_loss: 0.6501 - val_acc: 0.6735\n",
      "Epoch 170/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6453 - acc: 0.6684 - val_loss: 0.6498 - val_acc: 0.6735\n",
      "Epoch 171/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6451 - acc: 0.6684 - val_loss: 0.6494 - val_acc: 0.6735\n",
      "Epoch 172/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6447 - acc: 0.6684 - val_loss: 0.6491 - val_acc: 0.6735\n",
      "Epoch 173/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6443 - acc: 0.6684 - val_loss: 0.6487 - val_acc: 0.6735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6440 - acc: 0.6684 - val_loss: 0.6484 - val_acc: 0.6735\n",
      "Epoch 175/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6437 - acc: 0.6684 - val_loss: 0.6481 - val_acc: 0.6735\n",
      "Epoch 176/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6433 - acc: 0.6684 - val_loss: 0.6479 - val_acc: 0.6735\n",
      "Epoch 177/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6429 - acc: 0.6684 - val_loss: 0.6477 - val_acc: 0.6735\n",
      "Epoch 178/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6424 - acc: 0.6684 - val_loss: 0.6476 - val_acc: 0.6837\n",
      "Epoch 179/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6421 - acc: 0.6684 - val_loss: 0.6475 - val_acc: 0.6837\n",
      "Epoch 180/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6417 - acc: 0.6684 - val_loss: 0.6473 - val_acc: 0.6837\n",
      "Epoch 181/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6414 - acc: 0.6684 - val_loss: 0.6469 - val_acc: 0.6837\n",
      "Epoch 182/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6412 - acc: 0.6684 - val_loss: 0.6465 - val_acc: 0.6837\n",
      "Epoch 183/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6408 - acc: 0.6684 - val_loss: 0.6462 - val_acc: 0.6837\n",
      "Epoch 184/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6406 - acc: 0.6684 - val_loss: 0.6458 - val_acc: 0.6837\n",
      "Epoch 185/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6403 - acc: 0.6684 - val_loss: 0.6456 - val_acc: 0.6837\n",
      "Epoch 186/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6400 - acc: 0.6684 - val_loss: 0.6453 - val_acc: 0.6837\n",
      "Epoch 187/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6397 - acc: 0.6684 - val_loss: 0.6450 - val_acc: 0.6837\n",
      "Epoch 188/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6394 - acc: 0.6684 - val_loss: 0.6447 - val_acc: 0.6735\n",
      "Epoch 189/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6390 - acc: 0.6684 - val_loss: 0.6446 - val_acc: 0.6837\n",
      "Epoch 190/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6386 - acc: 0.6684 - val_loss: 0.6445 - val_acc: 0.6837\n",
      "Epoch 191/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6380 - acc: 0.6684 - val_loss: 0.6445 - val_acc: 0.6837\n",
      "Epoch 192/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6375 - acc: 0.6684 - val_loss: 0.6446 - val_acc: 0.6837\n",
      "Epoch 193/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6369 - acc: 0.6684 - val_loss: 0.6448 - val_acc: 0.6837\n",
      "Epoch 194/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6363 - acc: 0.6684 - val_loss: 0.6449 - val_acc: 0.6837\n",
      "Epoch 195/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6357 - acc: 0.6684 - val_loss: 0.6447 - val_acc: 0.6837\n",
      "Epoch 196/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6354 - acc: 0.6709 - val_loss: 0.6443 - val_acc: 0.6837\n",
      "Epoch 197/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6349 - acc: 0.6709 - val_loss: 0.6438 - val_acc: 0.6837\n",
      "Epoch 198/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6344 - acc: 0.6709 - val_loss: 0.6434 - val_acc: 0.6837\n",
      "Epoch 199/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6340 - acc: 0.6709 - val_loss: 0.6429 - val_acc: 0.6837\n",
      "Epoch 200/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6336 - acc: 0.6709 - val_loss: 0.6425 - val_acc: 0.6837\n",
      "Epoch 201/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6332 - acc: 0.6709 - val_loss: 0.6421 - val_acc: 0.6837\n",
      "Epoch 202/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6328 - acc: 0.6684 - val_loss: 0.6417 - val_acc: 0.6939\n",
      "Epoch 203/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6324 - acc: 0.6658 - val_loss: 0.6413 - val_acc: 0.6939\n",
      "Epoch 204/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6320 - acc: 0.6658 - val_loss: 0.6409 - val_acc: 0.6939\n",
      "Epoch 205/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6316 - acc: 0.6658 - val_loss: 0.6405 - val_acc: 0.6939\n",
      "Epoch 206/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6311 - acc: 0.6658 - val_loss: 0.6400 - val_acc: 0.6939\n",
      "Epoch 207/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6307 - acc: 0.6658 - val_loss: 0.6396 - val_acc: 0.6939\n",
      "Epoch 208/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6303 - acc: 0.6658 - val_loss: 0.6393 - val_acc: 0.6939\n",
      "Epoch 209/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6301 - acc: 0.6607 - val_loss: 0.6390 - val_acc: 0.6939\n",
      "Epoch 210/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6295 - acc: 0.6607 - val_loss: 0.6387 - val_acc: 0.6939\n",
      "Epoch 211/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6293 - acc: 0.6607 - val_loss: 0.6383 - val_acc: 0.6837\n",
      "Epoch 212/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6289 - acc: 0.6582 - val_loss: 0.6379 - val_acc: 0.6837\n",
      "Epoch 213/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6285 - acc: 0.6582 - val_loss: 0.6375 - val_acc: 0.6837\n",
      "Epoch 214/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6281 - acc: 0.6582 - val_loss: 0.6371 - val_acc: 0.6837\n",
      "Epoch 215/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6277 - acc: 0.6582 - val_loss: 0.6366 - val_acc: 0.6837\n",
      "Epoch 216/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6273 - acc: 0.6582 - val_loss: 0.6362 - val_acc: 0.6939\n",
      "Epoch 217/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6269 - acc: 0.6582 - val_loss: 0.6358 - val_acc: 0.6939\n",
      "Epoch 218/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6264 - acc: 0.6582 - val_loss: 0.6354 - val_acc: 0.6939\n",
      "Epoch 219/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6258 - acc: 0.6607 - val_loss: 0.6349 - val_acc: 0.6939\n",
      "Epoch 220/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6253 - acc: 0.6607 - val_loss: 0.6343 - val_acc: 0.6939\n",
      "Epoch 221/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6250 - acc: 0.6607 - val_loss: 0.6339 - val_acc: 0.6939\n",
      "Epoch 222/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6245 - acc: 0.6633 - val_loss: 0.6335 - val_acc: 0.6939\n",
      "Epoch 223/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6242 - acc: 0.6633 - val_loss: 0.6331 - val_acc: 0.6939\n",
      "Epoch 224/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6238 - acc: 0.6633 - val_loss: 0.6327 - val_acc: 0.6939\n",
      "Epoch 225/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6235 - acc: 0.6633 - val_loss: 0.6323 - val_acc: 0.6939\n",
      "Epoch 226/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6231 - acc: 0.6633 - val_loss: 0.6319 - val_acc: 0.6939\n",
      "Epoch 227/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6225 - acc: 0.6633 - val_loss: 0.6314 - val_acc: 0.6939\n",
      "Epoch 228/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6221 - acc: 0.6633 - val_loss: 0.6310 - val_acc: 0.6939\n",
      "Epoch 229/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6217 - acc: 0.6633 - val_loss: 0.6306 - val_acc: 0.6939\n",
      "Epoch 230/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6213 - acc: 0.6633 - val_loss: 0.6301 - val_acc: 0.6939\n",
      "Epoch 231/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6208 - acc: 0.6633 - val_loss: 0.6297 - val_acc: 0.6939\n",
      "Epoch 232/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6204 - acc: 0.6607 - val_loss: 0.6292 - val_acc: 0.6939\n",
      "Epoch 233/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6199 - acc: 0.6607 - val_loss: 0.6289 - val_acc: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6198 - acc: 0.6633 - val_loss: 0.6287 - val_acc: 0.7041\n",
      "Epoch 235/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6195 - acc: 0.6633 - val_loss: 0.6285 - val_acc: 0.7041\n",
      "Epoch 236/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6192 - acc: 0.6633 - val_loss: 0.6282 - val_acc: 0.7041\n",
      "Epoch 237/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6189 - acc: 0.6633 - val_loss: 0.6278 - val_acc: 0.7041\n",
      "Epoch 238/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6185 - acc: 0.6633 - val_loss: 0.6275 - val_acc: 0.7041\n",
      "Epoch 239/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6182 - acc: 0.6633 - val_loss: 0.6271 - val_acc: 0.7041\n",
      "Epoch 240/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6178 - acc: 0.6633 - val_loss: 0.6264 - val_acc: 0.7041\n",
      "Epoch 241/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6171 - acc: 0.6633 - val_loss: 0.6257 - val_acc: 0.7041\n",
      "Epoch 242/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6164 - acc: 0.6607 - val_loss: 0.6250 - val_acc: 0.7041\n",
      "Epoch 243/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6159 - acc: 0.6607 - val_loss: 0.6245 - val_acc: 0.7041\n",
      "Epoch 244/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6155 - acc: 0.6607 - val_loss: 0.6240 - val_acc: 0.7041\n",
      "Epoch 245/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6150 - acc: 0.6607 - val_loss: 0.6235 - val_acc: 0.7041\n",
      "Epoch 246/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6146 - acc: 0.6607 - val_loss: 0.6229 - val_acc: 0.7041\n",
      "Epoch 247/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6143 - acc: 0.6607 - val_loss: 0.6224 - val_acc: 0.7041\n",
      "Epoch 248/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6140 - acc: 0.6607 - val_loss: 0.6219 - val_acc: 0.7041\n",
      "Epoch 249/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6136 - acc: 0.6607 - val_loss: 0.6214 - val_acc: 0.7041\n",
      "Epoch 250/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6134 - acc: 0.6633 - val_loss: 0.6209 - val_acc: 0.7041\n",
      "Epoch 251/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6131 - acc: 0.6658 - val_loss: 0.6204 - val_acc: 0.7041\n",
      "Epoch 252/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6127 - acc: 0.6658 - val_loss: 0.6200 - val_acc: 0.7041\n",
      "Epoch 253/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6123 - acc: 0.6658 - val_loss: 0.6195 - val_acc: 0.7143\n",
      "Epoch 254/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6118 - acc: 0.6658 - val_loss: 0.6190 - val_acc: 0.7143\n",
      "Epoch 255/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6114 - acc: 0.6658 - val_loss: 0.6184 - val_acc: 0.7143\n",
      "Epoch 256/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6109 - acc: 0.6658 - val_loss: 0.6181 - val_acc: 0.7143\n",
      "Epoch 257/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6104 - acc: 0.6658 - val_loss: 0.6179 - val_acc: 0.7143\n",
      "Epoch 258/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6102 - acc: 0.6633 - val_loss: 0.6178 - val_acc: 0.7143\n",
      "Epoch 259/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6098 - acc: 0.6607 - val_loss: 0.6172 - val_acc: 0.7143\n",
      "Epoch 260/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6093 - acc: 0.6633 - val_loss: 0.6166 - val_acc: 0.7143\n",
      "Epoch 261/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6090 - acc: 0.6684 - val_loss: 0.6160 - val_acc: 0.7143\n",
      "Epoch 262/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6086 - acc: 0.6684 - val_loss: 0.6155 - val_acc: 0.7143\n",
      "Epoch 263/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6081 - acc: 0.6684 - val_loss: 0.6150 - val_acc: 0.7143\n",
      "Epoch 264/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6076 - acc: 0.6684 - val_loss: 0.6145 - val_acc: 0.7143\n",
      "Epoch 265/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6071 - acc: 0.6684 - val_loss: 0.6139 - val_acc: 0.7143\n",
      "Epoch 266/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6066 - acc: 0.6684 - val_loss: 0.6133 - val_acc: 0.7143\n",
      "Epoch 267/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6061 - acc: 0.6658 - val_loss: 0.6126 - val_acc: 0.7143\n",
      "Epoch 268/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6057 - acc: 0.6633 - val_loss: 0.6120 - val_acc: 0.7143\n",
      "Epoch 269/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6051 - acc: 0.6633 - val_loss: 0.6115 - val_acc: 0.7143\n",
      "Epoch 270/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6047 - acc: 0.6633 - val_loss: 0.6110 - val_acc: 0.7143\n",
      "Epoch 271/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6043 - acc: 0.6633 - val_loss: 0.6106 - val_acc: 0.7143\n",
      "Epoch 272/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6038 - acc: 0.6633 - val_loss: 0.6100 - val_acc: 0.7143\n",
      "Epoch 273/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6034 - acc: 0.6633 - val_loss: 0.6094 - val_acc: 0.7143\n",
      "Epoch 274/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6030 - acc: 0.6658 - val_loss: 0.6086 - val_acc: 0.7143\n",
      "Epoch 275/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6024 - acc: 0.6633 - val_loss: 0.6078 - val_acc: 0.7143\n",
      "Epoch 276/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6021 - acc: 0.6658 - val_loss: 0.6071 - val_acc: 0.7143\n",
      "Epoch 277/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6017 - acc: 0.6658 - val_loss: 0.6067 - val_acc: 0.7143\n",
      "Epoch 278/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6013 - acc: 0.6658 - val_loss: 0.6063 - val_acc: 0.7143\n",
      "Epoch 279/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6008 - acc: 0.6633 - val_loss: 0.6057 - val_acc: 0.7143\n",
      "Epoch 280/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6004 - acc: 0.6658 - val_loss: 0.6053 - val_acc: 0.7143\n",
      "Epoch 281/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5999 - acc: 0.6633 - val_loss: 0.6050 - val_acc: 0.7143\n",
      "Epoch 282/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5994 - acc: 0.6633 - val_loss: 0.6046 - val_acc: 0.7143\n",
      "Epoch 283/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5991 - acc: 0.6658 - val_loss: 0.6041 - val_acc: 0.7143\n",
      "Epoch 284/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5988 - acc: 0.6658 - val_loss: 0.6033 - val_acc: 0.7143\n",
      "Epoch 285/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5982 - acc: 0.6633 - val_loss: 0.6029 - val_acc: 0.7143\n",
      "Epoch 286/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5979 - acc: 0.6658 - val_loss: 0.6026 - val_acc: 0.7143\n",
      "Epoch 287/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5974 - acc: 0.6684 - val_loss: 0.6022 - val_acc: 0.7143\n",
      "Epoch 288/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5970 - acc: 0.6709 - val_loss: 0.6019 - val_acc: 0.7143\n",
      "Epoch 289/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5967 - acc: 0.6709 - val_loss: 0.6016 - val_acc: 0.7143\n",
      "Epoch 290/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5964 - acc: 0.6709 - val_loss: 0.6011 - val_acc: 0.7143\n",
      "Epoch 291/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5960 - acc: 0.6709 - val_loss: 0.6006 - val_acc: 0.7143\n",
      "Epoch 292/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5956 - acc: 0.6709 - val_loss: 0.6000 - val_acc: 0.7143\n",
      "Epoch 293/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5951 - acc: 0.6709 - val_loss: 0.5991 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5947 - acc: 0.6709 - val_loss: 0.5982 - val_acc: 0.7143\n",
      "Epoch 295/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5942 - acc: 0.6684 - val_loss: 0.5975 - val_acc: 0.7143\n",
      "Epoch 296/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5939 - acc: 0.6684 - val_loss: 0.5968 - val_acc: 0.7041\n",
      "Epoch 297/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5935 - acc: 0.6684 - val_loss: 0.5961 - val_acc: 0.7041\n",
      "Epoch 298/1500\n",
      "392/392 [==============================] - 0s 11us/step - loss: 0.5930 - acc: 0.6684 - val_loss: 0.5951 - val_acc: 0.7041\n",
      "Epoch 299/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5929 - acc: 0.6837 - val_loss: 0.5943 - val_acc: 0.7041\n",
      "Epoch 300/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5926 - acc: 0.6837 - val_loss: 0.5936 - val_acc: 0.7041\n",
      "Epoch 301/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5922 - acc: 0.6811 - val_loss: 0.5931 - val_acc: 0.7041\n",
      "Epoch 302/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5918 - acc: 0.6837 - val_loss: 0.5928 - val_acc: 0.7041\n",
      "Epoch 303/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5910 - acc: 0.6862 - val_loss: 0.5926 - val_acc: 0.7041\n",
      "Epoch 304/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5905 - acc: 0.6786 - val_loss: 0.5927 - val_acc: 0.7041\n",
      "Epoch 305/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5904 - acc: 0.6709 - val_loss: 0.5928 - val_acc: 0.7143\n",
      "Epoch 306/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5899 - acc: 0.6735 - val_loss: 0.5927 - val_acc: 0.7143\n",
      "Epoch 307/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5896 - acc: 0.6709 - val_loss: 0.5922 - val_acc: 0.7143\n",
      "Epoch 308/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5893 - acc: 0.6735 - val_loss: 0.5915 - val_acc: 0.7143\n",
      "Epoch 309/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5888 - acc: 0.6760 - val_loss: 0.5908 - val_acc: 0.7143\n",
      "Epoch 310/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5883 - acc: 0.6760 - val_loss: 0.5901 - val_acc: 0.7143\n",
      "Epoch 311/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5879 - acc: 0.6760 - val_loss: 0.5891 - val_acc: 0.7041\n",
      "Epoch 312/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5875 - acc: 0.6837 - val_loss: 0.5883 - val_acc: 0.7041\n",
      "Epoch 313/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5871 - acc: 0.6837 - val_loss: 0.5877 - val_acc: 0.6939\n",
      "Epoch 314/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5869 - acc: 0.6811 - val_loss: 0.5872 - val_acc: 0.6939\n",
      "Epoch 315/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5865 - acc: 0.6837 - val_loss: 0.5867 - val_acc: 0.6939\n",
      "Epoch 316/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5862 - acc: 0.6811 - val_loss: 0.5862 - val_acc: 0.6939\n",
      "Epoch 317/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5860 - acc: 0.6862 - val_loss: 0.5856 - val_acc: 0.6939\n",
      "Epoch 318/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5856 - acc: 0.6888 - val_loss: 0.5851 - val_acc: 0.6939\n",
      "Epoch 319/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5852 - acc: 0.6913 - val_loss: 0.5847 - val_acc: 0.6939\n",
      "Epoch 320/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5847 - acc: 0.6888 - val_loss: 0.5843 - val_acc: 0.6939\n",
      "Epoch 321/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5843 - acc: 0.6888 - val_loss: 0.5839 - val_acc: 0.6939\n",
      "Epoch 322/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5839 - acc: 0.6888 - val_loss: 0.5836 - val_acc: 0.6939\n",
      "Epoch 323/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5836 - acc: 0.6888 - val_loss: 0.5834 - val_acc: 0.6939\n",
      "Epoch 324/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5832 - acc: 0.6913 - val_loss: 0.5832 - val_acc: 0.6939\n",
      "Epoch 325/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5828 - acc: 0.6862 - val_loss: 0.5828 - val_acc: 0.6939\n",
      "Epoch 326/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5827 - acc: 0.6862 - val_loss: 0.5820 - val_acc: 0.6939\n",
      "Epoch 327/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5821 - acc: 0.6939 - val_loss: 0.5814 - val_acc: 0.6939\n",
      "Epoch 328/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5818 - acc: 0.6939 - val_loss: 0.5807 - val_acc: 0.6939\n",
      "Epoch 329/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5814 - acc: 0.6939 - val_loss: 0.5801 - val_acc: 0.6939\n",
      "Epoch 330/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5812 - acc: 0.6964 - val_loss: 0.5795 - val_acc: 0.6939\n",
      "Epoch 331/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5808 - acc: 0.6964 - val_loss: 0.5791 - val_acc: 0.6939\n",
      "Epoch 332/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5803 - acc: 0.6964 - val_loss: 0.5789 - val_acc: 0.6939\n",
      "Epoch 333/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5796 - acc: 0.6913 - val_loss: 0.5788 - val_acc: 0.6939\n",
      "Epoch 334/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5796 - acc: 0.6837 - val_loss: 0.5789 - val_acc: 0.6939\n",
      "Epoch 335/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5789 - acc: 0.6837 - val_loss: 0.5789 - val_acc: 0.6939\n",
      "Epoch 336/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5788 - acc: 0.6837 - val_loss: 0.5787 - val_acc: 0.6939\n",
      "Epoch 337/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5785 - acc: 0.6811 - val_loss: 0.5783 - val_acc: 0.6939\n",
      "Epoch 338/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5782 - acc: 0.6837 - val_loss: 0.5777 - val_acc: 0.6939\n",
      "Epoch 339/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5777 - acc: 0.6837 - val_loss: 0.5770 - val_acc: 0.6939\n",
      "Epoch 340/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5773 - acc: 0.6837 - val_loss: 0.5765 - val_acc: 0.6939\n",
      "Epoch 341/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5771 - acc: 0.6837 - val_loss: 0.5758 - val_acc: 0.6939\n",
      "Epoch 342/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5766 - acc: 0.6837 - val_loss: 0.5756 - val_acc: 0.6939\n",
      "Epoch 343/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5764 - acc: 0.6837 - val_loss: 0.5753 - val_acc: 0.6939\n",
      "Epoch 344/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5761 - acc: 0.6837 - val_loss: 0.5749 - val_acc: 0.6939\n",
      "Epoch 345/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5757 - acc: 0.6837 - val_loss: 0.5742 - val_acc: 0.6939\n",
      "Epoch 346/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5754 - acc: 0.6862 - val_loss: 0.5735 - val_acc: 0.6939\n",
      "Epoch 347/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5750 - acc: 0.6913 - val_loss: 0.5730 - val_acc: 0.6939\n",
      "Epoch 348/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5747 - acc: 0.6939 - val_loss: 0.5727 - val_acc: 0.6939\n",
      "Epoch 349/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5744 - acc: 0.6939 - val_loss: 0.5724 - val_acc: 0.6939\n",
      "Epoch 350/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5741 - acc: 0.6939 - val_loss: 0.5721 - val_acc: 0.6939\n",
      "Epoch 351/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5737 - acc: 0.6939 - val_loss: 0.5719 - val_acc: 0.6939\n",
      "Epoch 352/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5734 - acc: 0.6964 - val_loss: 0.5715 - val_acc: 0.6939\n",
      "Epoch 353/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5731 - acc: 0.6964 - val_loss: 0.5710 - val_acc: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5728 - acc: 0.6939 - val_loss: 0.5705 - val_acc: 0.6939\n",
      "Epoch 355/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5723 - acc: 0.6939 - val_loss: 0.5697 - val_acc: 0.6939\n",
      "Epoch 356/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5721 - acc: 0.6939 - val_loss: 0.5688 - val_acc: 0.6939\n",
      "Epoch 357/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5717 - acc: 0.6990 - val_loss: 0.5684 - val_acc: 0.6939\n",
      "Epoch 358/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5713 - acc: 0.7015 - val_loss: 0.5681 - val_acc: 0.6939\n",
      "Epoch 359/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5710 - acc: 0.7015 - val_loss: 0.5679 - val_acc: 0.6939\n",
      "Epoch 360/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5707 - acc: 0.6990 - val_loss: 0.5676 - val_acc: 0.6939\n",
      "Epoch 361/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5704 - acc: 0.6990 - val_loss: 0.5674 - val_acc: 0.6939\n",
      "Epoch 362/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5701 - acc: 0.6964 - val_loss: 0.5670 - val_acc: 0.6939\n",
      "Epoch 363/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5698 - acc: 0.6990 - val_loss: 0.5665 - val_acc: 0.6939\n",
      "Epoch 364/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5694 - acc: 0.6990 - val_loss: 0.5661 - val_acc: 0.6939\n",
      "Epoch 365/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5691 - acc: 0.6990 - val_loss: 0.5659 - val_acc: 0.6939\n",
      "Epoch 366/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5687 - acc: 0.7015 - val_loss: 0.5655 - val_acc: 0.6939\n",
      "Epoch 367/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5684 - acc: 0.7015 - val_loss: 0.5650 - val_acc: 0.6939\n",
      "Epoch 368/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5681 - acc: 0.7015 - val_loss: 0.5647 - val_acc: 0.6939\n",
      "Epoch 369/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5678 - acc: 0.7015 - val_loss: 0.5646 - val_acc: 0.6939\n",
      "Epoch 370/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5675 - acc: 0.7015 - val_loss: 0.5643 - val_acc: 0.6939\n",
      "Epoch 371/1500\n",
      "392/392 [==============================] - 0s 28us/step - loss: 0.5673 - acc: 0.7041 - val_loss: 0.5637 - val_acc: 0.7041\n",
      "Epoch 372/1500\n",
      "392/392 [==============================] - 0s 26us/step - loss: 0.5670 - acc: 0.7015 - val_loss: 0.5631 - val_acc: 0.6939\n",
      "Epoch 373/1500\n",
      "392/392 [==============================] - 0s 23us/step - loss: 0.5665 - acc: 0.7015 - val_loss: 0.5625 - val_acc: 0.6939\n",
      "Epoch 374/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.5663 - acc: 0.7015 - val_loss: 0.5620 - val_acc: 0.6939\n",
      "Epoch 375/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.5660 - acc: 0.7015 - val_loss: 0.5618 - val_acc: 0.6939\n",
      "Epoch 376/1500\n",
      "392/392 [==============================] - 0s 23us/step - loss: 0.5659 - acc: 0.7015 - val_loss: 0.5617 - val_acc: 0.6939\n",
      "Epoch 377/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5654 - acc: 0.7015 - val_loss: 0.5613 - val_acc: 0.6939\n",
      "Epoch 378/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5651 - acc: 0.7015 - val_loss: 0.5608 - val_acc: 0.7041\n",
      "Epoch 379/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5649 - acc: 0.7015 - val_loss: 0.5602 - val_acc: 0.7041\n",
      "Epoch 380/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5646 - acc: 0.7015 - val_loss: 0.5600 - val_acc: 0.7143\n",
      "Epoch 381/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5643 - acc: 0.7015 - val_loss: 0.5596 - val_acc: 0.7143\n",
      "Epoch 382/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5639 - acc: 0.6990 - val_loss: 0.5590 - val_acc: 0.7041\n",
      "Epoch 383/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5638 - acc: 0.6990 - val_loss: 0.5584 - val_acc: 0.7041\n",
      "Epoch 384/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5636 - acc: 0.7041 - val_loss: 0.5579 - val_acc: 0.7041\n",
      "Epoch 385/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5634 - acc: 0.7117 - val_loss: 0.5574 - val_acc: 0.7041\n",
      "Epoch 386/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5630 - acc: 0.7143 - val_loss: 0.5569 - val_acc: 0.7143\n",
      "Epoch 387/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5627 - acc: 0.7194 - val_loss: 0.5564 - val_acc: 0.7143\n",
      "Epoch 388/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5624 - acc: 0.7219 - val_loss: 0.5560 - val_acc: 0.7143\n",
      "Epoch 389/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5619 - acc: 0.7168 - val_loss: 0.5557 - val_acc: 0.7041\n",
      "Epoch 390/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5613 - acc: 0.7117 - val_loss: 0.5555 - val_acc: 0.7041\n",
      "Epoch 391/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5609 - acc: 0.7117 - val_loss: 0.5552 - val_acc: 0.7041\n",
      "Epoch 392/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5606 - acc: 0.7041 - val_loss: 0.5552 - val_acc: 0.7041\n",
      "Epoch 393/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5603 - acc: 0.7015 - val_loss: 0.5553 - val_acc: 0.7143\n",
      "Epoch 394/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5601 - acc: 0.7041 - val_loss: 0.5556 - val_acc: 0.7143\n",
      "Epoch 395/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5598 - acc: 0.7066 - val_loss: 0.5556 - val_acc: 0.7041\n",
      "Epoch 396/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5596 - acc: 0.7066 - val_loss: 0.5557 - val_acc: 0.7041\n",
      "Epoch 397/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5595 - acc: 0.7015 - val_loss: 0.5560 - val_acc: 0.6939\n",
      "Epoch 398/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5595 - acc: 0.6990 - val_loss: 0.5562 - val_acc: 0.6939\n",
      "Epoch 399/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5595 - acc: 0.6990 - val_loss: 0.5562 - val_acc: 0.6939\n",
      "Epoch 400/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5593 - acc: 0.6964 - val_loss: 0.5556 - val_acc: 0.6837\n",
      "Epoch 401/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5588 - acc: 0.6990 - val_loss: 0.5548 - val_acc: 0.6939\n",
      "Epoch 402/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5584 - acc: 0.7015 - val_loss: 0.5541 - val_acc: 0.7041\n",
      "Epoch 403/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5580 - acc: 0.7066 - val_loss: 0.5534 - val_acc: 0.7143\n",
      "Epoch 404/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5574 - acc: 0.7066 - val_loss: 0.5527 - val_acc: 0.7143\n",
      "Epoch 405/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5571 - acc: 0.7041 - val_loss: 0.5522 - val_acc: 0.7143\n",
      "Epoch 406/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5568 - acc: 0.7041 - val_loss: 0.5516 - val_acc: 0.7143\n",
      "Epoch 407/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5564 - acc: 0.7092 - val_loss: 0.5506 - val_acc: 0.7041\n",
      "Epoch 408/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5559 - acc: 0.7117 - val_loss: 0.5496 - val_acc: 0.7041\n",
      "Epoch 409/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5558 - acc: 0.7143 - val_loss: 0.5489 - val_acc: 0.7143\n",
      "Epoch 410/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5556 - acc: 0.7143 - val_loss: 0.5484 - val_acc: 0.7143\n",
      "Epoch 411/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5554 - acc: 0.7194 - val_loss: 0.5479 - val_acc: 0.7143\n",
      "Epoch 412/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5553 - acc: 0.7219 - val_loss: 0.5473 - val_acc: 0.7143\n",
      "Epoch 413/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5549 - acc: 0.7219 - val_loss: 0.5469 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5545 - acc: 0.7219 - val_loss: 0.5467 - val_acc: 0.7143\n",
      "Epoch 415/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5542 - acc: 0.7219 - val_loss: 0.5464 - val_acc: 0.7143\n",
      "Epoch 416/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5538 - acc: 0.7194 - val_loss: 0.5462 - val_acc: 0.7143\n",
      "Epoch 417/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5534 - acc: 0.7143 - val_loss: 0.5460 - val_acc: 0.7143\n",
      "Epoch 418/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5532 - acc: 0.7168 - val_loss: 0.5460 - val_acc: 0.7143\n",
      "Epoch 419/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5528 - acc: 0.7168 - val_loss: 0.5461 - val_acc: 0.6939\n",
      "Epoch 420/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5529 - acc: 0.7143 - val_loss: 0.5461 - val_acc: 0.7041\n",
      "Epoch 421/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5526 - acc: 0.7117 - val_loss: 0.5462 - val_acc: 0.7041\n",
      "Epoch 422/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5525 - acc: 0.7117 - val_loss: 0.5464 - val_acc: 0.7041\n",
      "Epoch 423/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5524 - acc: 0.7143 - val_loss: 0.5467 - val_acc: 0.7041\n",
      "Epoch 424/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5523 - acc: 0.7117 - val_loss: 0.5466 - val_acc: 0.7041\n",
      "Epoch 425/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5521 - acc: 0.7117 - val_loss: 0.5461 - val_acc: 0.7041\n",
      "Epoch 426/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5518 - acc: 0.7117 - val_loss: 0.5454 - val_acc: 0.7041\n",
      "Epoch 427/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5512 - acc: 0.7117 - val_loss: 0.5441 - val_acc: 0.6939\n",
      "Epoch 428/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5507 - acc: 0.7168 - val_loss: 0.5432 - val_acc: 0.7041\n",
      "Epoch 429/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5505 - acc: 0.7168 - val_loss: 0.5428 - val_acc: 0.7041\n",
      "Epoch 430/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5503 - acc: 0.7168 - val_loss: 0.5426 - val_acc: 0.7041\n",
      "Epoch 431/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5502 - acc: 0.7168 - val_loss: 0.5426 - val_acc: 0.7041\n",
      "Epoch 432/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5501 - acc: 0.7168 - val_loss: 0.5426 - val_acc: 0.6939\n",
      "Epoch 433/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5497 - acc: 0.7194 - val_loss: 0.5421 - val_acc: 0.7041\n",
      "Epoch 434/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5493 - acc: 0.7194 - val_loss: 0.5417 - val_acc: 0.7041\n",
      "Epoch 435/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5492 - acc: 0.7194 - val_loss: 0.5411 - val_acc: 0.7041\n",
      "Epoch 436/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5490 - acc: 0.7168 - val_loss: 0.5404 - val_acc: 0.7041\n",
      "Epoch 437/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5487 - acc: 0.7194 - val_loss: 0.5398 - val_acc: 0.7041\n",
      "Epoch 438/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5485 - acc: 0.7296 - val_loss: 0.5392 - val_acc: 0.7143\n",
      "Epoch 439/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5482 - acc: 0.7296 - val_loss: 0.5389 - val_acc: 0.7143\n",
      "Epoch 440/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5480 - acc: 0.7296 - val_loss: 0.5387 - val_acc: 0.7143\n",
      "Epoch 441/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5478 - acc: 0.7296 - val_loss: 0.5385 - val_acc: 0.7143\n",
      "Epoch 442/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5475 - acc: 0.7296 - val_loss: 0.5384 - val_acc: 0.7041\n",
      "Epoch 443/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5471 - acc: 0.7270 - val_loss: 0.5384 - val_acc: 0.7041\n",
      "Epoch 444/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5469 - acc: 0.7194 - val_loss: 0.5384 - val_acc: 0.7041\n",
      "Epoch 445/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5467 - acc: 0.7168 - val_loss: 0.5384 - val_acc: 0.7041\n",
      "Epoch 446/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5465 - acc: 0.7168 - val_loss: 0.5381 - val_acc: 0.7041\n",
      "Epoch 447/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5462 - acc: 0.7194 - val_loss: 0.5380 - val_acc: 0.7041\n",
      "Epoch 448/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5460 - acc: 0.7194 - val_loss: 0.5377 - val_acc: 0.7041\n",
      "Epoch 449/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5457 - acc: 0.7194 - val_loss: 0.5373 - val_acc: 0.7041\n",
      "Epoch 450/1500\n",
      "392/392 [==============================] - 0s 11us/step - loss: 0.5455 - acc: 0.7168 - val_loss: 0.5368 - val_acc: 0.7041\n",
      "Epoch 451/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5452 - acc: 0.7168 - val_loss: 0.5362 - val_acc: 0.7041\n",
      "Epoch 452/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5451 - acc: 0.7321 - val_loss: 0.5354 - val_acc: 0.7143\n",
      "Epoch 453/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5449 - acc: 0.7321 - val_loss: 0.5349 - val_acc: 0.7143\n",
      "Epoch 454/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5447 - acc: 0.7321 - val_loss: 0.5345 - val_acc: 0.7143\n",
      "Epoch 455/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5446 - acc: 0.7321 - val_loss: 0.5342 - val_acc: 0.7143\n",
      "Epoch 456/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5443 - acc: 0.7347 - val_loss: 0.5339 - val_acc: 0.7245\n",
      "Epoch 457/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5442 - acc: 0.7347 - val_loss: 0.5335 - val_acc: 0.7245\n",
      "Epoch 458/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5442 - acc: 0.7347 - val_loss: 0.5332 - val_acc: 0.7245\n",
      "Epoch 459/1500\n",
      "392/392 [==============================] - 0s 11us/step - loss: 0.5438 - acc: 0.7347 - val_loss: 0.5331 - val_acc: 0.7245\n",
      "Epoch 460/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5435 - acc: 0.7347 - val_loss: 0.5331 - val_acc: 0.7041\n",
      "Epoch 461/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5431 - acc: 0.7347 - val_loss: 0.5328 - val_acc: 0.7245\n",
      "Epoch 462/1500\n",
      "392/392 [==============================] - 0s 11us/step - loss: 0.5429 - acc: 0.7347 - val_loss: 0.5324 - val_acc: 0.7245\n",
      "Epoch 463/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5427 - acc: 0.7347 - val_loss: 0.5322 - val_acc: 0.7245\n",
      "Epoch 464/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5425 - acc: 0.7347 - val_loss: 0.5321 - val_acc: 0.7245\n",
      "Epoch 465/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5424 - acc: 0.7347 - val_loss: 0.5317 - val_acc: 0.7245\n",
      "Epoch 466/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5424 - acc: 0.7423 - val_loss: 0.5314 - val_acc: 0.7347\n",
      "Epoch 467/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5423 - acc: 0.7449 - val_loss: 0.5311 - val_acc: 0.7347\n",
      "Epoch 468/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5423 - acc: 0.7398 - val_loss: 0.5309 - val_acc: 0.7347\n",
      "Epoch 469/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5421 - acc: 0.7423 - val_loss: 0.5307 - val_acc: 0.7347\n",
      "Epoch 470/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5417 - acc: 0.7423 - val_loss: 0.5306 - val_acc: 0.7347\n",
      "Epoch 471/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5416 - acc: 0.7347 - val_loss: 0.5307 - val_acc: 0.7245\n",
      "Epoch 472/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5410 - acc: 0.7347 - val_loss: 0.5307 - val_acc: 0.7143\n",
      "Epoch 473/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5407 - acc: 0.7321 - val_loss: 0.5306 - val_acc: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5405 - acc: 0.7321 - val_loss: 0.5305 - val_acc: 0.7041\n",
      "Epoch 475/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5403 - acc: 0.7321 - val_loss: 0.5305 - val_acc: 0.7143\n",
      "Epoch 476/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5401 - acc: 0.7321 - val_loss: 0.5307 - val_acc: 0.7143\n",
      "Epoch 477/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5400 - acc: 0.7270 - val_loss: 0.5310 - val_acc: 0.7041\n",
      "Epoch 478/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5398 - acc: 0.7245 - val_loss: 0.5311 - val_acc: 0.7041\n",
      "Epoch 479/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5397 - acc: 0.7219 - val_loss: 0.5308 - val_acc: 0.7041\n",
      "Epoch 480/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5395 - acc: 0.7245 - val_loss: 0.5305 - val_acc: 0.7041\n",
      "Epoch 481/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5393 - acc: 0.7296 - val_loss: 0.5301 - val_acc: 0.7143\n",
      "Epoch 482/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5391 - acc: 0.7296 - val_loss: 0.5301 - val_acc: 0.7041\n",
      "Epoch 483/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5389 - acc: 0.7270 - val_loss: 0.5306 - val_acc: 0.7041\n",
      "Epoch 484/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5390 - acc: 0.7194 - val_loss: 0.5314 - val_acc: 0.7143\n",
      "Epoch 485/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5394 - acc: 0.7194 - val_loss: 0.5319 - val_acc: 0.7143\n",
      "Epoch 486/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5392 - acc: 0.7219 - val_loss: 0.5315 - val_acc: 0.7143\n",
      "Epoch 487/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5389 - acc: 0.7219 - val_loss: 0.5303 - val_acc: 0.7041\n",
      "Epoch 488/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5383 - acc: 0.7194 - val_loss: 0.5293 - val_acc: 0.7143\n",
      "Epoch 489/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5380 - acc: 0.7270 - val_loss: 0.5285 - val_acc: 0.7143\n",
      "Epoch 490/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5376 - acc: 0.7270 - val_loss: 0.5281 - val_acc: 0.7143\n",
      "Epoch 491/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5374 - acc: 0.7296 - val_loss: 0.5279 - val_acc: 0.7143\n",
      "Epoch 492/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5372 - acc: 0.7296 - val_loss: 0.5276 - val_acc: 0.7143\n",
      "Epoch 493/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5370 - acc: 0.7296 - val_loss: 0.5273 - val_acc: 0.7143\n",
      "Epoch 494/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5368 - acc: 0.7321 - val_loss: 0.5269 - val_acc: 0.7041\n",
      "Epoch 495/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5365 - acc: 0.7321 - val_loss: 0.5267 - val_acc: 0.7143\n",
      "Epoch 496/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5364 - acc: 0.7321 - val_loss: 0.5267 - val_acc: 0.7143\n",
      "Epoch 497/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5362 - acc: 0.7321 - val_loss: 0.5264 - val_acc: 0.7143\n",
      "Epoch 498/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5360 - acc: 0.7321 - val_loss: 0.5258 - val_acc: 0.7041\n",
      "Epoch 499/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5357 - acc: 0.7321 - val_loss: 0.5255 - val_acc: 0.7041\n",
      "Epoch 500/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5355 - acc: 0.7347 - val_loss: 0.5253 - val_acc: 0.7041\n",
      "Epoch 501/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5353 - acc: 0.7347 - val_loss: 0.5249 - val_acc: 0.7041\n",
      "Epoch 502/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5350 - acc: 0.7347 - val_loss: 0.5242 - val_acc: 0.7245\n",
      "Epoch 503/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5349 - acc: 0.7372 - val_loss: 0.5236 - val_acc: 0.7245\n",
      "Epoch 504/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5350 - acc: 0.7347 - val_loss: 0.5233 - val_acc: 0.7245\n",
      "Epoch 505/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5349 - acc: 0.7372 - val_loss: 0.5232 - val_acc: 0.7245\n",
      "Epoch 506/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5346 - acc: 0.7347 - val_loss: 0.5231 - val_acc: 0.7245\n",
      "Epoch 507/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5343 - acc: 0.7372 - val_loss: 0.5226 - val_acc: 0.7245\n",
      "Epoch 508/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5346 - acc: 0.7423 - val_loss: 0.5220 - val_acc: 0.7347\n",
      "Epoch 509/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5345 - acc: 0.7449 - val_loss: 0.5217 - val_acc: 0.7347\n",
      "Epoch 510/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5347 - acc: 0.7449 - val_loss: 0.5214 - val_acc: 0.7347\n",
      "Epoch 511/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5348 - acc: 0.7423 - val_loss: 0.5212 - val_acc: 0.7449\n",
      "Epoch 512/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5354 - acc: 0.7423 - val_loss: 0.5211 - val_acc: 0.7449\n",
      "Epoch 513/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5351 - acc: 0.7423 - val_loss: 0.5209 - val_acc: 0.7449\n",
      "Epoch 514/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5347 - acc: 0.7423 - val_loss: 0.5208 - val_acc: 0.7347\n",
      "Epoch 515/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5342 - acc: 0.7423 - val_loss: 0.5206 - val_acc: 0.7347\n",
      "Epoch 516/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5337 - acc: 0.7398 - val_loss: 0.5206 - val_acc: 0.7347\n",
      "Epoch 517/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5332 - acc: 0.7449 - val_loss: 0.5206 - val_acc: 0.7347\n",
      "Epoch 518/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5329 - acc: 0.7423 - val_loss: 0.5206 - val_acc: 0.7347\n",
      "Epoch 519/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5325 - acc: 0.7423 - val_loss: 0.5206 - val_acc: 0.7245\n",
      "Epoch 520/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5322 - acc: 0.7398 - val_loss: 0.5208 - val_acc: 0.7245\n",
      "Epoch 521/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5320 - acc: 0.7321 - val_loss: 0.5209 - val_acc: 0.7245\n",
      "Epoch 522/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5317 - acc: 0.7372 - val_loss: 0.5209 - val_acc: 0.7245\n",
      "Epoch 523/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5315 - acc: 0.7372 - val_loss: 0.5208 - val_acc: 0.7245\n",
      "Epoch 524/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5313 - acc: 0.7398 - val_loss: 0.5207 - val_acc: 0.7245\n",
      "Epoch 525/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5312 - acc: 0.7372 - val_loss: 0.5204 - val_acc: 0.7245\n",
      "Epoch 526/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5311 - acc: 0.7398 - val_loss: 0.5204 - val_acc: 0.7245\n",
      "Epoch 527/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5310 - acc: 0.7398 - val_loss: 0.5203 - val_acc: 0.7245\n",
      "Epoch 528/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5308 - acc: 0.7398 - val_loss: 0.5202 - val_acc: 0.7245\n",
      "Epoch 529/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5307 - acc: 0.7372 - val_loss: 0.5204 - val_acc: 0.7245\n",
      "Epoch 530/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5306 - acc: 0.7347 - val_loss: 0.5208 - val_acc: 0.7041\n",
      "Epoch 531/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5305 - acc: 0.7321 - val_loss: 0.5208 - val_acc: 0.7041\n",
      "Epoch 532/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5303 - acc: 0.7296 - val_loss: 0.5207 - val_acc: 0.7041\n",
      "Epoch 533/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5302 - acc: 0.7296 - val_loss: 0.5206 - val_acc: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5300 - acc: 0.7296 - val_loss: 0.5202 - val_acc: 0.7041\n",
      "Epoch 535/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5298 - acc: 0.7321 - val_loss: 0.5197 - val_acc: 0.7041\n",
      "Epoch 536/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5296 - acc: 0.7321 - val_loss: 0.5195 - val_acc: 0.7041\n",
      "Epoch 537/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5293 - acc: 0.7321 - val_loss: 0.5197 - val_acc: 0.7041\n",
      "Epoch 538/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5294 - acc: 0.7296 - val_loss: 0.5199 - val_acc: 0.7041\n",
      "Epoch 539/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5293 - acc: 0.7296 - val_loss: 0.5202 - val_acc: 0.7143\n",
      "Epoch 540/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5294 - acc: 0.7296 - val_loss: 0.5204 - val_acc: 0.7245\n",
      "Epoch 541/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5294 - acc: 0.7296 - val_loss: 0.5203 - val_acc: 0.7245\n",
      "Epoch 542/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5292 - acc: 0.7296 - val_loss: 0.5203 - val_acc: 0.7245\n",
      "Epoch 543/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5292 - acc: 0.7296 - val_loss: 0.5205 - val_acc: 0.7347\n",
      "Epoch 544/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5291 - acc: 0.7270 - val_loss: 0.5203 - val_acc: 0.7347\n",
      "Epoch 545/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5290 - acc: 0.7270 - val_loss: 0.5205 - val_acc: 0.7347\n",
      "Epoch 546/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5290 - acc: 0.7270 - val_loss: 0.5209 - val_acc: 0.7347\n",
      "Epoch 547/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5290 - acc: 0.7270 - val_loss: 0.5207 - val_acc: 0.7347\n",
      "Epoch 548/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5288 - acc: 0.7270 - val_loss: 0.5204 - val_acc: 0.7347\n",
      "Epoch 549/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5286 - acc: 0.7270 - val_loss: 0.5205 - val_acc: 0.7347\n",
      "Epoch 550/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5286 - acc: 0.7270 - val_loss: 0.5202 - val_acc: 0.7347\n",
      "Epoch 551/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5284 - acc: 0.7270 - val_loss: 0.5194 - val_acc: 0.7245\n",
      "Epoch 552/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5277 - acc: 0.7270 - val_loss: 0.5184 - val_acc: 0.7143\n",
      "Epoch 553/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5273 - acc: 0.7296 - val_loss: 0.5173 - val_acc: 0.7041\n",
      "Epoch 554/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5271 - acc: 0.7372 - val_loss: 0.5160 - val_acc: 0.7245\n",
      "Epoch 555/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5264 - acc: 0.7423 - val_loss: 0.5150 - val_acc: 0.7245\n",
      "Epoch 556/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5264 - acc: 0.7423 - val_loss: 0.5141 - val_acc: 0.7245\n",
      "Epoch 557/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5263 - acc: 0.7449 - val_loss: 0.5134 - val_acc: 0.7347\n",
      "Epoch 558/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5266 - acc: 0.7423 - val_loss: 0.5131 - val_acc: 0.7347\n",
      "Epoch 559/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5270 - acc: 0.7423 - val_loss: 0.5129 - val_acc: 0.7347\n",
      "Epoch 560/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5270 - acc: 0.7449 - val_loss: 0.5128 - val_acc: 0.7347\n",
      "Epoch 561/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5268 - acc: 0.7449 - val_loss: 0.5128 - val_acc: 0.7347\n",
      "Epoch 562/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5265 - acc: 0.7423 - val_loss: 0.5129 - val_acc: 0.7347\n",
      "Epoch 563/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5260 - acc: 0.7423 - val_loss: 0.5133 - val_acc: 0.7245\n",
      "Epoch 564/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5251 - acc: 0.7398 - val_loss: 0.5141 - val_acc: 0.7245\n",
      "Epoch 565/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5252 - acc: 0.7372 - val_loss: 0.5147 - val_acc: 0.7245\n",
      "Epoch 566/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5252 - acc: 0.7398 - val_loss: 0.5153 - val_acc: 0.7245\n",
      "Epoch 567/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5251 - acc: 0.7347 - val_loss: 0.5157 - val_acc: 0.7143\n",
      "Epoch 568/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5253 - acc: 0.7296 - val_loss: 0.5163 - val_acc: 0.7143\n",
      "Epoch 569/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5253 - acc: 0.7296 - val_loss: 0.5161 - val_acc: 0.7143\n",
      "Epoch 570/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5251 - acc: 0.7296 - val_loss: 0.5160 - val_acc: 0.7143\n",
      "Epoch 571/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5251 - acc: 0.7296 - val_loss: 0.5159 - val_acc: 0.7143\n",
      "Epoch 572/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5248 - acc: 0.7296 - val_loss: 0.5147 - val_acc: 0.7245\n",
      "Epoch 573/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5245 - acc: 0.7296 - val_loss: 0.5137 - val_acc: 0.7245\n",
      "Epoch 574/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5240 - acc: 0.7347 - val_loss: 0.5132 - val_acc: 0.7245\n",
      "Epoch 575/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5238 - acc: 0.7372 - val_loss: 0.5128 - val_acc: 0.7245\n",
      "Epoch 576/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5237 - acc: 0.7372 - val_loss: 0.5126 - val_acc: 0.7245\n",
      "Epoch 577/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5235 - acc: 0.7372 - val_loss: 0.5125 - val_acc: 0.7245\n",
      "Epoch 578/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5234 - acc: 0.7372 - val_loss: 0.5125 - val_acc: 0.7245\n",
      "Epoch 579/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5233 - acc: 0.7372 - val_loss: 0.5130 - val_acc: 0.7245\n",
      "Epoch 580/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5232 - acc: 0.7372 - val_loss: 0.5135 - val_acc: 0.7347\n",
      "Epoch 581/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5234 - acc: 0.7321 - val_loss: 0.5142 - val_acc: 0.7245\n",
      "Epoch 582/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5235 - acc: 0.7296 - val_loss: 0.5143 - val_acc: 0.7245\n",
      "Epoch 583/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5234 - acc: 0.7296 - val_loss: 0.5140 - val_acc: 0.7245\n",
      "Epoch 584/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5231 - acc: 0.7296 - val_loss: 0.5135 - val_acc: 0.7245\n",
      "Epoch 585/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5229 - acc: 0.7296 - val_loss: 0.5129 - val_acc: 0.7245\n",
      "Epoch 586/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5226 - acc: 0.7321 - val_loss: 0.5123 - val_acc: 0.7347\n",
      "Epoch 587/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5224 - acc: 0.7321 - val_loss: 0.5123 - val_acc: 0.7347\n",
      "Epoch 588/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5223 - acc: 0.7321 - val_loss: 0.5123 - val_acc: 0.7245\n",
      "Epoch 589/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5223 - acc: 0.7321 - val_loss: 0.5124 - val_acc: 0.7245\n",
      "Epoch 590/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5222 - acc: 0.7321 - val_loss: 0.5124 - val_acc: 0.7245\n",
      "Epoch 591/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5222 - acc: 0.7321 - val_loss: 0.5127 - val_acc: 0.7245\n",
      "Epoch 592/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5222 - acc: 0.7270 - val_loss: 0.5129 - val_acc: 0.7347\n",
      "Epoch 593/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5221 - acc: 0.7296 - val_loss: 0.5125 - val_acc: 0.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5218 - acc: 0.7296 - val_loss: 0.5117 - val_acc: 0.7245\n",
      "Epoch 595/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5215 - acc: 0.7321 - val_loss: 0.5107 - val_acc: 0.7347\n",
      "Epoch 596/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5210 - acc: 0.7321 - val_loss: 0.5098 - val_acc: 0.7245\n",
      "Epoch 597/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5208 - acc: 0.7347 - val_loss: 0.5089 - val_acc: 0.7245\n",
      "Epoch 598/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5203 - acc: 0.7347 - val_loss: 0.5081 - val_acc: 0.7245\n",
      "Epoch 599/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.5204 - acc: 0.7474 - val_loss: 0.5074 - val_acc: 0.7245\n",
      "Epoch 600/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5204 - acc: 0.7423 - val_loss: 0.5070 - val_acc: 0.7245\n",
      "Epoch 601/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5204 - acc: 0.7500 - val_loss: 0.5068 - val_acc: 0.7245\n",
      "Epoch 602/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5204 - acc: 0.7474 - val_loss: 0.5067 - val_acc: 0.7245\n",
      "Epoch 603/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5203 - acc: 0.7474 - val_loss: 0.5066 - val_acc: 0.7245\n",
      "Epoch 604/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5201 - acc: 0.7500 - val_loss: 0.5067 - val_acc: 0.7245\n",
      "Epoch 605/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5198 - acc: 0.7449 - val_loss: 0.5068 - val_acc: 0.7245\n",
      "Epoch 606/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5197 - acc: 0.7449 - val_loss: 0.5069 - val_acc: 0.7245\n",
      "Epoch 607/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5196 - acc: 0.7449 - val_loss: 0.5070 - val_acc: 0.7245\n",
      "Epoch 608/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5193 - acc: 0.7474 - val_loss: 0.5072 - val_acc: 0.7245\n",
      "Epoch 609/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5192 - acc: 0.7398 - val_loss: 0.5076 - val_acc: 0.7245\n",
      "Epoch 610/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5190 - acc: 0.7372 - val_loss: 0.5076 - val_acc: 0.7245\n",
      "Epoch 611/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5189 - acc: 0.7372 - val_loss: 0.5074 - val_acc: 0.7245\n",
      "Epoch 612/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5188 - acc: 0.7372 - val_loss: 0.5069 - val_acc: 0.7245\n",
      "Epoch 613/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5187 - acc: 0.7449 - val_loss: 0.5065 - val_acc: 0.7245\n",
      "Epoch 614/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5185 - acc: 0.7474 - val_loss: 0.5060 - val_acc: 0.7245\n",
      "Epoch 615/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5184 - acc: 0.7449 - val_loss: 0.5054 - val_acc: 0.7245\n",
      "Epoch 616/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.5187 - acc: 0.7500 - val_loss: 0.5049 - val_acc: 0.7245\n",
      "Epoch 617/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5188 - acc: 0.7526 - val_loss: 0.5046 - val_acc: 0.7449\n",
      "Epoch 618/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5190 - acc: 0.7526 - val_loss: 0.5045 - val_acc: 0.7449\n",
      "Epoch 619/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5189 - acc: 0.7526 - val_loss: 0.5045 - val_acc: 0.7245\n",
      "Epoch 620/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5187 - acc: 0.7526 - val_loss: 0.5044 - val_acc: 0.7245\n",
      "Epoch 621/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5186 - acc: 0.7551 - val_loss: 0.5043 - val_acc: 0.7245\n",
      "Epoch 622/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5183 - acc: 0.7551 - val_loss: 0.5044 - val_acc: 0.7245\n",
      "Epoch 623/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5180 - acc: 0.7526 - val_loss: 0.5044 - val_acc: 0.7245\n",
      "Epoch 624/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5177 - acc: 0.7577 - val_loss: 0.5045 - val_acc: 0.7245\n",
      "Epoch 625/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5175 - acc: 0.7449 - val_loss: 0.5046 - val_acc: 0.7245\n",
      "Epoch 626/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5173 - acc: 0.7449 - val_loss: 0.5043 - val_acc: 0.7245\n",
      "Epoch 627/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5172 - acc: 0.7474 - val_loss: 0.5040 - val_acc: 0.7245\n",
      "Epoch 628/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5171 - acc: 0.7500 - val_loss: 0.5040 - val_acc: 0.7245\n",
      "Epoch 629/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5169 - acc: 0.7474 - val_loss: 0.5038 - val_acc: 0.7245\n",
      "Epoch 630/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5169 - acc: 0.7551 - val_loss: 0.5035 - val_acc: 0.7245\n",
      "Epoch 631/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5169 - acc: 0.7551 - val_loss: 0.5032 - val_acc: 0.7245\n",
      "Epoch 632/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5169 - acc: 0.7526 - val_loss: 0.5030 - val_acc: 0.7245\n",
      "Epoch 633/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5168 - acc: 0.7551 - val_loss: 0.5029 - val_acc: 0.7245\n",
      "Epoch 634/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5167 - acc: 0.7526 - val_loss: 0.5027 - val_acc: 0.7245\n",
      "Epoch 635/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5164 - acc: 0.7551 - val_loss: 0.5029 - val_acc: 0.7245\n",
      "Epoch 636/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5161 - acc: 0.7577 - val_loss: 0.5032 - val_acc: 0.7245\n",
      "Epoch 637/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5158 - acc: 0.7449 - val_loss: 0.5035 - val_acc: 0.7245\n",
      "Epoch 638/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5158 - acc: 0.7474 - val_loss: 0.5039 - val_acc: 0.7245\n",
      "Epoch 639/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5157 - acc: 0.7398 - val_loss: 0.5043 - val_acc: 0.7245\n",
      "Epoch 640/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5156 - acc: 0.7347 - val_loss: 0.5048 - val_acc: 0.7347\n",
      "Epoch 641/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5155 - acc: 0.7372 - val_loss: 0.5051 - val_acc: 0.7347\n",
      "Epoch 642/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5157 - acc: 0.7372 - val_loss: 0.5058 - val_acc: 0.7347\n",
      "Epoch 643/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5156 - acc: 0.7347 - val_loss: 0.5064 - val_acc: 0.7449\n",
      "Epoch 644/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5158 - acc: 0.7347 - val_loss: 0.5067 - val_acc: 0.7449\n",
      "Epoch 645/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5160 - acc: 0.7347 - val_loss: 0.5068 - val_acc: 0.7449\n",
      "Epoch 646/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5158 - acc: 0.7347 - val_loss: 0.5065 - val_acc: 0.7449\n",
      "Epoch 647/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5156 - acc: 0.7347 - val_loss: 0.5070 - val_acc: 0.7347\n",
      "Epoch 648/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5158 - acc: 0.7372 - val_loss: 0.5074 - val_acc: 0.7347\n",
      "Epoch 649/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5158 - acc: 0.7372 - val_loss: 0.5069 - val_acc: 0.7347\n",
      "Epoch 650/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5154 - acc: 0.7372 - val_loss: 0.5059 - val_acc: 0.7449\n",
      "Epoch 651/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5150 - acc: 0.7372 - val_loss: 0.5053 - val_acc: 0.7347\n",
      "Epoch 652/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5148 - acc: 0.7372 - val_loss: 0.5052 - val_acc: 0.7347\n",
      "Epoch 653/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5147 - acc: 0.7372 - val_loss: 0.5050 - val_acc: 0.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 654/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5143 - acc: 0.7347 - val_loss: 0.5041 - val_acc: 0.7347\n",
      "Epoch 655/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5143 - acc: 0.7372 - val_loss: 0.5031 - val_acc: 0.7245\n",
      "Epoch 656/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5138 - acc: 0.7423 - val_loss: 0.5023 - val_acc: 0.7245\n",
      "Epoch 657/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5137 - acc: 0.7423 - val_loss: 0.5020 - val_acc: 0.7245\n",
      "Epoch 658/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5136 - acc: 0.7449 - val_loss: 0.5017 - val_acc: 0.7245\n",
      "Epoch 659/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5135 - acc: 0.7449 - val_loss: 0.5015 - val_acc: 0.7245\n",
      "Epoch 660/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5135 - acc: 0.7449 - val_loss: 0.5011 - val_acc: 0.7245\n",
      "Epoch 661/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5133 - acc: 0.7449 - val_loss: 0.5010 - val_acc: 0.7245\n",
      "Epoch 662/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5132 - acc: 0.7449 - val_loss: 0.5009 - val_acc: 0.7245\n",
      "Epoch 663/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5131 - acc: 0.7449 - val_loss: 0.5008 - val_acc: 0.7245\n",
      "Epoch 664/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5130 - acc: 0.7449 - val_loss: 0.5007 - val_acc: 0.7245\n",
      "Epoch 665/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5130 - acc: 0.7474 - val_loss: 0.5009 - val_acc: 0.7245\n",
      "Epoch 666/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5128 - acc: 0.7449 - val_loss: 0.5008 - val_acc: 0.7245\n",
      "Epoch 667/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5127 - acc: 0.7449 - val_loss: 0.5006 - val_acc: 0.7245\n",
      "Epoch 668/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5127 - acc: 0.7526 - val_loss: 0.5001 - val_acc: 0.7245\n",
      "Epoch 669/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5128 - acc: 0.7602 - val_loss: 0.4999 - val_acc: 0.7245\n",
      "Epoch 670/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5127 - acc: 0.7602 - val_loss: 0.4999 - val_acc: 0.7245\n",
      "Epoch 671/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5126 - acc: 0.7602 - val_loss: 0.5001 - val_acc: 0.7245\n",
      "Epoch 672/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5123 - acc: 0.7526 - val_loss: 0.5000 - val_acc: 0.7245\n",
      "Epoch 673/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5121 - acc: 0.7500 - val_loss: 0.4997 - val_acc: 0.7245\n",
      "Epoch 674/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5121 - acc: 0.7602 - val_loss: 0.4995 - val_acc: 0.7245\n",
      "Epoch 675/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5121 - acc: 0.7602 - val_loss: 0.4993 - val_acc: 0.7245\n",
      "Epoch 676/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5120 - acc: 0.7602 - val_loss: 0.4994 - val_acc: 0.7245\n",
      "Epoch 677/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5117 - acc: 0.7577 - val_loss: 0.4997 - val_acc: 0.7245\n",
      "Epoch 678/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5115 - acc: 0.7500 - val_loss: 0.5001 - val_acc: 0.7245\n",
      "Epoch 679/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5115 - acc: 0.7474 - val_loss: 0.5002 - val_acc: 0.7245\n",
      "Epoch 680/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5113 - acc: 0.7449 - val_loss: 0.5003 - val_acc: 0.7245\n",
      "Epoch 681/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5112 - acc: 0.7449 - val_loss: 0.4999 - val_acc: 0.7245\n",
      "Epoch 682/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5112 - acc: 0.7474 - val_loss: 0.4994 - val_acc: 0.7245\n",
      "Epoch 683/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5110 - acc: 0.7577 - val_loss: 0.4991 - val_acc: 0.7245\n",
      "Epoch 684/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5110 - acc: 0.7602 - val_loss: 0.4990 - val_acc: 0.7245\n",
      "Epoch 685/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5109 - acc: 0.7602 - val_loss: 0.4990 - val_acc: 0.7245\n",
      "Epoch 686/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5108 - acc: 0.7653 - val_loss: 0.4988 - val_acc: 0.7245\n",
      "Epoch 687/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5108 - acc: 0.7577 - val_loss: 0.4990 - val_acc: 0.7245\n",
      "Epoch 688/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5105 - acc: 0.7551 - val_loss: 0.4991 - val_acc: 0.7245\n",
      "Epoch 689/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5104 - acc: 0.7526 - val_loss: 0.4992 - val_acc: 0.7245\n",
      "Epoch 690/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5104 - acc: 0.7474 - val_loss: 0.4992 - val_acc: 0.7245\n",
      "Epoch 691/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5102 - acc: 0.7474 - val_loss: 0.4989 - val_acc: 0.7245\n",
      "Epoch 692/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5101 - acc: 0.7526 - val_loss: 0.4989 - val_acc: 0.7245\n",
      "Epoch 693/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5100 - acc: 0.7500 - val_loss: 0.4987 - val_acc: 0.7245\n",
      "Epoch 694/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5099 - acc: 0.7526 - val_loss: 0.4984 - val_acc: 0.7245\n",
      "Epoch 695/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5098 - acc: 0.7551 - val_loss: 0.4979 - val_acc: 0.7245\n",
      "Epoch 696/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5098 - acc: 0.7602 - val_loss: 0.4976 - val_acc: 0.7245\n",
      "Epoch 697/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5097 - acc: 0.7628 - val_loss: 0.4975 - val_acc: 0.7245\n",
      "Epoch 698/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5096 - acc: 0.7628 - val_loss: 0.4974 - val_acc: 0.7245\n",
      "Epoch 699/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5095 - acc: 0.7628 - val_loss: 0.4974 - val_acc: 0.7245\n",
      "Epoch 700/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5093 - acc: 0.7551 - val_loss: 0.4976 - val_acc: 0.7245\n",
      "Epoch 701/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5092 - acc: 0.7577 - val_loss: 0.4979 - val_acc: 0.7245\n",
      "Epoch 702/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5090 - acc: 0.7551 - val_loss: 0.4977 - val_acc: 0.7245\n",
      "Epoch 703/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5089 - acc: 0.7577 - val_loss: 0.4974 - val_acc: 0.7245\n",
      "Epoch 704/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5088 - acc: 0.7602 - val_loss: 0.4970 - val_acc: 0.7245\n",
      "Epoch 705/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5087 - acc: 0.7628 - val_loss: 0.4966 - val_acc: 0.7245\n",
      "Epoch 706/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5087 - acc: 0.7628 - val_loss: 0.4965 - val_acc: 0.7245\n",
      "Epoch 707/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5087 - acc: 0.7628 - val_loss: 0.4963 - val_acc: 0.7245\n",
      "Epoch 708/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5086 - acc: 0.7628 - val_loss: 0.4964 - val_acc: 0.7245\n",
      "Epoch 709/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5085 - acc: 0.7628 - val_loss: 0.4968 - val_acc: 0.7245\n",
      "Epoch 710/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5082 - acc: 0.7602 - val_loss: 0.4967 - val_acc: 0.7245\n",
      "Epoch 711/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5082 - acc: 0.7577 - val_loss: 0.4964 - val_acc: 0.7245\n",
      "Epoch 712/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5081 - acc: 0.7602 - val_loss: 0.4961 - val_acc: 0.7245\n",
      "Epoch 713/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5081 - acc: 0.7653 - val_loss: 0.4958 - val_acc: 0.7245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 714/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5082 - acc: 0.7730 - val_loss: 0.4956 - val_acc: 0.7245\n",
      "Epoch 715/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5083 - acc: 0.7730 - val_loss: 0.4955 - val_acc: 0.7245\n",
      "Epoch 716/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5081 - acc: 0.7730 - val_loss: 0.4956 - val_acc: 0.7245\n",
      "Epoch 717/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5079 - acc: 0.7704 - val_loss: 0.4955 - val_acc: 0.7245\n",
      "Epoch 718/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5080 - acc: 0.7730 - val_loss: 0.4953 - val_acc: 0.7245\n",
      "Epoch 719/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5079 - acc: 0.7730 - val_loss: 0.4953 - val_acc: 0.7245\n",
      "Epoch 720/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5077 - acc: 0.7730 - val_loss: 0.4953 - val_acc: 0.7245\n",
      "Epoch 721/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5075 - acc: 0.7730 - val_loss: 0.4953 - val_acc: 0.7245\n",
      "Epoch 722/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5074 - acc: 0.7730 - val_loss: 0.4953 - val_acc: 0.7245\n",
      "Epoch 723/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5073 - acc: 0.7730 - val_loss: 0.4953 - val_acc: 0.7245\n",
      "Epoch 724/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5071 - acc: 0.7653 - val_loss: 0.4955 - val_acc: 0.7245\n",
      "Epoch 725/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5069 - acc: 0.7653 - val_loss: 0.4952 - val_acc: 0.7245\n",
      "Epoch 726/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5068 - acc: 0.7730 - val_loss: 0.4951 - val_acc: 0.7245\n",
      "Epoch 727/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5068 - acc: 0.7704 - val_loss: 0.4951 - val_acc: 0.7245\n",
      "Epoch 728/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5066 - acc: 0.7628 - val_loss: 0.4954 - val_acc: 0.7245\n",
      "Epoch 729/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5063 - acc: 0.7602 - val_loss: 0.4956 - val_acc: 0.7245\n",
      "Epoch 730/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5061 - acc: 0.7602 - val_loss: 0.4957 - val_acc: 0.7245\n",
      "Epoch 731/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5061 - acc: 0.7577 - val_loss: 0.4956 - val_acc: 0.7245\n",
      "Epoch 732/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5060 - acc: 0.7602 - val_loss: 0.4953 - val_acc: 0.7245\n",
      "Epoch 733/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5060 - acc: 0.7602 - val_loss: 0.4951 - val_acc: 0.7245\n",
      "Epoch 734/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5059 - acc: 0.7602 - val_loss: 0.4951 - val_acc: 0.7245\n",
      "Epoch 735/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5057 - acc: 0.7602 - val_loss: 0.4951 - val_acc: 0.7245\n",
      "Epoch 736/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5056 - acc: 0.7602 - val_loss: 0.4950 - val_acc: 0.7245\n",
      "Epoch 737/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5055 - acc: 0.7602 - val_loss: 0.4949 - val_acc: 0.7245\n",
      "Epoch 738/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5055 - acc: 0.7602 - val_loss: 0.4947 - val_acc: 0.7245\n",
      "Epoch 739/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5054 - acc: 0.7628 - val_loss: 0.4944 - val_acc: 0.7245\n",
      "Epoch 740/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5059 - acc: 0.7704 - val_loss: 0.4938 - val_acc: 0.7347\n",
      "Epoch 741/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5059 - acc: 0.7704 - val_loss: 0.4935 - val_acc: 0.7347\n",
      "Epoch 742/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5064 - acc: 0.7730 - val_loss: 0.4932 - val_acc: 0.7347\n",
      "Epoch 743/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5069 - acc: 0.7628 - val_loss: 0.4930 - val_acc: 0.7653\n",
      "Epoch 744/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5071 - acc: 0.7628 - val_loss: 0.4929 - val_acc: 0.7653\n",
      "Epoch 745/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5072 - acc: 0.7628 - val_loss: 0.4928 - val_acc: 0.7653\n",
      "Epoch 746/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5069 - acc: 0.7628 - val_loss: 0.4927 - val_acc: 0.7653\n",
      "Epoch 747/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5067 - acc: 0.7653 - val_loss: 0.4926 - val_acc: 0.7449\n",
      "Epoch 748/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5063 - acc: 0.7679 - val_loss: 0.4925 - val_acc: 0.7347\n",
      "Epoch 749/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5059 - acc: 0.7730 - val_loss: 0.4925 - val_acc: 0.7347\n",
      "Epoch 750/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5056 - acc: 0.7730 - val_loss: 0.4926 - val_acc: 0.7347\n",
      "Epoch 751/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5053 - acc: 0.7730 - val_loss: 0.4928 - val_acc: 0.7347\n",
      "Epoch 752/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5045 - acc: 0.7730 - val_loss: 0.4931 - val_acc: 0.7245\n",
      "Epoch 753/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5042 - acc: 0.7704 - val_loss: 0.4931 - val_acc: 0.7245\n",
      "Epoch 754/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5041 - acc: 0.7704 - val_loss: 0.4927 - val_acc: 0.7245\n",
      "Epoch 755/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5045 - acc: 0.7704 - val_loss: 0.4924 - val_acc: 0.7347\n",
      "Epoch 756/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5045 - acc: 0.7730 - val_loss: 0.4924 - val_acc: 0.7347\n",
      "Epoch 757/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5043 - acc: 0.7704 - val_loss: 0.4923 - val_acc: 0.7347\n",
      "Epoch 758/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5043 - acc: 0.7730 - val_loss: 0.4921 - val_acc: 0.7347\n",
      "Epoch 759/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5043 - acc: 0.7755 - val_loss: 0.4920 - val_acc: 0.7347\n",
      "Epoch 760/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5040 - acc: 0.7730 - val_loss: 0.4922 - val_acc: 0.7347\n",
      "Epoch 761/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5038 - acc: 0.7755 - val_loss: 0.4923 - val_acc: 0.7245\n",
      "Epoch 762/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5034 - acc: 0.7730 - val_loss: 0.4929 - val_acc: 0.7245\n",
      "Epoch 763/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5032 - acc: 0.7628 - val_loss: 0.4933 - val_acc: 0.7245\n",
      "Epoch 764/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5030 - acc: 0.7602 - val_loss: 0.4936 - val_acc: 0.7347\n",
      "Epoch 765/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5028 - acc: 0.7577 - val_loss: 0.4940 - val_acc: 0.7347\n",
      "Epoch 766/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5028 - acc: 0.7526 - val_loss: 0.4942 - val_acc: 0.7347\n",
      "Epoch 767/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5027 - acc: 0.7551 - val_loss: 0.4942 - val_acc: 0.7347\n",
      "Epoch 768/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5026 - acc: 0.7551 - val_loss: 0.4946 - val_acc: 0.7347\n",
      "Epoch 769/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5025 - acc: 0.7500 - val_loss: 0.4951 - val_acc: 0.7347\n",
      "Epoch 770/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5026 - acc: 0.7449 - val_loss: 0.4953 - val_acc: 0.7449\n",
      "Epoch 771/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5026 - acc: 0.7474 - val_loss: 0.4948 - val_acc: 0.7347\n",
      "Epoch 772/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5023 - acc: 0.7474 - val_loss: 0.4942 - val_acc: 0.7347\n",
      "Epoch 773/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5021 - acc: 0.7526 - val_loss: 0.4937 - val_acc: 0.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5021 - acc: 0.7526 - val_loss: 0.4932 - val_acc: 0.7347\n",
      "Epoch 775/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5020 - acc: 0.7602 - val_loss: 0.4928 - val_acc: 0.7245\n",
      "Epoch 776/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5019 - acc: 0.7628 - val_loss: 0.4925 - val_acc: 0.7245\n",
      "Epoch 777/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5019 - acc: 0.7628 - val_loss: 0.4922 - val_acc: 0.7245\n",
      "Epoch 778/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5019 - acc: 0.7653 - val_loss: 0.4918 - val_acc: 0.7245\n",
      "Epoch 779/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5019 - acc: 0.7704 - val_loss: 0.4914 - val_acc: 0.7347\n",
      "Epoch 780/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5020 - acc: 0.7730 - val_loss: 0.4912 - val_acc: 0.7347\n",
      "Epoch 781/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5019 - acc: 0.7730 - val_loss: 0.4912 - val_acc: 0.7347\n",
      "Epoch 782/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5017 - acc: 0.7755 - val_loss: 0.4915 - val_acc: 0.7245\n",
      "Epoch 783/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5017 - acc: 0.7653 - val_loss: 0.4922 - val_acc: 0.7347\n",
      "Epoch 784/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5011 - acc: 0.7602 - val_loss: 0.4927 - val_acc: 0.7347\n",
      "Epoch 785/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5011 - acc: 0.7577 - val_loss: 0.4933 - val_acc: 0.7347\n",
      "Epoch 786/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5011 - acc: 0.7526 - val_loss: 0.4936 - val_acc: 0.7347\n",
      "Epoch 787/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5011 - acc: 0.7474 - val_loss: 0.4941 - val_acc: 0.7449\n",
      "Epoch 788/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5012 - acc: 0.7423 - val_loss: 0.4946 - val_acc: 0.7449\n",
      "Epoch 789/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5012 - acc: 0.7423 - val_loss: 0.4945 - val_acc: 0.7449\n",
      "Epoch 790/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5010 - acc: 0.7423 - val_loss: 0.4941 - val_acc: 0.7449\n",
      "Epoch 791/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5009 - acc: 0.7423 - val_loss: 0.4942 - val_acc: 0.7449\n",
      "Epoch 792/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5009 - acc: 0.7423 - val_loss: 0.4943 - val_acc: 0.7449\n",
      "Epoch 793/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5009 - acc: 0.7449 - val_loss: 0.4946 - val_acc: 0.7449\n",
      "Epoch 794/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5009 - acc: 0.7449 - val_loss: 0.4946 - val_acc: 0.7449\n",
      "Epoch 795/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5009 - acc: 0.7449 - val_loss: 0.4940 - val_acc: 0.7449\n",
      "Epoch 796/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5005 - acc: 0.7423 - val_loss: 0.4940 - val_acc: 0.7449\n",
      "Epoch 797/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5005 - acc: 0.7449 - val_loss: 0.4942 - val_acc: 0.7449\n",
      "Epoch 798/1500\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.5004 - acc: 0.7449 - val_loss: 0.4938 - val_acc: 0.7449\n",
      "Epoch 799/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5002 - acc: 0.7423 - val_loss: 0.4932 - val_acc: 0.7449\n",
      "Epoch 800/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5000 - acc: 0.7474 - val_loss: 0.4928 - val_acc: 0.7449\n",
      "Epoch 801/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4999 - acc: 0.7500 - val_loss: 0.4929 - val_acc: 0.7449\n",
      "Epoch 802/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4998 - acc: 0.7474 - val_loss: 0.4928 - val_acc: 0.7449\n",
      "Epoch 803/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4998 - acc: 0.7500 - val_loss: 0.4927 - val_acc: 0.7449\n",
      "Epoch 804/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4997 - acc: 0.7474 - val_loss: 0.4927 - val_acc: 0.7449\n",
      "Epoch 805/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4996 - acc: 0.7500 - val_loss: 0.4923 - val_acc: 0.7347\n",
      "Epoch 806/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4994 - acc: 0.7500 - val_loss: 0.4917 - val_acc: 0.7347\n",
      "Epoch 807/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4993 - acc: 0.7602 - val_loss: 0.4909 - val_acc: 0.7347\n",
      "Epoch 808/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.4993 - acc: 0.7653 - val_loss: 0.4903 - val_acc: 0.7245\n",
      "Epoch 809/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4991 - acc: 0.7704 - val_loss: 0.4899 - val_acc: 0.7245\n",
      "Epoch 810/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4994 - acc: 0.7730 - val_loss: 0.4894 - val_acc: 0.7347\n",
      "Epoch 811/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4994 - acc: 0.7730 - val_loss: 0.4890 - val_acc: 0.7347\n",
      "Epoch 812/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4996 - acc: 0.7755 - val_loss: 0.4888 - val_acc: 0.7347\n",
      "Epoch 813/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4993 - acc: 0.7781 - val_loss: 0.4888 - val_acc: 0.7347\n",
      "Epoch 814/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4993 - acc: 0.7781 - val_loss: 0.4886 - val_acc: 0.7449\n",
      "Epoch 815/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4994 - acc: 0.7781 - val_loss: 0.4884 - val_acc: 0.7449\n",
      "Epoch 816/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4995 - acc: 0.7781 - val_loss: 0.4883 - val_acc: 0.7449\n",
      "Epoch 817/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4994 - acc: 0.7781 - val_loss: 0.4885 - val_acc: 0.7449\n",
      "Epoch 818/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4989 - acc: 0.7781 - val_loss: 0.4888 - val_acc: 0.7347\n",
      "Epoch 819/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4984 - acc: 0.7730 - val_loss: 0.4890 - val_acc: 0.7347\n",
      "Epoch 820/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4984 - acc: 0.7730 - val_loss: 0.4889 - val_acc: 0.7347\n",
      "Epoch 821/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4983 - acc: 0.7730 - val_loss: 0.4886 - val_acc: 0.7347\n",
      "Epoch 822/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4982 - acc: 0.7704 - val_loss: 0.4884 - val_acc: 0.7347\n",
      "Epoch 823/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4985 - acc: 0.7730 - val_loss: 0.4879 - val_acc: 0.7449\n",
      "Epoch 824/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4985 - acc: 0.7806 - val_loss: 0.4877 - val_acc: 0.7449\n",
      "Epoch 825/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4984 - acc: 0.7781 - val_loss: 0.4877 - val_acc: 0.7449\n",
      "Epoch 826/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4983 - acc: 0.7806 - val_loss: 0.4876 - val_acc: 0.7449\n",
      "Epoch 827/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4982 - acc: 0.7806 - val_loss: 0.4876 - val_acc: 0.7449\n",
      "Epoch 828/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4981 - acc: 0.7806 - val_loss: 0.4877 - val_acc: 0.7449\n",
      "Epoch 829/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4977 - acc: 0.7704 - val_loss: 0.4881 - val_acc: 0.7347\n",
      "Epoch 830/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4974 - acc: 0.7730 - val_loss: 0.4886 - val_acc: 0.7347\n",
      "Epoch 831/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4974 - acc: 0.7704 - val_loss: 0.4889 - val_acc: 0.7347\n",
      "Epoch 832/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4973 - acc: 0.7679 - val_loss: 0.4885 - val_acc: 0.7347\n",
      "Epoch 833/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4973 - acc: 0.7730 - val_loss: 0.4879 - val_acc: 0.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4973 - acc: 0.7704 - val_loss: 0.4875 - val_acc: 0.7449\n",
      "Epoch 835/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4976 - acc: 0.7755 - val_loss: 0.4873 - val_acc: 0.7449\n",
      "Epoch 836/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4975 - acc: 0.7755 - val_loss: 0.4872 - val_acc: 0.7449\n",
      "Epoch 837/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4974 - acc: 0.7781 - val_loss: 0.4872 - val_acc: 0.7449\n",
      "Epoch 838/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4973 - acc: 0.7781 - val_loss: 0.4873 - val_acc: 0.7449\n",
      "Epoch 839/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4971 - acc: 0.7730 - val_loss: 0.4877 - val_acc: 0.7347\n",
      "Epoch 840/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4970 - acc: 0.7730 - val_loss: 0.4880 - val_acc: 0.7449\n",
      "Epoch 841/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4967 - acc: 0.7730 - val_loss: 0.4881 - val_acc: 0.7449\n",
      "Epoch 842/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4966 - acc: 0.7730 - val_loss: 0.4881 - val_acc: 0.7449\n",
      "Epoch 843/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4966 - acc: 0.7730 - val_loss: 0.4877 - val_acc: 0.7449\n",
      "Epoch 844/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4965 - acc: 0.7730 - val_loss: 0.4876 - val_acc: 0.7449\n",
      "Epoch 845/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4964 - acc: 0.7730 - val_loss: 0.4874 - val_acc: 0.7449\n",
      "Epoch 846/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4964 - acc: 0.7730 - val_loss: 0.4873 - val_acc: 0.7449\n",
      "Epoch 847/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4963 - acc: 0.7704 - val_loss: 0.4872 - val_acc: 0.7551\n",
      "Epoch 848/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4962 - acc: 0.7704 - val_loss: 0.4871 - val_acc: 0.7551\n",
      "Epoch 849/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4962 - acc: 0.7704 - val_loss: 0.4876 - val_acc: 0.7449\n",
      "Epoch 850/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4959 - acc: 0.7730 - val_loss: 0.4879 - val_acc: 0.7347\n",
      "Epoch 851/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4959 - acc: 0.7653 - val_loss: 0.4882 - val_acc: 0.7347\n",
      "Epoch 852/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4959 - acc: 0.7602 - val_loss: 0.4887 - val_acc: 0.7449\n",
      "Epoch 853/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4958 - acc: 0.7577 - val_loss: 0.4888 - val_acc: 0.7449\n",
      "Epoch 854/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4957 - acc: 0.7474 - val_loss: 0.4888 - val_acc: 0.7449\n",
      "Epoch 855/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4957 - acc: 0.7474 - val_loss: 0.4885 - val_acc: 0.7449\n",
      "Epoch 856/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4956 - acc: 0.7577 - val_loss: 0.4886 - val_acc: 0.7449\n",
      "Epoch 857/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4955 - acc: 0.7526 - val_loss: 0.4887 - val_acc: 0.7449\n",
      "Epoch 858/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4954 - acc: 0.7577 - val_loss: 0.4886 - val_acc: 0.7449\n",
      "Epoch 859/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4954 - acc: 0.7551 - val_loss: 0.4888 - val_acc: 0.7449\n",
      "Epoch 860/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4953 - acc: 0.7551 - val_loss: 0.4888 - val_acc: 0.7449\n",
      "Epoch 861/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4952 - acc: 0.7551 - val_loss: 0.4890 - val_acc: 0.7449\n",
      "Epoch 862/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4952 - acc: 0.7449 - val_loss: 0.4891 - val_acc: 0.7449\n",
      "Epoch 863/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4951 - acc: 0.7474 - val_loss: 0.4889 - val_acc: 0.7449\n",
      "Epoch 864/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4951 - acc: 0.7474 - val_loss: 0.4891 - val_acc: 0.7449\n",
      "Epoch 865/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.4950 - acc: 0.7449 - val_loss: 0.4888 - val_acc: 0.7449\n",
      "Epoch 866/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4949 - acc: 0.7526 - val_loss: 0.4881 - val_acc: 0.7449\n",
      "Epoch 867/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4946 - acc: 0.7628 - val_loss: 0.4874 - val_acc: 0.7347\n",
      "Epoch 868/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4948 - acc: 0.7704 - val_loss: 0.4869 - val_acc: 0.7449\n",
      "Epoch 869/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4947 - acc: 0.7704 - val_loss: 0.4864 - val_acc: 0.7551\n",
      "Epoch 870/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4947 - acc: 0.7730 - val_loss: 0.4861 - val_acc: 0.7449\n",
      "Epoch 871/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4947 - acc: 0.7755 - val_loss: 0.4859 - val_acc: 0.7449\n",
      "Epoch 872/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4947 - acc: 0.7755 - val_loss: 0.4857 - val_acc: 0.7449\n",
      "Epoch 873/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4948 - acc: 0.7755 - val_loss: 0.4854 - val_acc: 0.7449\n",
      "Epoch 874/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4948 - acc: 0.7755 - val_loss: 0.4854 - val_acc: 0.7449\n",
      "Epoch 875/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4946 - acc: 0.7755 - val_loss: 0.4853 - val_acc: 0.7449\n",
      "Epoch 876/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4945 - acc: 0.7755 - val_loss: 0.4855 - val_acc: 0.7449\n",
      "Epoch 877/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4943 - acc: 0.7755 - val_loss: 0.4861 - val_acc: 0.7551\n",
      "Epoch 878/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4940 - acc: 0.7730 - val_loss: 0.4867 - val_acc: 0.7347\n",
      "Epoch 879/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4939 - acc: 0.7679 - val_loss: 0.4871 - val_acc: 0.7449\n",
      "Epoch 880/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4938 - acc: 0.7628 - val_loss: 0.4875 - val_acc: 0.7449\n",
      "Epoch 881/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4937 - acc: 0.7628 - val_loss: 0.4880 - val_acc: 0.7449\n",
      "Epoch 882/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4938 - acc: 0.7474 - val_loss: 0.4886 - val_acc: 0.7449\n",
      "Epoch 883/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4938 - acc: 0.7423 - val_loss: 0.4890 - val_acc: 0.7449\n",
      "Epoch 884/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4938 - acc: 0.7449 - val_loss: 0.4894 - val_acc: 0.7449\n",
      "Epoch 885/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4938 - acc: 0.7423 - val_loss: 0.4895 - val_acc: 0.7449\n",
      "Epoch 886/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4938 - acc: 0.7423 - val_loss: 0.4892 - val_acc: 0.7449\n",
      "Epoch 887/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4936 - acc: 0.7449 - val_loss: 0.4887 - val_acc: 0.7449\n",
      "Epoch 888/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4934 - acc: 0.7474 - val_loss: 0.4882 - val_acc: 0.7449\n",
      "Epoch 889/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4933 - acc: 0.7551 - val_loss: 0.4877 - val_acc: 0.7449\n",
      "Epoch 890/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4931 - acc: 0.7602 - val_loss: 0.4874 - val_acc: 0.7449\n",
      "Epoch 891/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4930 - acc: 0.7628 - val_loss: 0.4873 - val_acc: 0.7449\n",
      "Epoch 892/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4930 - acc: 0.7628 - val_loss: 0.4875 - val_acc: 0.7449\n",
      "Epoch 893/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4929 - acc: 0.7577 - val_loss: 0.4877 - val_acc: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4929 - acc: 0.7602 - val_loss: 0.4871 - val_acc: 0.7449\n",
      "Epoch 895/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4926 - acc: 0.7653 - val_loss: 0.4861 - val_acc: 0.7551\n",
      "Epoch 896/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4927 - acc: 0.7704 - val_loss: 0.4851 - val_acc: 0.7551\n",
      "Epoch 897/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4928 - acc: 0.7755 - val_loss: 0.4845 - val_acc: 0.7449\n",
      "Epoch 898/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4927 - acc: 0.7755 - val_loss: 0.4844 - val_acc: 0.7449\n",
      "Epoch 899/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4927 - acc: 0.7755 - val_loss: 0.4842 - val_acc: 0.7449\n",
      "Epoch 900/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4928 - acc: 0.7755 - val_loss: 0.4840 - val_acc: 0.7449\n",
      "Epoch 901/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4927 - acc: 0.7781 - val_loss: 0.4842 - val_acc: 0.7449\n",
      "Epoch 902/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4925 - acc: 0.7755 - val_loss: 0.4844 - val_acc: 0.7449\n",
      "Epoch 903/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4924 - acc: 0.7781 - val_loss: 0.4844 - val_acc: 0.7449\n",
      "Epoch 904/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4923 - acc: 0.7781 - val_loss: 0.4844 - val_acc: 0.7449\n",
      "Epoch 905/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4922 - acc: 0.7781 - val_loss: 0.4842 - val_acc: 0.7449\n",
      "Epoch 906/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4922 - acc: 0.7781 - val_loss: 0.4838 - val_acc: 0.7449\n",
      "Epoch 907/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4925 - acc: 0.7781 - val_loss: 0.4834 - val_acc: 0.7347\n",
      "Epoch 908/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4927 - acc: 0.7781 - val_loss: 0.4831 - val_acc: 0.7347\n",
      "Epoch 909/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4928 - acc: 0.7806 - val_loss: 0.4829 - val_acc: 0.7347\n",
      "Epoch 910/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4929 - acc: 0.7806 - val_loss: 0.4829 - val_acc: 0.7347\n",
      "Epoch 911/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4927 - acc: 0.7781 - val_loss: 0.4831 - val_acc: 0.7347\n",
      "Epoch 912/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4922 - acc: 0.7806 - val_loss: 0.4834 - val_acc: 0.7347\n",
      "Epoch 913/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4919 - acc: 0.7806 - val_loss: 0.4837 - val_acc: 0.7449\n",
      "Epoch 914/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4918 - acc: 0.7755 - val_loss: 0.4841 - val_acc: 0.7449\n",
      "Epoch 915/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4915 - acc: 0.7781 - val_loss: 0.4844 - val_acc: 0.7551\n",
      "Epoch 916/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4914 - acc: 0.7755 - val_loss: 0.4848 - val_acc: 0.7653\n",
      "Epoch 917/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4913 - acc: 0.7679 - val_loss: 0.4846 - val_acc: 0.7653\n",
      "Epoch 918/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4913 - acc: 0.7704 - val_loss: 0.4844 - val_acc: 0.7551\n",
      "Epoch 919/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4912 - acc: 0.7755 - val_loss: 0.4843 - val_acc: 0.7551\n",
      "Epoch 920/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4912 - acc: 0.7755 - val_loss: 0.4844 - val_acc: 0.7551\n",
      "Epoch 921/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4910 - acc: 0.7730 - val_loss: 0.4850 - val_acc: 0.7653\n",
      "Epoch 922/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4910 - acc: 0.7679 - val_loss: 0.4857 - val_acc: 0.7551\n",
      "Epoch 923/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4910 - acc: 0.7628 - val_loss: 0.4862 - val_acc: 0.7449\n",
      "Epoch 924/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4910 - acc: 0.7551 - val_loss: 0.4870 - val_acc: 0.7449\n",
      "Epoch 925/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4911 - acc: 0.7551 - val_loss: 0.4878 - val_acc: 0.7449\n",
      "Epoch 926/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4912 - acc: 0.7602 - val_loss: 0.4888 - val_acc: 0.7449\n",
      "Epoch 927/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4915 - acc: 0.7653 - val_loss: 0.4894 - val_acc: 0.7449\n",
      "Epoch 928/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4916 - acc: 0.7628 - val_loss: 0.4900 - val_acc: 0.7449\n",
      "Epoch 929/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4919 - acc: 0.7653 - val_loss: 0.4911 - val_acc: 0.7347\n",
      "Epoch 930/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4924 - acc: 0.7577 - val_loss: 0.4918 - val_acc: 0.7347\n",
      "Epoch 931/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4925 - acc: 0.7577 - val_loss: 0.4916 - val_acc: 0.7347\n",
      "Epoch 932/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4923 - acc: 0.7577 - val_loss: 0.4911 - val_acc: 0.7347\n",
      "Epoch 933/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4921 - acc: 0.7653 - val_loss: 0.4901 - val_acc: 0.7449\n",
      "Epoch 934/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4914 - acc: 0.7653 - val_loss: 0.4888 - val_acc: 0.7449\n",
      "Epoch 935/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4909 - acc: 0.7653 - val_loss: 0.4869 - val_acc: 0.7449\n",
      "Epoch 936/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4903 - acc: 0.7653 - val_loss: 0.4856 - val_acc: 0.7551\n",
      "Epoch 937/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4901 - acc: 0.7628 - val_loss: 0.4847 - val_acc: 0.7551\n",
      "Epoch 938/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4901 - acc: 0.7730 - val_loss: 0.4840 - val_acc: 0.7551\n",
      "Epoch 939/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4900 - acc: 0.7755 - val_loss: 0.4840 - val_acc: 0.7551\n",
      "Epoch 940/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4899 - acc: 0.7730 - val_loss: 0.4841 - val_acc: 0.7551\n",
      "Epoch 941/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4898 - acc: 0.7704 - val_loss: 0.4844 - val_acc: 0.7551\n",
      "Epoch 942/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4898 - acc: 0.7679 - val_loss: 0.4846 - val_acc: 0.7449\n",
      "Epoch 943/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4897 - acc: 0.7679 - val_loss: 0.4843 - val_acc: 0.7551\n",
      "Epoch 944/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4896 - acc: 0.7679 - val_loss: 0.4842 - val_acc: 0.7551\n",
      "Epoch 945/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4895 - acc: 0.7704 - val_loss: 0.4838 - val_acc: 0.7551\n",
      "Epoch 946/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4895 - acc: 0.7755 - val_loss: 0.4831 - val_acc: 0.7551\n",
      "Epoch 947/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4895 - acc: 0.7755 - val_loss: 0.4828 - val_acc: 0.7551\n",
      "Epoch 948/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4895 - acc: 0.7730 - val_loss: 0.4827 - val_acc: 0.7551\n",
      "Epoch 949/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4894 - acc: 0.7730 - val_loss: 0.4831 - val_acc: 0.7551\n",
      "Epoch 950/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4894 - acc: 0.7781 - val_loss: 0.4841 - val_acc: 0.7551\n",
      "Epoch 951/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4893 - acc: 0.7679 - val_loss: 0.4852 - val_acc: 0.7551\n",
      "Epoch 952/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4891 - acc: 0.7653 - val_loss: 0.4861 - val_acc: 0.7449\n",
      "Epoch 953/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4893 - acc: 0.7679 - val_loss: 0.4862 - val_acc: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 954/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4893 - acc: 0.7679 - val_loss: 0.4859 - val_acc: 0.7449\n",
      "Epoch 955/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4891 - acc: 0.7679 - val_loss: 0.4855 - val_acc: 0.7551\n",
      "Epoch 956/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4889 - acc: 0.7679 - val_loss: 0.4847 - val_acc: 0.7449\n",
      "Epoch 957/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4888 - acc: 0.7679 - val_loss: 0.4840 - val_acc: 0.7551\n",
      "Epoch 958/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4887 - acc: 0.7730 - val_loss: 0.4834 - val_acc: 0.7551\n",
      "Epoch 959/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4887 - acc: 0.7781 - val_loss: 0.4832 - val_acc: 0.7551\n",
      "Epoch 960/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4886 - acc: 0.7755 - val_loss: 0.4832 - val_acc: 0.7551\n",
      "Epoch 961/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4885 - acc: 0.7755 - val_loss: 0.4829 - val_acc: 0.7551\n",
      "Epoch 962/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4886 - acc: 0.7755 - val_loss: 0.4826 - val_acc: 0.7551\n",
      "Epoch 963/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4885 - acc: 0.7755 - val_loss: 0.4828 - val_acc: 0.7551\n",
      "Epoch 964/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4883 - acc: 0.7781 - val_loss: 0.4834 - val_acc: 0.7551\n",
      "Epoch 965/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4883 - acc: 0.7755 - val_loss: 0.4842 - val_acc: 0.7449\n",
      "Epoch 966/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4881 - acc: 0.7653 - val_loss: 0.4852 - val_acc: 0.7551\n",
      "Epoch 967/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4884 - acc: 0.7653 - val_loss: 0.4860 - val_acc: 0.7449\n",
      "Epoch 968/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4884 - acc: 0.7704 - val_loss: 0.4862 - val_acc: 0.7449\n",
      "Epoch 969/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4884 - acc: 0.7679 - val_loss: 0.4867 - val_acc: 0.7449\n",
      "Epoch 970/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4885 - acc: 0.7602 - val_loss: 0.4877 - val_acc: 0.7449\n",
      "Epoch 971/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4888 - acc: 0.7679 - val_loss: 0.4889 - val_acc: 0.7449\n",
      "Epoch 972/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4894 - acc: 0.7679 - val_loss: 0.4891 - val_acc: 0.7449\n",
      "Epoch 973/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4895 - acc: 0.7653 - val_loss: 0.4891 - val_acc: 0.7347\n",
      "Epoch 974/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4893 - acc: 0.7653 - val_loss: 0.4881 - val_acc: 0.7449\n",
      "Epoch 975/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4888 - acc: 0.7679 - val_loss: 0.4869 - val_acc: 0.7449\n",
      "Epoch 976/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4884 - acc: 0.7679 - val_loss: 0.4862 - val_acc: 0.7449\n",
      "Epoch 977/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4881 - acc: 0.7653 - val_loss: 0.4854 - val_acc: 0.7551\n",
      "Epoch 978/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4879 - acc: 0.7730 - val_loss: 0.4847 - val_acc: 0.7449\n",
      "Epoch 979/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4876 - acc: 0.7781 - val_loss: 0.4837 - val_acc: 0.7449\n",
      "Epoch 980/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4877 - acc: 0.7781 - val_loss: 0.4827 - val_acc: 0.7551\n",
      "Epoch 981/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4874 - acc: 0.7730 - val_loss: 0.4821 - val_acc: 0.7551\n",
      "Epoch 982/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4875 - acc: 0.7781 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 983/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4875 - acc: 0.7781 - val_loss: 0.4816 - val_acc: 0.7551\n",
      "Epoch 984/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4875 - acc: 0.7781 - val_loss: 0.4813 - val_acc: 0.7551\n",
      "Epoch 985/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4876 - acc: 0.7730 - val_loss: 0.4811 - val_acc: 0.7551\n",
      "Epoch 986/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4875 - acc: 0.7755 - val_loss: 0.4813 - val_acc: 0.7551\n",
      "Epoch 987/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4873 - acc: 0.7755 - val_loss: 0.4816 - val_acc: 0.7551\n",
      "Epoch 988/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4871 - acc: 0.7781 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 989/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4870 - acc: 0.7781 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 990/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4871 - acc: 0.7781 - val_loss: 0.4818 - val_acc: 0.7551\n",
      "Epoch 991/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4869 - acc: 0.7806 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 992/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4868 - acc: 0.7781 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 993/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4868 - acc: 0.7781 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 994/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4867 - acc: 0.7781 - val_loss: 0.4823 - val_acc: 0.7551\n",
      "Epoch 995/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4867 - acc: 0.7755 - val_loss: 0.4825 - val_acc: 0.7551\n",
      "Epoch 996/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4866 - acc: 0.7730 - val_loss: 0.4831 - val_acc: 0.7449\n",
      "Epoch 997/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4866 - acc: 0.7781 - val_loss: 0.4840 - val_acc: 0.7449\n",
      "Epoch 998/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4865 - acc: 0.7755 - val_loss: 0.4839 - val_acc: 0.7449\n",
      "Epoch 999/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4864 - acc: 0.7781 - val_loss: 0.4831 - val_acc: 0.7449\n",
      "Epoch 1000/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4862 - acc: 0.7806 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1001/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4862 - acc: 0.7781 - val_loss: 0.4818 - val_acc: 0.7551\n",
      "Epoch 1002/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4863 - acc: 0.7781 - val_loss: 0.4814 - val_acc: 0.7551\n",
      "Epoch 1003/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4862 - acc: 0.7781 - val_loss: 0.4812 - val_acc: 0.7551\n",
      "Epoch 1004/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4862 - acc: 0.7781 - val_loss: 0.4815 - val_acc: 0.7551\n",
      "Epoch 1005/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4860 - acc: 0.7806 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1006/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4860 - acc: 0.7781 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1007/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4859 - acc: 0.7781 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1008/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4858 - acc: 0.7781 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 1009/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4859 - acc: 0.7781 - val_loss: 0.4812 - val_acc: 0.7551\n",
      "Epoch 1010/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4860 - acc: 0.7806 - val_loss: 0.4806 - val_acc: 0.7551\n",
      "Epoch 1011/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4863 - acc: 0.7755 - val_loss: 0.4802 - val_acc: 0.7449\n",
      "Epoch 1012/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4863 - acc: 0.7755 - val_loss: 0.4803 - val_acc: 0.7449\n",
      "Epoch 1013/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4861 - acc: 0.7781 - val_loss: 0.4807 - val_acc: 0.7551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1014/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4858 - acc: 0.7781 - val_loss: 0.4812 - val_acc: 0.7551\n",
      "Epoch 1015/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4856 - acc: 0.7781 - val_loss: 0.4815 - val_acc: 0.7551\n",
      "Epoch 1016/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4856 - acc: 0.7781 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 1017/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4854 - acc: 0.7781 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 1018/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4854 - acc: 0.7781 - val_loss: 0.4818 - val_acc: 0.7551\n",
      "Epoch 1019/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4853 - acc: 0.7781 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 1020/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4853 - acc: 0.7781 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1021/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4853 - acc: 0.7755 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1022/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4852 - acc: 0.7806 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1023/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4851 - acc: 0.7806 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1024/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4851 - acc: 0.7781 - val_loss: 0.4821 - val_acc: 0.7551\n",
      "Epoch 1025/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4850 - acc: 0.7781 - val_loss: 0.4818 - val_acc: 0.7551\n",
      "Epoch 1026/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4850 - acc: 0.7755 - val_loss: 0.4814 - val_acc: 0.7551\n",
      "Epoch 1027/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4849 - acc: 0.7781 - val_loss: 0.4810 - val_acc: 0.7551\n",
      "Epoch 1028/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4852 - acc: 0.7806 - val_loss: 0.4808 - val_acc: 0.7551\n",
      "Epoch 1029/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4852 - acc: 0.7781 - val_loss: 0.4811 - val_acc: 0.7551\n",
      "Epoch 1030/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4849 - acc: 0.7806 - val_loss: 0.4811 - val_acc: 0.7551\n",
      "Epoch 1031/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4848 - acc: 0.7806 - val_loss: 0.4812 - val_acc: 0.7551\n",
      "Epoch 1032/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4848 - acc: 0.7806 - val_loss: 0.4808 - val_acc: 0.7551\n",
      "Epoch 1033/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4849 - acc: 0.7806 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1034/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4850 - acc: 0.7781 - val_loss: 0.4800 - val_acc: 0.7551\n",
      "Epoch 1035/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4852 - acc: 0.7755 - val_loss: 0.4799 - val_acc: 0.7449\n",
      "Epoch 1036/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4851 - acc: 0.7781 - val_loss: 0.4801 - val_acc: 0.7551\n",
      "Epoch 1037/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4850 - acc: 0.7755 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1038/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4848 - acc: 0.7755 - val_loss: 0.4800 - val_acc: 0.7347\n",
      "Epoch 1039/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4851 - acc: 0.7755 - val_loss: 0.4796 - val_acc: 0.7449\n",
      "Epoch 1040/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4856 - acc: 0.7806 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1041/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4858 - acc: 0.7806 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1042/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4855 - acc: 0.7806 - val_loss: 0.4795 - val_acc: 0.7449\n",
      "Epoch 1043/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4848 - acc: 0.7806 - val_loss: 0.4801 - val_acc: 0.7551\n",
      "Epoch 1044/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4846 - acc: 0.7781 - val_loss: 0.4807 - val_acc: 0.7551\n",
      "Epoch 1045/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4843 - acc: 0.7806 - val_loss: 0.4813 - val_acc: 0.7551\n",
      "Epoch 1046/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4841 - acc: 0.7806 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1047/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4838 - acc: 0.7781 - val_loss: 0.4829 - val_acc: 0.7551\n",
      "Epoch 1048/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4840 - acc: 0.7832 - val_loss: 0.4831 - val_acc: 0.7449\n",
      "Epoch 1049/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4840 - acc: 0.7832 - val_loss: 0.4830 - val_acc: 0.7551\n",
      "Epoch 1050/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4839 - acc: 0.7832 - val_loss: 0.4833 - val_acc: 0.7449\n",
      "Epoch 1051/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4838 - acc: 0.7832 - val_loss: 0.4833 - val_acc: 0.7449\n",
      "Epoch 1052/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4837 - acc: 0.7832 - val_loss: 0.4830 - val_acc: 0.7551\n",
      "Epoch 1053/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4836 - acc: 0.7806 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1054/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4836 - acc: 0.7781 - val_loss: 0.4818 - val_acc: 0.7551\n",
      "Epoch 1055/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4834 - acc: 0.7755 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 1056/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4834 - acc: 0.7781 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1057/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4833 - acc: 0.7755 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 1058/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4833 - acc: 0.7781 - val_loss: 0.4818 - val_acc: 0.7551\n",
      "Epoch 1059/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4832 - acc: 0.7781 - val_loss: 0.4813 - val_acc: 0.7551\n",
      "Epoch 1060/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4832 - acc: 0.7781 - val_loss: 0.4810 - val_acc: 0.7551\n",
      "Epoch 1061/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4832 - acc: 0.7781 - val_loss: 0.4809 - val_acc: 0.7551\n",
      "Epoch 1062/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4830 - acc: 0.7781 - val_loss: 0.4814 - val_acc: 0.7551\n",
      "Epoch 1063/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4830 - acc: 0.7781 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 1064/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4831 - acc: 0.7832 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1065/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4829 - acc: 0.7806 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 1066/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4828 - acc: 0.7806 - val_loss: 0.4809 - val_acc: 0.7551\n",
      "Epoch 1067/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4829 - acc: 0.7781 - val_loss: 0.4803 - val_acc: 0.7551\n",
      "Epoch 1068/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4829 - acc: 0.7781 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1069/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4828 - acc: 0.7781 - val_loss: 0.4805 - val_acc: 0.7551\n",
      "Epoch 1070/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4827 - acc: 0.7806 - val_loss: 0.4808 - val_acc: 0.7551\n",
      "Epoch 1071/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4826 - acc: 0.7781 - val_loss: 0.4814 - val_acc: 0.7551\n",
      "Epoch 1072/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4825 - acc: 0.7857 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 1073/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 13us/step - loss: 0.4826 - acc: 0.7806 - val_loss: 0.4825 - val_acc: 0.7449\n",
      "Epoch 1074/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4826 - acc: 0.7832 - val_loss: 0.4831 - val_acc: 0.7449\n",
      "Epoch 1075/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4826 - acc: 0.7832 - val_loss: 0.4837 - val_acc: 0.7449\n",
      "Epoch 1076/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4826 - acc: 0.7806 - val_loss: 0.4840 - val_acc: 0.7449\n",
      "Epoch 1077/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4827 - acc: 0.7806 - val_loss: 0.4843 - val_acc: 0.7449\n",
      "Epoch 1078/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4828 - acc: 0.7704 - val_loss: 0.4845 - val_acc: 0.7449\n",
      "Epoch 1079/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4827 - acc: 0.7730 - val_loss: 0.4838 - val_acc: 0.7449\n",
      "Epoch 1080/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4824 - acc: 0.7806 - val_loss: 0.4831 - val_acc: 0.7449\n",
      "Epoch 1081/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4823 - acc: 0.7832 - val_loss: 0.4828 - val_acc: 0.7449\n",
      "Epoch 1082/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4821 - acc: 0.7857 - val_loss: 0.4827 - val_acc: 0.7449\n",
      "Epoch 1083/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4821 - acc: 0.7857 - val_loss: 0.4828 - val_acc: 0.7449\n",
      "Epoch 1084/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4822 - acc: 0.7857 - val_loss: 0.4833 - val_acc: 0.7449\n",
      "Epoch 1085/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4821 - acc: 0.7806 - val_loss: 0.4837 - val_acc: 0.7449\n",
      "Epoch 1086/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4822 - acc: 0.7755 - val_loss: 0.4840 - val_acc: 0.7449\n",
      "Epoch 1087/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4823 - acc: 0.7755 - val_loss: 0.4843 - val_acc: 0.7449\n",
      "Epoch 1088/1500\n",
      "392/392 [==============================] - 0s 32us/step - loss: 0.4823 - acc: 0.7755 - val_loss: 0.4841 - val_acc: 0.7449\n",
      "Epoch 1089/1500\n",
      "392/392 [==============================] - 0s 22us/step - loss: 0.4822 - acc: 0.7755 - val_loss: 0.4833 - val_acc: 0.7449\n",
      "Epoch 1090/1500\n",
      "392/392 [==============================] - 0s 23us/step - loss: 0.4820 - acc: 0.7857 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 1091/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4817 - acc: 0.7857 - val_loss: 0.4814 - val_acc: 0.7551\n",
      "Epoch 1092/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.4817 - acc: 0.7832 - val_loss: 0.4806 - val_acc: 0.7551\n",
      "Epoch 1093/1500\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.4815 - acc: 0.7883 - val_loss: 0.4803 - val_acc: 0.7551\n",
      "Epoch 1094/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4816 - acc: 0.7857 - val_loss: 0.4797 - val_acc: 0.7551\n",
      "Epoch 1095/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4815 - acc: 0.7832 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1096/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4817 - acc: 0.7806 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1097/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4821 - acc: 0.7755 - val_loss: 0.4783 - val_acc: 0.7551\n",
      "Epoch 1098/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4824 - acc: 0.7806 - val_loss: 0.4779 - val_acc: 0.7551\n",
      "Epoch 1099/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4829 - acc: 0.7806 - val_loss: 0.4777 - val_acc: 0.7551\n",
      "Epoch 1100/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4831 - acc: 0.7806 - val_loss: 0.4777 - val_acc: 0.7551\n",
      "Epoch 1101/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4830 - acc: 0.7806 - val_loss: 0.4777 - val_acc: 0.7551\n",
      "Epoch 1102/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4827 - acc: 0.7806 - val_loss: 0.4779 - val_acc: 0.7551\n",
      "Epoch 1103/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4823 - acc: 0.7806 - val_loss: 0.4781 - val_acc: 0.7551\n",
      "Epoch 1104/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4820 - acc: 0.7755 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1105/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4814 - acc: 0.7755 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1106/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4811 - acc: 0.7857 - val_loss: 0.4798 - val_acc: 0.7551\n",
      "Epoch 1107/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4809 - acc: 0.7857 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1108/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4808 - acc: 0.7857 - val_loss: 0.4805 - val_acc: 0.7551\n",
      "Epoch 1109/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4808 - acc: 0.7832 - val_loss: 0.4806 - val_acc: 0.7551\n",
      "Epoch 1110/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4807 - acc: 0.7832 - val_loss: 0.4808 - val_acc: 0.7551\n",
      "Epoch 1111/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4808 - acc: 0.7857 - val_loss: 0.4817 - val_acc: 0.7551\n",
      "Epoch 1112/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4808 - acc: 0.7883 - val_loss: 0.4823 - val_acc: 0.7551\n",
      "Epoch 1113/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4807 - acc: 0.7857 - val_loss: 0.4823 - val_acc: 0.7551\n",
      "Epoch 1114/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4808 - acc: 0.7857 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1115/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4809 - acc: 0.7857 - val_loss: 0.4815 - val_acc: 0.7551\n",
      "Epoch 1116/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4805 - acc: 0.7857 - val_loss: 0.4810 - val_acc: 0.7551\n",
      "Epoch 1117/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4803 - acc: 0.7832 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1118/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4803 - acc: 0.7832 - val_loss: 0.4798 - val_acc: 0.7551\n",
      "Epoch 1119/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4802 - acc: 0.7857 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1120/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4803 - acc: 0.7832 - val_loss: 0.4790 - val_acc: 0.7551\n",
      "Epoch 1121/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4803 - acc: 0.7806 - val_loss: 0.4784 - val_acc: 0.7551\n",
      "Epoch 1122/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4806 - acc: 0.7806 - val_loss: 0.4781 - val_acc: 0.7551\n",
      "Epoch 1123/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4807 - acc: 0.7806 - val_loss: 0.4782 - val_acc: 0.7551\n",
      "Epoch 1124/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4805 - acc: 0.7781 - val_loss: 0.4785 - val_acc: 0.7551\n",
      "Epoch 1125/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4803 - acc: 0.7755 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1126/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4801 - acc: 0.7806 - val_loss: 0.4790 - val_acc: 0.7551\n",
      "Epoch 1127/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4801 - acc: 0.7857 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1128/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4801 - acc: 0.7806 - val_loss: 0.4785 - val_acc: 0.7551\n",
      "Epoch 1129/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4804 - acc: 0.7755 - val_loss: 0.4780 - val_acc: 0.7551\n",
      "Epoch 1130/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4803 - acc: 0.7806 - val_loss: 0.4781 - val_acc: 0.7551\n",
      "Epoch 1131/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4802 - acc: 0.7806 - val_loss: 0.4781 - val_acc: 0.7551\n",
      "Epoch 1132/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 13us/step - loss: 0.4802 - acc: 0.7806 - val_loss: 0.4781 - val_acc: 0.7551\n",
      "Epoch 1133/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4801 - acc: 0.7806 - val_loss: 0.4782 - val_acc: 0.7551\n",
      "Epoch 1134/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4800 - acc: 0.7781 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1135/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4796 - acc: 0.7832 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1136/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4795 - acc: 0.7883 - val_loss: 0.4796 - val_acc: 0.7551\n",
      "Epoch 1137/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4795 - acc: 0.7832 - val_loss: 0.4796 - val_acc: 0.7551\n",
      "Epoch 1138/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4794 - acc: 0.7857 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1139/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4795 - acc: 0.7883 - val_loss: 0.4788 - val_acc: 0.7551\n",
      "Epoch 1140/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4795 - acc: 0.7806 - val_loss: 0.4785 - val_acc: 0.7551\n",
      "Epoch 1141/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4796 - acc: 0.7806 - val_loss: 0.4785 - val_acc: 0.7551\n",
      "Epoch 1142/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4795 - acc: 0.7781 - val_loss: 0.4788 - val_acc: 0.7551\n",
      "Epoch 1143/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4793 - acc: 0.7832 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1144/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4793 - acc: 0.7857 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1145/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4792 - acc: 0.7857 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1146/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4791 - acc: 0.7857 - val_loss: 0.4795 - val_acc: 0.7551\n",
      "Epoch 1147/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4792 - acc: 0.7806 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1148/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4790 - acc: 0.7883 - val_loss: 0.4812 - val_acc: 0.7551\n",
      "Epoch 1149/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4792 - acc: 0.7908 - val_loss: 0.4823 - val_acc: 0.7551\n",
      "Epoch 1150/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4793 - acc: 0.7832 - val_loss: 0.4833 - val_acc: 0.7347\n",
      "Epoch 1151/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4799 - acc: 0.7806 - val_loss: 0.4842 - val_acc: 0.7347\n",
      "Epoch 1152/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4801 - acc: 0.7832 - val_loss: 0.4848 - val_acc: 0.7347\n",
      "Epoch 1153/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4802 - acc: 0.7857 - val_loss: 0.4848 - val_acc: 0.7347\n",
      "Epoch 1154/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4801 - acc: 0.7857 - val_loss: 0.4843 - val_acc: 0.7347\n",
      "Epoch 1155/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4799 - acc: 0.7832 - val_loss: 0.4837 - val_acc: 0.7347\n",
      "Epoch 1156/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4795 - acc: 0.7806 - val_loss: 0.4824 - val_acc: 0.7449\n",
      "Epoch 1157/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4790 - acc: 0.7857 - val_loss: 0.4814 - val_acc: 0.7551\n",
      "Epoch 1158/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4788 - acc: 0.7883 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1159/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4786 - acc: 0.7857 - val_loss: 0.4798 - val_acc: 0.7551\n",
      "Epoch 1160/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4785 - acc: 0.7806 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1161/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4785 - acc: 0.7730 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1162/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4784 - acc: 0.7730 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1163/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4783 - acc: 0.7730 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1164/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4783 - acc: 0.7806 - val_loss: 0.4799 - val_acc: 0.7551\n",
      "Epoch 1165/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4783 - acc: 0.7857 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1166/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4782 - acc: 0.7883 - val_loss: 0.4808 - val_acc: 0.7551\n",
      "Epoch 1167/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4784 - acc: 0.7908 - val_loss: 0.4816 - val_acc: 0.7551\n",
      "Epoch 1168/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4784 - acc: 0.7857 - val_loss: 0.4824 - val_acc: 0.7449\n",
      "Epoch 1169/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4786 - acc: 0.7857 - val_loss: 0.4830 - val_acc: 0.7449\n",
      "Epoch 1170/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4787 - acc: 0.7832 - val_loss: 0.4832 - val_acc: 0.7449\n",
      "Epoch 1171/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4788 - acc: 0.7832 - val_loss: 0.4835 - val_acc: 0.7449\n",
      "Epoch 1172/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4788 - acc: 0.7806 - val_loss: 0.4833 - val_acc: 0.7449\n",
      "Epoch 1173/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4786 - acc: 0.7857 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1174/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4780 - acc: 0.7883 - val_loss: 0.4806 - val_acc: 0.7551\n",
      "Epoch 1175/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4779 - acc: 0.7857 - val_loss: 0.4795 - val_acc: 0.7551\n",
      "Epoch 1176/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4777 - acc: 0.7832 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1177/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4778 - acc: 0.7806 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1178/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4777 - acc: 0.7883 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1179/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4777 - acc: 0.7806 - val_loss: 0.4797 - val_acc: 0.7551\n",
      "Epoch 1180/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4776 - acc: 0.7832 - val_loss: 0.4797 - val_acc: 0.7551\n",
      "Epoch 1181/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4776 - acc: 0.7857 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1182/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4776 - acc: 0.7832 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1183/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4775 - acc: 0.7857 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1184/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4774 - acc: 0.7883 - val_loss: 0.4806 - val_acc: 0.7551\n",
      "Epoch 1185/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4775 - acc: 0.7883 - val_loss: 0.4807 - val_acc: 0.7551\n",
      "Epoch 1186/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4774 - acc: 0.7883 - val_loss: 0.4805 - val_acc: 0.7551\n",
      "Epoch 1187/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4773 - acc: 0.7908 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1188/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4774 - acc: 0.7857 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1189/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4772 - acc: 0.7857 - val_loss: 0.4805 - val_acc: 0.7551\n",
      "Epoch 1190/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4772 - acc: 0.7857 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1191/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 15us/step - loss: 0.4772 - acc: 0.7857 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1192/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4772 - acc: 0.7857 - val_loss: 0.4797 - val_acc: 0.7551\n",
      "Epoch 1193/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4769 - acc: 0.7857 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1194/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4772 - acc: 0.7806 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1195/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4771 - acc: 0.7832 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1196/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4771 - acc: 0.7832 - val_loss: 0.4788 - val_acc: 0.7551\n",
      "Epoch 1197/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4770 - acc: 0.7857 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1198/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4770 - acc: 0.7832 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1199/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4769 - acc: 0.7832 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1200/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4769 - acc: 0.7832 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1201/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4768 - acc: 0.7832 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1202/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4768 - acc: 0.7781 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1203/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4768 - acc: 0.7857 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1204/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4767 - acc: 0.7857 - val_loss: 0.4790 - val_acc: 0.7551\n",
      "Epoch 1205/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4767 - acc: 0.7832 - val_loss: 0.4798 - val_acc: 0.7551\n",
      "Epoch 1206/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4766 - acc: 0.7883 - val_loss: 0.4803 - val_acc: 0.7551\n",
      "Epoch 1207/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4765 - acc: 0.7883 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1208/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4764 - acc: 0.7908 - val_loss: 0.4796 - val_acc: 0.7551\n",
      "Epoch 1209/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4765 - acc: 0.7857 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1210/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4764 - acc: 0.7883 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1211/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4766 - acc: 0.7883 - val_loss: 0.4800 - val_acc: 0.7551\n",
      "Epoch 1212/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4763 - acc: 0.7908 - val_loss: 0.4803 - val_acc: 0.7551\n",
      "Epoch 1213/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4766 - acc: 0.7883 - val_loss: 0.4813 - val_acc: 0.7551\n",
      "Epoch 1214/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4764 - acc: 0.7908 - val_loss: 0.4816 - val_acc: 0.7551\n",
      "Epoch 1215/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4764 - acc: 0.7908 - val_loss: 0.4823 - val_acc: 0.7449\n",
      "Epoch 1216/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4766 - acc: 0.7883 - val_loss: 0.4829 - val_acc: 0.7449\n",
      "Epoch 1217/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4766 - acc: 0.7908 - val_loss: 0.4828 - val_acc: 0.7449\n",
      "Epoch 1218/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4766 - acc: 0.7883 - val_loss: 0.4824 - val_acc: 0.7449\n",
      "Epoch 1219/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4763 - acc: 0.7883 - val_loss: 0.4815 - val_acc: 0.7551\n",
      "Epoch 1220/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4760 - acc: 0.7934 - val_loss: 0.4805 - val_acc: 0.7551\n",
      "Epoch 1221/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4759 - acc: 0.7857 - val_loss: 0.4797 - val_acc: 0.7551\n",
      "Epoch 1222/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4758 - acc: 0.7883 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1223/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4760 - acc: 0.7832 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1224/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4759 - acc: 0.7832 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1225/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4758 - acc: 0.7832 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1226/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4759 - acc: 0.7908 - val_loss: 0.4801 - val_acc: 0.7551\n",
      "Epoch 1227/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4757 - acc: 0.7883 - val_loss: 0.4807 - val_acc: 0.7551\n",
      "Epoch 1228/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4758 - acc: 0.7934 - val_loss: 0.4810 - val_acc: 0.7551\n",
      "Epoch 1229/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4757 - acc: 0.7934 - val_loss: 0.4806 - val_acc: 0.7551\n",
      "Epoch 1230/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4757 - acc: 0.7908 - val_loss: 0.4800 - val_acc: 0.7551\n",
      "Epoch 1231/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4757 - acc: 0.7883 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1232/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4757 - acc: 0.7883 - val_loss: 0.4784 - val_acc: 0.7551\n",
      "Epoch 1233/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4757 - acc: 0.7832 - val_loss: 0.4779 - val_acc: 0.7653\n",
      "Epoch 1234/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4757 - acc: 0.7857 - val_loss: 0.4776 - val_acc: 0.7653\n",
      "Epoch 1235/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4759 - acc: 0.7883 - val_loss: 0.4772 - val_acc: 0.7755\n",
      "Epoch 1236/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4760 - acc: 0.7857 - val_loss: 0.4770 - val_acc: 0.7653\n",
      "Epoch 1237/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4763 - acc: 0.7832 - val_loss: 0.4770 - val_acc: 0.7653\n",
      "Epoch 1238/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4760 - acc: 0.7857 - val_loss: 0.4774 - val_acc: 0.7755\n",
      "Epoch 1239/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4758 - acc: 0.7857 - val_loss: 0.4776 - val_acc: 0.7653\n",
      "Epoch 1240/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4755 - acc: 0.7883 - val_loss: 0.4780 - val_acc: 0.7551\n",
      "Epoch 1241/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4753 - acc: 0.7832 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1242/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4752 - acc: 0.7857 - val_loss: 0.4798 - val_acc: 0.7551\n",
      "Epoch 1243/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4750 - acc: 0.7908 - val_loss: 0.4811 - val_acc: 0.7551\n",
      "Epoch 1244/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4752 - acc: 0.7908 - val_loss: 0.4820 - val_acc: 0.7551\n",
      "Epoch 1245/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4753 - acc: 0.7908 - val_loss: 0.4824 - val_acc: 0.7551\n",
      "Epoch 1246/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4754 - acc: 0.7908 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1247/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4753 - acc: 0.7908 - val_loss: 0.4822 - val_acc: 0.7551\n",
      "Epoch 1248/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4753 - acc: 0.7908 - val_loss: 0.4827 - val_acc: 0.7551\n",
      "Epoch 1249/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4755 - acc: 0.7908 - val_loss: 0.4833 - val_acc: 0.7449\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 14us/step - loss: 0.4756 - acc: 0.7883 - val_loss: 0.4833 - val_acc: 0.7449\n",
      "Epoch 1251/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4755 - acc: 0.7883 - val_loss: 0.4827 - val_acc: 0.7551\n",
      "Epoch 1252/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4752 - acc: 0.7934 - val_loss: 0.4819 - val_acc: 0.7551\n",
      "Epoch 1253/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4747 - acc: 0.7908 - val_loss: 0.4804 - val_acc: 0.7551\n",
      "Epoch 1254/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4744 - acc: 0.7857 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1255/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4747 - acc: 0.7883 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1256/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4747 - acc: 0.7832 - val_loss: 0.4790 - val_acc: 0.7551\n",
      "Epoch 1257/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4745 - acc: 0.7857 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1258/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4745 - acc: 0.7883 - val_loss: 0.4795 - val_acc: 0.7551\n",
      "Epoch 1259/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4746 - acc: 0.7883 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1260/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4746 - acc: 0.7857 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1261/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4746 - acc: 0.7832 - val_loss: 0.4782 - val_acc: 0.7551\n",
      "Epoch 1262/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4748 - acc: 0.7832 - val_loss: 0.4777 - val_acc: 0.7653\n",
      "Epoch 1263/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4748 - acc: 0.7857 - val_loss: 0.4773 - val_acc: 0.7653\n",
      "Epoch 1264/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4751 - acc: 0.7857 - val_loss: 0.4772 - val_acc: 0.7653\n",
      "Epoch 1265/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4749 - acc: 0.7857 - val_loss: 0.4774 - val_acc: 0.7755\n",
      "Epoch 1266/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4747 - acc: 0.7857 - val_loss: 0.4779 - val_acc: 0.7653\n",
      "Epoch 1267/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4746 - acc: 0.7832 - val_loss: 0.4784 - val_acc: 0.7551\n",
      "Epoch 1268/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4743 - acc: 0.7806 - val_loss: 0.4785 - val_acc: 0.7551\n",
      "Epoch 1269/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4743 - acc: 0.7832 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1270/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4743 - acc: 0.7806 - val_loss: 0.4783 - val_acc: 0.7551\n",
      "Epoch 1271/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4743 - acc: 0.7832 - val_loss: 0.4784 - val_acc: 0.7551\n",
      "Epoch 1272/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4743 - acc: 0.7806 - val_loss: 0.4785 - val_acc: 0.7551\n",
      "Epoch 1273/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4743 - acc: 0.7832 - val_loss: 0.4783 - val_acc: 0.7551\n",
      "Epoch 1274/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4742 - acc: 0.7832 - val_loss: 0.4788 - val_acc: 0.7551\n",
      "Epoch 1275/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4740 - acc: 0.7832 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1276/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4740 - acc: 0.7832 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1277/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4740 - acc: 0.7857 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1278/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4739 - acc: 0.7883 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1279/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4739 - acc: 0.7883 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1280/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4739 - acc: 0.7883 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1281/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4738 - acc: 0.7883 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1282/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4738 - acc: 0.7832 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1283/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4738 - acc: 0.7832 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1284/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4738 - acc: 0.7883 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1285/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4737 - acc: 0.7857 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1286/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4738 - acc: 0.7832 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1287/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4737 - acc: 0.7832 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1288/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4736 - acc: 0.7857 - val_loss: 0.4793 - val_acc: 0.7551\n",
      "Epoch 1289/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4739 - acc: 0.7832 - val_loss: 0.4800 - val_acc: 0.7551\n",
      "Epoch 1290/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4736 - acc: 0.7857 - val_loss: 0.4803 - val_acc: 0.7551\n",
      "Epoch 1291/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4737 - acc: 0.7934 - val_loss: 0.4805 - val_acc: 0.7551\n",
      "Epoch 1292/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4736 - acc: 0.7883 - val_loss: 0.4797 - val_acc: 0.7551\n",
      "Epoch 1293/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4737 - acc: 0.7832 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1294/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4734 - acc: 0.7832 - val_loss: 0.4784 - val_acc: 0.7551\n",
      "Epoch 1295/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4735 - acc: 0.7832 - val_loss: 0.4782 - val_acc: 0.7551\n",
      "Epoch 1296/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4736 - acc: 0.7832 - val_loss: 0.4782 - val_acc: 0.7551\n",
      "Epoch 1297/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4735 - acc: 0.7832 - val_loss: 0.4784 - val_acc: 0.7551\n",
      "Epoch 1298/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4734 - acc: 0.7832 - val_loss: 0.4788 - val_acc: 0.7551\n",
      "Epoch 1299/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4735 - acc: 0.7857 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1300/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4733 - acc: 0.7857 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1301/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4732 - acc: 0.7832 - val_loss: 0.4787 - val_acc: 0.7551\n",
      "Epoch 1302/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4735 - acc: 0.7832 - val_loss: 0.4779 - val_acc: 0.7653\n",
      "Epoch 1303/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4736 - acc: 0.7832 - val_loss: 0.4775 - val_acc: 0.7755\n",
      "Epoch 1304/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4736 - acc: 0.7883 - val_loss: 0.4774 - val_acc: 0.7755\n",
      "Epoch 1305/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4736 - acc: 0.7883 - val_loss: 0.4771 - val_acc: 0.7653\n",
      "Epoch 1306/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4737 - acc: 0.7883 - val_loss: 0.4770 - val_acc: 0.7653\n",
      "Epoch 1307/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4738 - acc: 0.7857 - val_loss: 0.4772 - val_acc: 0.7653\n",
      "Epoch 1308/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4736 - acc: 0.7883 - val_loss: 0.4775 - val_acc: 0.7755\n",
      "Epoch 1309/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 13us/step - loss: 0.4735 - acc: 0.7883 - val_loss: 0.4775 - val_acc: 0.7755\n",
      "Epoch 1310/1500\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.4734 - acc: 0.7883 - val_loss: 0.4773 - val_acc: 0.7755\n",
      "Epoch 1311/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4736 - acc: 0.7883 - val_loss: 0.4770 - val_acc: 0.7653\n",
      "Epoch 1312/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4736 - acc: 0.7883 - val_loss: 0.4770 - val_acc: 0.7755\n",
      "Epoch 1313/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4737 - acc: 0.7857 - val_loss: 0.4767 - val_acc: 0.7755\n",
      "Epoch 1314/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4740 - acc: 0.7857 - val_loss: 0.4766 - val_acc: 0.7755\n",
      "Epoch 1315/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4739 - acc: 0.7857 - val_loss: 0.4768 - val_acc: 0.7755\n",
      "Epoch 1316/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4737 - acc: 0.7857 - val_loss: 0.4768 - val_acc: 0.7755\n",
      "Epoch 1317/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4738 - acc: 0.7857 - val_loss: 0.4766 - val_acc: 0.7755\n",
      "Epoch 1318/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4739 - acc: 0.7857 - val_loss: 0.4768 - val_acc: 0.7755\n",
      "Epoch 1319/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4736 - acc: 0.7857 - val_loss: 0.4771 - val_acc: 0.7755\n",
      "Epoch 1320/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4733 - acc: 0.7883 - val_loss: 0.4775 - val_acc: 0.7755\n",
      "Epoch 1321/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4729 - acc: 0.7857 - val_loss: 0.4781 - val_acc: 0.7653\n",
      "Epoch 1322/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4726 - acc: 0.7832 - val_loss: 0.4788 - val_acc: 0.7551\n",
      "Epoch 1323/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4728 - acc: 0.7832 - val_loss: 0.4802 - val_acc: 0.7551\n",
      "Epoch 1324/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4728 - acc: 0.7959 - val_loss: 0.4820 - val_acc: 0.7347\n",
      "Epoch 1325/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4735 - acc: 0.7959 - val_loss: 0.4836 - val_acc: 0.7245\n",
      "Epoch 1326/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4737 - acc: 0.7959 - val_loss: 0.4842 - val_acc: 0.7245\n",
      "Epoch 1327/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4738 - acc: 0.7959 - val_loss: 0.4841 - val_acc: 0.7245\n",
      "Epoch 1328/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4737 - acc: 0.7959 - val_loss: 0.4841 - val_acc: 0.7245\n",
      "Epoch 1329/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4737 - acc: 0.7959 - val_loss: 0.4840 - val_acc: 0.7245\n",
      "Epoch 1330/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4736 - acc: 0.7959 - val_loss: 0.4841 - val_acc: 0.7245\n",
      "Epoch 1331/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4736 - acc: 0.7959 - val_loss: 0.4841 - val_acc: 0.7245\n",
      "Epoch 1332/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4736 - acc: 0.7959 - val_loss: 0.4840 - val_acc: 0.7245\n",
      "Epoch 1333/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4734 - acc: 0.7959 - val_loss: 0.4828 - val_acc: 0.7245\n",
      "Epoch 1334/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4729 - acc: 0.7934 - val_loss: 0.4821 - val_acc: 0.7347\n",
      "Epoch 1335/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4727 - acc: 0.7934 - val_loss: 0.4818 - val_acc: 0.7347\n",
      "Epoch 1336/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4726 - acc: 0.7934 - val_loss: 0.4815 - val_acc: 0.7347\n",
      "Epoch 1337/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4725 - acc: 0.7934 - val_loss: 0.4815 - val_acc: 0.7347\n",
      "Epoch 1338/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4725 - acc: 0.7934 - val_loss: 0.4815 - val_acc: 0.7347\n",
      "Epoch 1339/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4724 - acc: 0.7934 - val_loss: 0.4813 - val_acc: 0.7347\n",
      "Epoch 1340/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4724 - acc: 0.7934 - val_loss: 0.4811 - val_acc: 0.7449\n",
      "Epoch 1341/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4724 - acc: 0.7908 - val_loss: 0.4806 - val_acc: 0.7449\n",
      "Epoch 1342/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4721 - acc: 0.7908 - val_loss: 0.4808 - val_acc: 0.7449\n",
      "Epoch 1343/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4723 - acc: 0.7959 - val_loss: 0.4812 - val_acc: 0.7449\n",
      "Epoch 1344/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4721 - acc: 0.7959 - val_loss: 0.4806 - val_acc: 0.7449\n",
      "Epoch 1345/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4721 - acc: 0.7883 - val_loss: 0.4799 - val_acc: 0.7551\n",
      "Epoch 1346/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4718 - acc: 0.7908 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1347/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4720 - acc: 0.7832 - val_loss: 0.4784 - val_acc: 0.7653\n",
      "Epoch 1348/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4719 - acc: 0.7832 - val_loss: 0.4781 - val_acc: 0.7755\n",
      "Epoch 1349/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4721 - acc: 0.7832 - val_loss: 0.4781 - val_acc: 0.7755\n",
      "Epoch 1350/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4720 - acc: 0.7832 - val_loss: 0.4785 - val_acc: 0.7653\n",
      "Epoch 1351/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4718 - acc: 0.7832 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1352/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4716 - acc: 0.7857 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1353/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4716 - acc: 0.7857 - val_loss: 0.4792 - val_acc: 0.7551\n",
      "Epoch 1354/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4715 - acc: 0.7857 - val_loss: 0.4795 - val_acc: 0.7551\n",
      "Epoch 1355/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4715 - acc: 0.7908 - val_loss: 0.4802 - val_acc: 0.7449\n",
      "Epoch 1356/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4715 - acc: 0.7883 - val_loss: 0.4808 - val_acc: 0.7449\n",
      "Epoch 1357/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4716 - acc: 0.7908 - val_loss: 0.4810 - val_acc: 0.7347\n",
      "Epoch 1358/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4715 - acc: 0.7908 - val_loss: 0.4807 - val_acc: 0.7449\n",
      "Epoch 1359/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4715 - acc: 0.7883 - val_loss: 0.4805 - val_acc: 0.7449\n",
      "Epoch 1360/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4714 - acc: 0.7883 - val_loss: 0.4807 - val_acc: 0.7347\n",
      "Epoch 1361/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4715 - acc: 0.7908 - val_loss: 0.4812 - val_acc: 0.7347\n",
      "Epoch 1362/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4716 - acc: 0.7959 - val_loss: 0.4822 - val_acc: 0.7347\n",
      "Epoch 1363/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4719 - acc: 0.7959 - val_loss: 0.4825 - val_acc: 0.7347\n",
      "Epoch 1364/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4719 - acc: 0.7959 - val_loss: 0.4824 - val_acc: 0.7347\n",
      "Epoch 1365/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4717 - acc: 0.7934 - val_loss: 0.4822 - val_acc: 0.7347\n",
      "Epoch 1366/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4717 - acc: 0.7934 - val_loss: 0.4822 - val_acc: 0.7347\n",
      "Epoch 1367/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4719 - acc: 0.7934 - val_loss: 0.4827 - val_acc: 0.7347\n",
      "Epoch 1368/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 15us/step - loss: 0.4718 - acc: 0.7934 - val_loss: 0.4826 - val_acc: 0.7347\n",
      "Epoch 1369/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4717 - acc: 0.7934 - val_loss: 0.4822 - val_acc: 0.7347\n",
      "Epoch 1370/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4715 - acc: 0.7934 - val_loss: 0.4817 - val_acc: 0.7347\n",
      "Epoch 1371/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4716 - acc: 0.7908 - val_loss: 0.4808 - val_acc: 0.7347\n",
      "Epoch 1372/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4711 - acc: 0.7908 - val_loss: 0.4806 - val_acc: 0.7347\n",
      "Epoch 1373/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4710 - acc: 0.7883 - val_loss: 0.4804 - val_acc: 0.7347\n",
      "Epoch 1374/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4709 - acc: 0.7832 - val_loss: 0.4796 - val_acc: 0.7449\n",
      "Epoch 1375/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4708 - acc: 0.7857 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1376/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4708 - acc: 0.7857 - val_loss: 0.4786 - val_acc: 0.7653\n",
      "Epoch 1377/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4710 - acc: 0.7832 - val_loss: 0.4783 - val_acc: 0.7755\n",
      "Epoch 1378/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4710 - acc: 0.7832 - val_loss: 0.4784 - val_acc: 0.7755\n",
      "Epoch 1379/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4709 - acc: 0.7832 - val_loss: 0.4789 - val_acc: 0.7551\n",
      "Epoch 1380/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4708 - acc: 0.7832 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1381/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4707 - acc: 0.7857 - val_loss: 0.4799 - val_acc: 0.7449\n",
      "Epoch 1382/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4707 - acc: 0.7883 - val_loss: 0.4802 - val_acc: 0.7449\n",
      "Epoch 1383/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4707 - acc: 0.7883 - val_loss: 0.4803 - val_acc: 0.7449\n",
      "Epoch 1384/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4707 - acc: 0.7883 - val_loss: 0.4803 - val_acc: 0.7449\n",
      "Epoch 1385/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4707 - acc: 0.7908 - val_loss: 0.4799 - val_acc: 0.7449\n",
      "Epoch 1386/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4706 - acc: 0.7883 - val_loss: 0.4797 - val_acc: 0.7449\n",
      "Epoch 1387/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4705 - acc: 0.7832 - val_loss: 0.4790 - val_acc: 0.7449\n",
      "Epoch 1388/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4708 - acc: 0.7857 - val_loss: 0.4783 - val_acc: 0.7755\n",
      "Epoch 1389/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4708 - acc: 0.7832 - val_loss: 0.4782 - val_acc: 0.7755\n",
      "Epoch 1390/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4705 - acc: 0.7832 - val_loss: 0.4788 - val_acc: 0.7449\n",
      "Epoch 1391/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4705 - acc: 0.7857 - val_loss: 0.4798 - val_acc: 0.7449\n",
      "Epoch 1392/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4703 - acc: 0.7883 - val_loss: 0.4804 - val_acc: 0.7347\n",
      "Epoch 1393/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4704 - acc: 0.7883 - val_loss: 0.4809 - val_acc: 0.7347\n",
      "Epoch 1394/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4708 - acc: 0.7883 - val_loss: 0.4816 - val_acc: 0.7347\n",
      "Epoch 1395/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4707 - acc: 0.7959 - val_loss: 0.4818 - val_acc: 0.7347\n",
      "Epoch 1396/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4708 - acc: 0.7985 - val_loss: 0.4818 - val_acc: 0.7347\n",
      "Epoch 1397/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4707 - acc: 0.7985 - val_loss: 0.4819 - val_acc: 0.7347\n",
      "Epoch 1398/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4708 - acc: 0.7985 - val_loss: 0.4820 - val_acc: 0.7347\n",
      "Epoch 1399/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4706 - acc: 0.7985 - val_loss: 0.4811 - val_acc: 0.7347\n",
      "Epoch 1400/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4705 - acc: 0.7934 - val_loss: 0.4799 - val_acc: 0.7347\n",
      "Epoch 1401/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4704 - acc: 0.7857 - val_loss: 0.4793 - val_acc: 0.7449\n",
      "Epoch 1402/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4702 - acc: 0.7832 - val_loss: 0.4795 - val_acc: 0.7449\n",
      "Epoch 1403/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4702 - acc: 0.7832 - val_loss: 0.4794 - val_acc: 0.7449\n",
      "Epoch 1404/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4702 - acc: 0.7832 - val_loss: 0.4795 - val_acc: 0.7449\n",
      "Epoch 1405/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4701 - acc: 0.7832 - val_loss: 0.4796 - val_acc: 0.7347\n",
      "Epoch 1406/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4701 - acc: 0.7857 - val_loss: 0.4797 - val_acc: 0.7347\n",
      "Epoch 1407/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4700 - acc: 0.7857 - val_loss: 0.4797 - val_acc: 0.7347\n",
      "Epoch 1408/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4700 - acc: 0.7857 - val_loss: 0.4797 - val_acc: 0.7347\n",
      "Epoch 1409/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4699 - acc: 0.7832 - val_loss: 0.4793 - val_acc: 0.7347\n",
      "Epoch 1410/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4699 - acc: 0.7857 - val_loss: 0.4790 - val_acc: 0.7449\n",
      "Epoch 1411/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4700 - acc: 0.7857 - val_loss: 0.4785 - val_acc: 0.7449\n",
      "Epoch 1412/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4698 - acc: 0.7832 - val_loss: 0.4781 - val_acc: 0.7653\n",
      "Epoch 1413/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4700 - acc: 0.7832 - val_loss: 0.4776 - val_acc: 0.7755\n",
      "Epoch 1414/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4701 - acc: 0.7832 - val_loss: 0.4775 - val_acc: 0.7857\n",
      "Epoch 1415/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4702 - acc: 0.7832 - val_loss: 0.4778 - val_acc: 0.7755\n",
      "Epoch 1416/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4699 - acc: 0.7832 - val_loss: 0.4780 - val_acc: 0.7755\n",
      "Epoch 1417/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4698 - acc: 0.7832 - val_loss: 0.4782 - val_acc: 0.7551\n",
      "Epoch 1418/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4698 - acc: 0.7857 - val_loss: 0.4782 - val_acc: 0.7653\n",
      "Epoch 1419/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4697 - acc: 0.7857 - val_loss: 0.4782 - val_acc: 0.7653\n",
      "Epoch 1420/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4697 - acc: 0.7857 - val_loss: 0.4781 - val_acc: 0.7755\n",
      "Epoch 1421/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4697 - acc: 0.7857 - val_loss: 0.4781 - val_acc: 0.7653\n",
      "Epoch 1422/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4696 - acc: 0.7857 - val_loss: 0.4781 - val_acc: 0.7755\n",
      "Epoch 1423/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4696 - acc: 0.7857 - val_loss: 0.4777 - val_acc: 0.7755\n",
      "Epoch 1424/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4699 - acc: 0.7832 - val_loss: 0.4773 - val_acc: 0.7857\n",
      "Epoch 1425/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4699 - acc: 0.7857 - val_loss: 0.4771 - val_acc: 0.7755\n",
      "Epoch 1426/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4701 - acc: 0.7883 - val_loss: 0.4770 - val_acc: 0.7755\n",
      "Epoch 1427/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 13us/step - loss: 0.4701 - acc: 0.7883 - val_loss: 0.4770 - val_acc: 0.7755\n",
      "Epoch 1428/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4702 - acc: 0.7883 - val_loss: 0.4769 - val_acc: 0.7755\n",
      "Epoch 1429/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4701 - acc: 0.7883 - val_loss: 0.4770 - val_acc: 0.7755\n",
      "Epoch 1430/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4699 - acc: 0.7857 - val_loss: 0.4774 - val_acc: 0.7857\n",
      "Epoch 1431/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4697 - acc: 0.7832 - val_loss: 0.4779 - val_acc: 0.7755\n",
      "Epoch 1432/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4695 - acc: 0.7832 - val_loss: 0.4780 - val_acc: 0.7755\n",
      "Epoch 1433/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4695 - acc: 0.7832 - val_loss: 0.4778 - val_acc: 0.7857\n",
      "Epoch 1434/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4695 - acc: 0.7832 - val_loss: 0.4777 - val_acc: 0.7857\n",
      "Epoch 1435/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4695 - acc: 0.7832 - val_loss: 0.4777 - val_acc: 0.7857\n",
      "Epoch 1436/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4694 - acc: 0.7832 - val_loss: 0.4781 - val_acc: 0.7755\n",
      "Epoch 1437/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4693 - acc: 0.7832 - val_loss: 0.4785 - val_acc: 0.7551\n",
      "Epoch 1438/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4692 - acc: 0.7857 - val_loss: 0.4788 - val_acc: 0.7449\n",
      "Epoch 1439/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4691 - acc: 0.7908 - val_loss: 0.4790 - val_acc: 0.7449\n",
      "Epoch 1440/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4691 - acc: 0.7857 - val_loss: 0.4793 - val_acc: 0.7347\n",
      "Epoch 1441/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4691 - acc: 0.7857 - val_loss: 0.4791 - val_acc: 0.7449\n",
      "Epoch 1442/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4692 - acc: 0.7857 - val_loss: 0.4788 - val_acc: 0.7449\n",
      "Epoch 1443/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4690 - acc: 0.7883 - val_loss: 0.4786 - val_acc: 0.7449\n",
      "Epoch 1444/1500\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.4691 - acc: 0.7883 - val_loss: 0.4787 - val_acc: 0.7449\n",
      "Epoch 1445/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4690 - acc: 0.7908 - val_loss: 0.4791 - val_acc: 0.7347\n",
      "Epoch 1446/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4689 - acc: 0.7857 - val_loss: 0.4794 - val_acc: 0.7347\n",
      "Epoch 1447/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4689 - acc: 0.7857 - val_loss: 0.4801 - val_acc: 0.7347\n",
      "Epoch 1448/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4690 - acc: 0.7934 - val_loss: 0.4806 - val_acc: 0.7347\n",
      "Epoch 1449/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4692 - acc: 0.7934 - val_loss: 0.4813 - val_acc: 0.7347\n",
      "Epoch 1450/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4693 - acc: 0.7985 - val_loss: 0.4816 - val_acc: 0.7347\n",
      "Epoch 1451/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4694 - acc: 0.7959 - val_loss: 0.4813 - val_acc: 0.7347\n",
      "Epoch 1452/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4692 - acc: 0.7959 - val_loss: 0.4804 - val_acc: 0.7347\n",
      "Epoch 1453/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4690 - acc: 0.7934 - val_loss: 0.4801 - val_acc: 0.7347\n",
      "Epoch 1454/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4689 - acc: 0.7908 - val_loss: 0.4801 - val_acc: 0.7347\n",
      "Epoch 1455/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4689 - acc: 0.7908 - val_loss: 0.4803 - val_acc: 0.7347\n",
      "Epoch 1456/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4689 - acc: 0.7908 - val_loss: 0.4798 - val_acc: 0.7347\n",
      "Epoch 1457/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4688 - acc: 0.7883 - val_loss: 0.4794 - val_acc: 0.7347\n",
      "Epoch 1458/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4686 - acc: 0.7857 - val_loss: 0.4790 - val_acc: 0.7449\n",
      "Epoch 1459/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4687 - acc: 0.7883 - val_loss: 0.4786 - val_acc: 0.7551\n",
      "Epoch 1460/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4686 - acc: 0.7857 - val_loss: 0.4781 - val_acc: 0.7755\n",
      "Epoch 1461/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4687 - acc: 0.7857 - val_loss: 0.4780 - val_acc: 0.7755\n",
      "Epoch 1462/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4687 - acc: 0.7857 - val_loss: 0.4782 - val_acc: 0.7755\n",
      "Epoch 1463/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4686 - acc: 0.7883 - val_loss: 0.4785 - val_acc: 0.7653\n",
      "Epoch 1464/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4686 - acc: 0.7857 - val_loss: 0.4790 - val_acc: 0.7347\n",
      "Epoch 1465/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4685 - acc: 0.7857 - val_loss: 0.4791 - val_acc: 0.7347\n",
      "Epoch 1466/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4685 - acc: 0.7857 - val_loss: 0.4791 - val_acc: 0.7347\n",
      "Epoch 1467/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4684 - acc: 0.7908 - val_loss: 0.4790 - val_acc: 0.7347\n",
      "Epoch 1468/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4684 - acc: 0.7883 - val_loss: 0.4788 - val_acc: 0.7653\n",
      "Epoch 1469/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4684 - acc: 0.7857 - val_loss: 0.4788 - val_acc: 0.7653\n",
      "Epoch 1470/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4685 - acc: 0.7857 - val_loss: 0.4788 - val_acc: 0.7653\n",
      "Epoch 1471/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4684 - acc: 0.7857 - val_loss: 0.4790 - val_acc: 0.7551\n",
      "Epoch 1472/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4683 - acc: 0.7883 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1473/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4683 - acc: 0.7883 - val_loss: 0.4791 - val_acc: 0.7551\n",
      "Epoch 1474/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4683 - acc: 0.7908 - val_loss: 0.4790 - val_acc: 0.7653\n",
      "Epoch 1475/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4683 - acc: 0.7857 - val_loss: 0.4790 - val_acc: 0.7653\n",
      "Epoch 1476/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4682 - acc: 0.7857 - val_loss: 0.4794 - val_acc: 0.7551\n",
      "Epoch 1477/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4683 - acc: 0.7883 - val_loss: 0.4795 - val_acc: 0.7449\n",
      "Epoch 1478/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4682 - acc: 0.7857 - val_loss: 0.4796 - val_acc: 0.7551\n",
      "Epoch 1479/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4682 - acc: 0.7857 - val_loss: 0.4802 - val_acc: 0.7347\n",
      "Epoch 1480/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4682 - acc: 0.7934 - val_loss: 0.4812 - val_acc: 0.7347\n",
      "Epoch 1481/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4684 - acc: 0.7959 - val_loss: 0.4815 - val_acc: 0.7347\n",
      "Epoch 1482/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4683 - acc: 0.7959 - val_loss: 0.4812 - val_acc: 0.7347\n",
      "Epoch 1483/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4683 - acc: 0.7959 - val_loss: 0.4808 - val_acc: 0.7347\n",
      "Epoch 1484/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4682 - acc: 0.7908 - val_loss: 0.4804 - val_acc: 0.7449\n",
      "Epoch 1485/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4682 - acc: 0.7883 - val_loss: 0.4806 - val_acc: 0.7347\n",
      "Epoch 1486/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 13us/step - loss: 0.4681 - acc: 0.7883 - val_loss: 0.4805 - val_acc: 0.7449\n",
      "Epoch 1487/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4681 - acc: 0.7857 - val_loss: 0.4806 - val_acc: 0.7449\n",
      "Epoch 1488/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4681 - acc: 0.7883 - val_loss: 0.4807 - val_acc: 0.7347\n",
      "Epoch 1489/1500\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.4681 - acc: 0.7883 - val_loss: 0.4804 - val_acc: 0.7449\n",
      "Epoch 1490/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4680 - acc: 0.7832 - val_loss: 0.4801 - val_acc: 0.7551\n",
      "Epoch 1491/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4681 - acc: 0.7832 - val_loss: 0.4798 - val_acc: 0.7653\n",
      "Epoch 1492/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4679 - acc: 0.7832 - val_loss: 0.4793 - val_acc: 0.7653\n",
      "Epoch 1493/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4681 - acc: 0.7832 - val_loss: 0.4788 - val_acc: 0.7755\n",
      "Epoch 1494/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4683 - acc: 0.7832 - val_loss: 0.4785 - val_acc: 0.7755\n",
      "Epoch 1495/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4684 - acc: 0.7857 - val_loss: 0.4785 - val_acc: 0.7755\n",
      "Epoch 1496/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4683 - acc: 0.7832 - val_loss: 0.4785 - val_acc: 0.7755\n",
      "Epoch 1497/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4682 - acc: 0.7832 - val_loss: 0.4784 - val_acc: 0.7755\n",
      "Epoch 1498/1500\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.4682 - acc: 0.7857 - val_loss: 0.4781 - val_acc: 0.7755\n",
      "Epoch 1499/1500\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.4687 - acc: 0.7857 - val_loss: 0.4778 - val_acc: 0.7755\n",
      "Epoch 1500/1500\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.4691 - acc: 0.7857 - val_loss: 0.4777 - val_acc: 0.7755\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val,y_val),epochs=1500,batch_size=128,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 25us/step\n",
      "[0.47769237203257425, 0.7755102040816326]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model on validation data\n",
    "evaluate = model.evaluate(X_val,y_val)\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
