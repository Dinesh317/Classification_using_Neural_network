{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symptom1</th>\n",
       "      <th>symptom2</th>\n",
       "      <th>symptom3</th>\n",
       "      <th>symptom4</th>\n",
       "      <th>symptom5</th>\n",
       "      <th>symptom6</th>\n",
       "      <th>symptom7</th>\n",
       "      <th>symptom8</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symptom1  symptom2  symptom3  symptom4  symptom5  symptom6  symptom7  \\\n",
       "0       6.0     148.0      72.0      35.0       0.0      33.6     0.627   \n",
       "1       1.0      85.0      66.0      29.0       0.0      26.6     0.351   \n",
       "2       8.0     183.0      64.0       0.0       0.0      23.3     0.672   \n",
       "3       1.0      89.0      66.0      23.0      94.0      28.1     0.167   \n",
       "4       0.0     137.0      40.0      35.0     168.0      43.1     2.288   \n",
       "\n",
       "   symptom8  results  \n",
       "0      50.0      1.0  \n",
       "1      31.0      0.0  \n",
       "2      32.0      1.0  \n",
       "3      21.0      0.0  \n",
       "4      33.0      1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#read dataset\n",
    "df = pd.read_csv('sample_disease_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#min-max normalization \n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into input (X) and output (y) variables\n",
    "X = x_scaled[:,0:8]\n",
    "y = x_scaled[:,8]\n",
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size=0.2, random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing library \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.plot_model(model, to_file='model.jpg',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/ndesignai/VENVS/image/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 392 samples, validate on 98 samples\n",
      "Epoch 1/1000\n",
      "392/392 [==============================] - 0s 511us/step - loss: 0.7066 - acc: 0.5587 - val_loss: 0.6942 - val_acc: 0.6531\n",
      "Epoch 2/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.7047 - acc: 0.5612 - val_loss: 0.6933 - val_acc: 0.6633\n",
      "Epoch 3/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.7033 - acc: 0.5791 - val_loss: 0.6926 - val_acc: 0.6429\n",
      "Epoch 4/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.7020 - acc: 0.5918 - val_loss: 0.6919 - val_acc: 0.6327\n",
      "Epoch 5/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.7009 - acc: 0.5969 - val_loss: 0.6913 - val_acc: 0.6429\n",
      "Epoch 6/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6999 - acc: 0.6046 - val_loss: 0.6905 - val_acc: 0.6531\n",
      "Epoch 7/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6987 - acc: 0.6071 - val_loss: 0.6898 - val_acc: 0.6633\n",
      "Epoch 8/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6976 - acc: 0.6097 - val_loss: 0.6892 - val_acc: 0.6429\n",
      "Epoch 9/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6967 - acc: 0.6071 - val_loss: 0.6886 - val_acc: 0.6939\n",
      "Epoch 10/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6956 - acc: 0.6122 - val_loss: 0.6881 - val_acc: 0.6837\n",
      "Epoch 11/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6946 - acc: 0.6199 - val_loss: 0.6875 - val_acc: 0.6837\n",
      "Epoch 12/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6939 - acc: 0.6224 - val_loss: 0.6869 - val_acc: 0.6735\n",
      "Epoch 13/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6929 - acc: 0.6276 - val_loss: 0.6865 - val_acc: 0.6531\n",
      "Epoch 14/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6920 - acc: 0.6173 - val_loss: 0.6860 - val_acc: 0.6429\n",
      "Epoch 15/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6911 - acc: 0.6352 - val_loss: 0.6856 - val_acc: 0.6429\n",
      "Epoch 16/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6901 - acc: 0.6378 - val_loss: 0.6852 - val_acc: 0.6224\n",
      "Epoch 17/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6892 - acc: 0.6429 - val_loss: 0.6847 - val_acc: 0.6327\n",
      "Epoch 18/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6884 - acc: 0.6378 - val_loss: 0.6843 - val_acc: 0.6327\n",
      "Epoch 19/1000\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6877 - acc: 0.6429 - val_loss: 0.6839 - val_acc: 0.6531\n",
      "Epoch 20/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6871 - acc: 0.6378 - val_loss: 0.6835 - val_acc: 0.6633\n",
      "Epoch 21/1000\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6865 - acc: 0.6352 - val_loss: 0.6830 - val_acc: 0.6735\n",
      "Epoch 22/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6858 - acc: 0.6301 - val_loss: 0.6826 - val_acc: 0.6735\n",
      "Epoch 23/1000\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6854 - acc: 0.6301 - val_loss: 0.6821 - val_acc: 0.6735\n",
      "Epoch 24/1000\n",
      "392/392 [==============================] - 0s 22us/step - loss: 0.6849 - acc: 0.6301 - val_loss: 0.6817 - val_acc: 0.6735\n",
      "Epoch 25/1000\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.6842 - acc: 0.6378 - val_loss: 0.6812 - val_acc: 0.6735\n",
      "Epoch 26/1000\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6836 - acc: 0.6352 - val_loss: 0.6808 - val_acc: 0.6531\n",
      "Epoch 27/1000\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.6830 - acc: 0.6378 - val_loss: 0.6803 - val_acc: 0.6429\n",
      "Epoch 28/1000\n",
      "392/392 [==============================] - 0s 23us/step - loss: 0.6825 - acc: 0.6429 - val_loss: 0.6800 - val_acc: 0.6429\n",
      "Epoch 29/1000\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.6820 - acc: 0.6403 - val_loss: 0.6796 - val_acc: 0.6429\n",
      "Epoch 30/1000\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.6816 - acc: 0.6378 - val_loss: 0.6792 - val_acc: 0.6429\n",
      "Epoch 31/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6811 - acc: 0.6352 - val_loss: 0.6788 - val_acc: 0.6429\n",
      "Epoch 32/1000\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6805 - acc: 0.6454 - val_loss: 0.6784 - val_acc: 0.6429\n",
      "Epoch 33/1000\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.6800 - acc: 0.6480 - val_loss: 0.6780 - val_acc: 0.6429\n",
      "Epoch 34/1000\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.6795 - acc: 0.6505 - val_loss: 0.6776 - val_acc: 0.6429\n",
      "Epoch 35/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6790 - acc: 0.6531 - val_loss: 0.6771 - val_acc: 0.6531\n",
      "Epoch 36/1000\n",
      "392/392 [==============================] - 0s 22us/step - loss: 0.6785 - acc: 0.6505 - val_loss: 0.6767 - val_acc: 0.6633\n",
      "Epoch 37/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6779 - acc: 0.6556 - val_loss: 0.6763 - val_acc: 0.6633\n",
      "Epoch 38/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6774 - acc: 0.6531 - val_loss: 0.6759 - val_acc: 0.6633\n",
      "Epoch 39/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6770 - acc: 0.6531 - val_loss: 0.6756 - val_acc: 0.6531\n",
      "Epoch 40/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6765 - acc: 0.6505 - val_loss: 0.6753 - val_acc: 0.6429\n",
      "Epoch 41/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6761 - acc: 0.6505 - val_loss: 0.6749 - val_acc: 0.6429\n",
      "Epoch 42/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6755 - acc: 0.6582 - val_loss: 0.6746 - val_acc: 0.6327\n",
      "Epoch 43/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6750 - acc: 0.6556 - val_loss: 0.6743 - val_acc: 0.6429\n",
      "Epoch 44/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6744 - acc: 0.6531 - val_loss: 0.6740 - val_acc: 0.6429\n",
      "Epoch 45/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6739 - acc: 0.6531 - val_loss: 0.6737 - val_acc: 0.6429\n",
      "Epoch 46/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6735 - acc: 0.6607 - val_loss: 0.6734 - val_acc: 0.6429\n",
      "Epoch 47/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6729 - acc: 0.6633 - val_loss: 0.6732 - val_acc: 0.6429\n",
      "Epoch 48/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6725 - acc: 0.6684 - val_loss: 0.6731 - val_acc: 0.6429\n",
      "Epoch 49/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6720 - acc: 0.6658 - val_loss: 0.6729 - val_acc: 0.6327\n",
      "Epoch 50/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6716 - acc: 0.6633 - val_loss: 0.6727 - val_acc: 0.6224\n",
      "Epoch 51/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6712 - acc: 0.6658 - val_loss: 0.6724 - val_acc: 0.6224\n",
      "Epoch 52/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6708 - acc: 0.6658 - val_loss: 0.6722 - val_acc: 0.6224\n",
      "Epoch 53/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6705 - acc: 0.6684 - val_loss: 0.6719 - val_acc: 0.6224\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 14us/step - loss: 0.6701 - acc: 0.6684 - val_loss: 0.6716 - val_acc: 0.6224\n",
      "Epoch 55/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6697 - acc: 0.6684 - val_loss: 0.6713 - val_acc: 0.6122\n",
      "Epoch 56/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6694 - acc: 0.6709 - val_loss: 0.6711 - val_acc: 0.6122\n",
      "Epoch 57/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6690 - acc: 0.6658 - val_loss: 0.6708 - val_acc: 0.6122\n",
      "Epoch 58/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6687 - acc: 0.6658 - val_loss: 0.6706 - val_acc: 0.6122\n",
      "Epoch 59/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6683 - acc: 0.6709 - val_loss: 0.6703 - val_acc: 0.6224\n",
      "Epoch 60/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6678 - acc: 0.6684 - val_loss: 0.6700 - val_acc: 0.6224\n",
      "Epoch 61/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6675 - acc: 0.6684 - val_loss: 0.6698 - val_acc: 0.6429\n",
      "Epoch 62/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6670 - acc: 0.6684 - val_loss: 0.6695 - val_acc: 0.6429\n",
      "Epoch 63/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6666 - acc: 0.6658 - val_loss: 0.6693 - val_acc: 0.6429\n",
      "Epoch 64/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6663 - acc: 0.6658 - val_loss: 0.6691 - val_acc: 0.6429\n",
      "Epoch 65/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6660 - acc: 0.6658 - val_loss: 0.6688 - val_acc: 0.6429\n",
      "Epoch 66/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6657 - acc: 0.6684 - val_loss: 0.6686 - val_acc: 0.6429\n",
      "Epoch 67/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6654 - acc: 0.6684 - val_loss: 0.6684 - val_acc: 0.6429\n",
      "Epoch 68/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6651 - acc: 0.6684 - val_loss: 0.6681 - val_acc: 0.6429\n",
      "Epoch 69/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6648 - acc: 0.6684 - val_loss: 0.6679 - val_acc: 0.6429\n",
      "Epoch 70/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6645 - acc: 0.6684 - val_loss: 0.6676 - val_acc: 0.6429\n",
      "Epoch 71/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6642 - acc: 0.6684 - val_loss: 0.6673 - val_acc: 0.6429\n",
      "Epoch 72/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6639 - acc: 0.6684 - val_loss: 0.6670 - val_acc: 0.6429\n",
      "Epoch 73/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6636 - acc: 0.6684 - val_loss: 0.6667 - val_acc: 0.6429\n",
      "Epoch 74/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6633 - acc: 0.6684 - val_loss: 0.6664 - val_acc: 0.6531\n",
      "Epoch 75/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6629 - acc: 0.6684 - val_loss: 0.6662 - val_acc: 0.6531\n",
      "Epoch 76/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6625 - acc: 0.6658 - val_loss: 0.6660 - val_acc: 0.6531\n",
      "Epoch 77/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6622 - acc: 0.6658 - val_loss: 0.6657 - val_acc: 0.6531\n",
      "Epoch 78/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6619 - acc: 0.6658 - val_loss: 0.6655 - val_acc: 0.6531\n",
      "Epoch 79/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6617 - acc: 0.6633 - val_loss: 0.6653 - val_acc: 0.6531\n",
      "Epoch 80/1000\n",
      "392/392 [==============================] - 0s 11us/step - loss: 0.6614 - acc: 0.6633 - val_loss: 0.6651 - val_acc: 0.6531\n",
      "Epoch 81/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6611 - acc: 0.6633 - val_loss: 0.6648 - val_acc: 0.6531\n",
      "Epoch 82/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6609 - acc: 0.6633 - val_loss: 0.6646 - val_acc: 0.6531\n",
      "Epoch 83/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6606 - acc: 0.6633 - val_loss: 0.6643 - val_acc: 0.6531\n",
      "Epoch 84/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6604 - acc: 0.6633 - val_loss: 0.6641 - val_acc: 0.6531\n",
      "Epoch 85/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6601 - acc: 0.6633 - val_loss: 0.6639 - val_acc: 0.6531\n",
      "Epoch 86/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6598 - acc: 0.6633 - val_loss: 0.6637 - val_acc: 0.6531\n",
      "Epoch 87/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6594 - acc: 0.6607 - val_loss: 0.6636 - val_acc: 0.6531\n",
      "Epoch 88/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6592 - acc: 0.6633 - val_loss: 0.6636 - val_acc: 0.6531\n",
      "Epoch 89/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6589 - acc: 0.6709 - val_loss: 0.6634 - val_acc: 0.6531\n",
      "Epoch 90/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6586 - acc: 0.6709 - val_loss: 0.6633 - val_acc: 0.6531\n",
      "Epoch 91/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6584 - acc: 0.6684 - val_loss: 0.6631 - val_acc: 0.6531\n",
      "Epoch 92/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6581 - acc: 0.6658 - val_loss: 0.6629 - val_acc: 0.6531\n",
      "Epoch 93/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6579 - acc: 0.6658 - val_loss: 0.6627 - val_acc: 0.6531\n",
      "Epoch 94/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6577 - acc: 0.6658 - val_loss: 0.6625 - val_acc: 0.6531\n",
      "Epoch 95/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6575 - acc: 0.6658 - val_loss: 0.6623 - val_acc: 0.6531\n",
      "Epoch 96/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6573 - acc: 0.6684 - val_loss: 0.6620 - val_acc: 0.6531\n",
      "Epoch 97/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6570 - acc: 0.6684 - val_loss: 0.6618 - val_acc: 0.6531\n",
      "Epoch 98/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6568 - acc: 0.6684 - val_loss: 0.6615 - val_acc: 0.6531\n",
      "Epoch 99/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6566 - acc: 0.6684 - val_loss: 0.6613 - val_acc: 0.6531\n",
      "Epoch 100/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6563 - acc: 0.6684 - val_loss: 0.6610 - val_acc: 0.6531\n",
      "Epoch 101/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6561 - acc: 0.6684 - val_loss: 0.6609 - val_acc: 0.6531\n",
      "Epoch 102/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6559 - acc: 0.6658 - val_loss: 0.6607 - val_acc: 0.6531\n",
      "Epoch 103/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6557 - acc: 0.6658 - val_loss: 0.6605 - val_acc: 0.6531\n",
      "Epoch 104/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6556 - acc: 0.6684 - val_loss: 0.6602 - val_acc: 0.6531\n",
      "Epoch 105/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6554 - acc: 0.6709 - val_loss: 0.6600 - val_acc: 0.6531\n",
      "Epoch 106/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6552 - acc: 0.6684 - val_loss: 0.6598 - val_acc: 0.6531\n",
      "Epoch 107/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6550 - acc: 0.6709 - val_loss: 0.6597 - val_acc: 0.6531\n",
      "Epoch 108/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6548 - acc: 0.6684 - val_loss: 0.6595 - val_acc: 0.6531\n",
      "Epoch 109/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6545 - acc: 0.6684 - val_loss: 0.6593 - val_acc: 0.6531\n",
      "Epoch 110/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6543 - acc: 0.6658 - val_loss: 0.6592 - val_acc: 0.6531\n",
      "Epoch 111/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6541 - acc: 0.6658 - val_loss: 0.6591 - val_acc: 0.6531\n",
      "Epoch 112/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6539 - acc: 0.6633 - val_loss: 0.6590 - val_acc: 0.6531\n",
      "Epoch 113/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6538 - acc: 0.6658 - val_loss: 0.6589 - val_acc: 0.6531\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 15us/step - loss: 0.6537 - acc: 0.6658 - val_loss: 0.6587 - val_acc: 0.6531\n",
      "Epoch 115/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6535 - acc: 0.6633 - val_loss: 0.6587 - val_acc: 0.6531\n",
      "Epoch 116/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.6533 - acc: 0.6658 - val_loss: 0.6587 - val_acc: 0.6429\n",
      "Epoch 117/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6531 - acc: 0.6658 - val_loss: 0.6586 - val_acc: 0.6429\n",
      "Epoch 118/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6529 - acc: 0.6658 - val_loss: 0.6583 - val_acc: 0.6429\n",
      "Epoch 119/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6527 - acc: 0.6658 - val_loss: 0.6581 - val_acc: 0.6429\n",
      "Epoch 120/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6525 - acc: 0.6658 - val_loss: 0.6580 - val_acc: 0.6429\n",
      "Epoch 121/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6523 - acc: 0.6658 - val_loss: 0.6580 - val_acc: 0.6429\n",
      "Epoch 122/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6522 - acc: 0.6658 - val_loss: 0.6579 - val_acc: 0.6429\n",
      "Epoch 123/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6520 - acc: 0.6658 - val_loss: 0.6579 - val_acc: 0.6327\n",
      "Epoch 124/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6519 - acc: 0.6633 - val_loss: 0.6579 - val_acc: 0.6327\n",
      "Epoch 125/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6517 - acc: 0.6633 - val_loss: 0.6577 - val_acc: 0.6327\n",
      "Epoch 126/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6515 - acc: 0.6633 - val_loss: 0.6576 - val_acc: 0.6327\n",
      "Epoch 127/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6513 - acc: 0.6633 - val_loss: 0.6573 - val_acc: 0.6327\n",
      "Epoch 128/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6512 - acc: 0.6633 - val_loss: 0.6571 - val_acc: 0.6327\n",
      "Epoch 129/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.6633 - val_loss: 0.6570 - val_acc: 0.6327\n",
      "Epoch 130/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6508 - acc: 0.6633 - val_loss: 0.6568 - val_acc: 0.6327\n",
      "Epoch 131/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6506 - acc: 0.6633 - val_loss: 0.6565 - val_acc: 0.6327\n",
      "Epoch 132/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.6658 - val_loss: 0.6562 - val_acc: 0.6429\n",
      "Epoch 133/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6503 - acc: 0.6658 - val_loss: 0.6557 - val_acc: 0.6429\n",
      "Epoch 134/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6501 - acc: 0.6658 - val_loss: 0.6554 - val_acc: 0.6531\n",
      "Epoch 135/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6499 - acc: 0.6658 - val_loss: 0.6550 - val_acc: 0.6531\n",
      "Epoch 136/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6497 - acc: 0.6658 - val_loss: 0.6545 - val_acc: 0.6531\n",
      "Epoch 137/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6496 - acc: 0.6658 - val_loss: 0.6541 - val_acc: 0.6531\n",
      "Epoch 138/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.6658 - val_loss: 0.6539 - val_acc: 0.6531\n",
      "Epoch 139/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6493 - acc: 0.6658 - val_loss: 0.6537 - val_acc: 0.6531\n",
      "Epoch 140/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6491 - acc: 0.6658 - val_loss: 0.6535 - val_acc: 0.6531\n",
      "Epoch 141/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6489 - acc: 0.6658 - val_loss: 0.6534 - val_acc: 0.6531\n",
      "Epoch 142/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6487 - acc: 0.6684 - val_loss: 0.6532 - val_acc: 0.6531\n",
      "Epoch 143/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6485 - acc: 0.6658 - val_loss: 0.6531 - val_acc: 0.6531\n",
      "Epoch 144/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6483 - acc: 0.6658 - val_loss: 0.6528 - val_acc: 0.6531\n",
      "Epoch 145/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6481 - acc: 0.6658 - val_loss: 0.6526 - val_acc: 0.6531\n",
      "Epoch 146/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6479 - acc: 0.6658 - val_loss: 0.6524 - val_acc: 0.6531\n",
      "Epoch 147/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6477 - acc: 0.6658 - val_loss: 0.6522 - val_acc: 0.6531\n",
      "Epoch 148/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6476 - acc: 0.6658 - val_loss: 0.6520 - val_acc: 0.6531\n",
      "Epoch 149/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6474 - acc: 0.6658 - val_loss: 0.6518 - val_acc: 0.6531\n",
      "Epoch 150/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6472 - acc: 0.6684 - val_loss: 0.6515 - val_acc: 0.6531\n",
      "Epoch 151/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6469 - acc: 0.6684 - val_loss: 0.6511 - val_acc: 0.6531\n",
      "Epoch 152/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6467 - acc: 0.6658 - val_loss: 0.6506 - val_acc: 0.6531\n",
      "Epoch 153/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6465 - acc: 0.6658 - val_loss: 0.6501 - val_acc: 0.6531\n",
      "Epoch 154/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6462 - acc: 0.6658 - val_loss: 0.6497 - val_acc: 0.6531\n",
      "Epoch 155/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6459 - acc: 0.6684 - val_loss: 0.6494 - val_acc: 0.6531\n",
      "Epoch 156/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6456 - acc: 0.6684 - val_loss: 0.6492 - val_acc: 0.6531\n",
      "Epoch 157/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6454 - acc: 0.6684 - val_loss: 0.6490 - val_acc: 0.6531\n",
      "Epoch 158/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6452 - acc: 0.6684 - val_loss: 0.6488 - val_acc: 0.6531\n",
      "Epoch 159/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6450 - acc: 0.6658 - val_loss: 0.6485 - val_acc: 0.6531\n",
      "Epoch 160/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6447 - acc: 0.6684 - val_loss: 0.6482 - val_acc: 0.6531\n",
      "Epoch 161/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.6445 - acc: 0.6684 - val_loss: 0.6479 - val_acc: 0.6531\n",
      "Epoch 162/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6443 - acc: 0.6684 - val_loss: 0.6476 - val_acc: 0.6531\n",
      "Epoch 163/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6440 - acc: 0.6709 - val_loss: 0.6472 - val_acc: 0.6531\n",
      "Epoch 164/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6437 - acc: 0.6735 - val_loss: 0.6467 - val_acc: 0.6531\n",
      "Epoch 165/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6433 - acc: 0.6709 - val_loss: 0.6460 - val_acc: 0.6429\n",
      "Epoch 166/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6429 - acc: 0.6735 - val_loss: 0.6454 - val_acc: 0.6531\n",
      "Epoch 167/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6426 - acc: 0.6735 - val_loss: 0.6447 - val_acc: 0.6531\n",
      "Epoch 168/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6422 - acc: 0.6786 - val_loss: 0.6441 - val_acc: 0.6531\n",
      "Epoch 169/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6420 - acc: 0.6760 - val_loss: 0.6433 - val_acc: 0.6429\n",
      "Epoch 170/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6416 - acc: 0.6786 - val_loss: 0.6426 - val_acc: 0.6429\n",
      "Epoch 171/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6413 - acc: 0.6760 - val_loss: 0.6416 - val_acc: 0.6429\n",
      "Epoch 172/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6410 - acc: 0.6735 - val_loss: 0.6406 - val_acc: 0.6429\n",
      "Epoch 173/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6406 - acc: 0.6786 - val_loss: 0.6400 - val_acc: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6402 - acc: 0.6786 - val_loss: 0.6396 - val_acc: 0.6429\n",
      "Epoch 175/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6399 - acc: 0.6811 - val_loss: 0.6391 - val_acc: 0.6429\n",
      "Epoch 176/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6395 - acc: 0.6811 - val_loss: 0.6386 - val_acc: 0.6429\n",
      "Epoch 177/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6391 - acc: 0.6811 - val_loss: 0.6382 - val_acc: 0.6429\n",
      "Epoch 178/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6387 - acc: 0.6811 - val_loss: 0.6379 - val_acc: 0.6429\n",
      "Epoch 179/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6384 - acc: 0.6786 - val_loss: 0.6376 - val_acc: 0.6429\n",
      "Epoch 180/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6381 - acc: 0.6786 - val_loss: 0.6376 - val_acc: 0.6429\n",
      "Epoch 181/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6378 - acc: 0.6811 - val_loss: 0.6374 - val_acc: 0.6429\n",
      "Epoch 182/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6375 - acc: 0.6837 - val_loss: 0.6372 - val_acc: 0.6429\n",
      "Epoch 183/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6372 - acc: 0.6811 - val_loss: 0.6370 - val_acc: 0.6429\n",
      "Epoch 184/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6369 - acc: 0.6786 - val_loss: 0.6368 - val_acc: 0.6429\n",
      "Epoch 185/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6366 - acc: 0.6760 - val_loss: 0.6364 - val_acc: 0.6429\n",
      "Epoch 186/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6363 - acc: 0.6760 - val_loss: 0.6362 - val_acc: 0.6429\n",
      "Epoch 187/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6360 - acc: 0.6760 - val_loss: 0.6360 - val_acc: 0.6531\n",
      "Epoch 188/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6357 - acc: 0.6786 - val_loss: 0.6357 - val_acc: 0.6531\n",
      "Epoch 189/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6353 - acc: 0.6786 - val_loss: 0.6353 - val_acc: 0.6531\n",
      "Epoch 190/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6350 - acc: 0.6786 - val_loss: 0.6349 - val_acc: 0.6531\n",
      "Epoch 191/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6347 - acc: 0.6786 - val_loss: 0.6344 - val_acc: 0.6531\n",
      "Epoch 192/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6344 - acc: 0.6786 - val_loss: 0.6341 - val_acc: 0.6531\n",
      "Epoch 193/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6341 - acc: 0.6786 - val_loss: 0.6336 - val_acc: 0.6531\n",
      "Epoch 194/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6337 - acc: 0.6786 - val_loss: 0.6332 - val_acc: 0.6531\n",
      "Epoch 195/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6334 - acc: 0.6760 - val_loss: 0.6328 - val_acc: 0.6531\n",
      "Epoch 196/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6331 - acc: 0.6786 - val_loss: 0.6328 - val_acc: 0.6531\n",
      "Epoch 197/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6329 - acc: 0.6811 - val_loss: 0.6327 - val_acc: 0.6531\n",
      "Epoch 198/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6327 - acc: 0.6735 - val_loss: 0.6326 - val_acc: 0.6531\n",
      "Epoch 199/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6324 - acc: 0.6735 - val_loss: 0.6322 - val_acc: 0.6531\n",
      "Epoch 200/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6321 - acc: 0.6735 - val_loss: 0.6318 - val_acc: 0.6633\n",
      "Epoch 201/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6317 - acc: 0.6760 - val_loss: 0.6317 - val_acc: 0.6531\n",
      "Epoch 202/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6315 - acc: 0.6735 - val_loss: 0.6315 - val_acc: 0.6531\n",
      "Epoch 203/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6312 - acc: 0.6709 - val_loss: 0.6314 - val_acc: 0.6531\n",
      "Epoch 204/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6310 - acc: 0.6709 - val_loss: 0.6312 - val_acc: 0.6531\n",
      "Epoch 205/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6307 - acc: 0.6709 - val_loss: 0.6309 - val_acc: 0.6531\n",
      "Epoch 206/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6305 - acc: 0.6709 - val_loss: 0.6303 - val_acc: 0.6531\n",
      "Epoch 207/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6300 - acc: 0.6735 - val_loss: 0.6297 - val_acc: 0.6429\n",
      "Epoch 208/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6296 - acc: 0.6735 - val_loss: 0.6292 - val_acc: 0.6531\n",
      "Epoch 209/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6293 - acc: 0.6709 - val_loss: 0.6288 - val_acc: 0.6531\n",
      "Epoch 210/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6290 - acc: 0.6709 - val_loss: 0.6283 - val_acc: 0.6531\n",
      "Epoch 211/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6288 - acc: 0.6735 - val_loss: 0.6275 - val_acc: 0.6633\n",
      "Epoch 212/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6284 - acc: 0.6786 - val_loss: 0.6269 - val_acc: 0.6633\n",
      "Epoch 213/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6280 - acc: 0.6888 - val_loss: 0.6262 - val_acc: 0.6633\n",
      "Epoch 214/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6277 - acc: 0.6862 - val_loss: 0.6256 - val_acc: 0.6633\n",
      "Epoch 215/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6274 - acc: 0.6888 - val_loss: 0.6249 - val_acc: 0.6633\n",
      "Epoch 216/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6271 - acc: 0.6862 - val_loss: 0.6242 - val_acc: 0.6531\n",
      "Epoch 217/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6269 - acc: 0.6888 - val_loss: 0.6234 - val_acc: 0.6531\n",
      "Epoch 218/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6266 - acc: 0.6939 - val_loss: 0.6230 - val_acc: 0.6429\n",
      "Epoch 219/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6266 - acc: 0.6888 - val_loss: 0.6225 - val_acc: 0.6429\n",
      "Epoch 220/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6263 - acc: 0.6862 - val_loss: 0.6221 - val_acc: 0.6429\n",
      "Epoch 221/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6260 - acc: 0.6862 - val_loss: 0.6218 - val_acc: 0.6429\n",
      "Epoch 222/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6257 - acc: 0.6862 - val_loss: 0.6215 - val_acc: 0.6531\n",
      "Epoch 223/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6254 - acc: 0.6888 - val_loss: 0.6212 - val_acc: 0.6429\n",
      "Epoch 224/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6250 - acc: 0.6888 - val_loss: 0.6209 - val_acc: 0.6429\n",
      "Epoch 225/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6246 - acc: 0.6888 - val_loss: 0.6206 - val_acc: 0.6531\n",
      "Epoch 226/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6242 - acc: 0.6888 - val_loss: 0.6203 - val_acc: 0.6633\n",
      "Epoch 227/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6239 - acc: 0.6888 - val_loss: 0.6200 - val_acc: 0.6633\n",
      "Epoch 228/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6235 - acc: 0.6862 - val_loss: 0.6199 - val_acc: 0.6633\n",
      "Epoch 229/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6231 - acc: 0.6862 - val_loss: 0.6196 - val_acc: 0.6633\n",
      "Epoch 230/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6228 - acc: 0.6862 - val_loss: 0.6195 - val_acc: 0.6531\n",
      "Epoch 231/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6224 - acc: 0.6939 - val_loss: 0.6196 - val_acc: 0.6531\n",
      "Epoch 232/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6221 - acc: 0.6913 - val_loss: 0.6195 - val_acc: 0.6531\n",
      "Epoch 233/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6218 - acc: 0.6913 - val_loss: 0.6190 - val_acc: 0.6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6215 - acc: 0.6913 - val_loss: 0.6185 - val_acc: 0.6531\n",
      "Epoch 235/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6212 - acc: 0.6862 - val_loss: 0.6179 - val_acc: 0.6633\n",
      "Epoch 236/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6209 - acc: 0.6888 - val_loss: 0.6175 - val_acc: 0.6633\n",
      "Epoch 237/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6206 - acc: 0.6888 - val_loss: 0.6172 - val_acc: 0.6735\n",
      "Epoch 238/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6203 - acc: 0.6888 - val_loss: 0.6169 - val_acc: 0.6735\n",
      "Epoch 239/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6200 - acc: 0.6862 - val_loss: 0.6167 - val_acc: 0.6735\n",
      "Epoch 240/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6197 - acc: 0.6862 - val_loss: 0.6162 - val_acc: 0.6837\n",
      "Epoch 241/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6194 - acc: 0.6888 - val_loss: 0.6158 - val_acc: 0.6837\n",
      "Epoch 242/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6191 - acc: 0.6888 - val_loss: 0.6155 - val_acc: 0.6837\n",
      "Epoch 243/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6188 - acc: 0.6862 - val_loss: 0.6151 - val_acc: 0.6837\n",
      "Epoch 244/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6185 - acc: 0.6888 - val_loss: 0.6149 - val_acc: 0.6837\n",
      "Epoch 245/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6181 - acc: 0.6888 - val_loss: 0.6146 - val_acc: 0.6837\n",
      "Epoch 246/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6177 - acc: 0.6888 - val_loss: 0.6144 - val_acc: 0.6837\n",
      "Epoch 247/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6174 - acc: 0.6888 - val_loss: 0.6141 - val_acc: 0.6837\n",
      "Epoch 248/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6171 - acc: 0.6888 - val_loss: 0.6137 - val_acc: 0.6837\n",
      "Epoch 249/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6168 - acc: 0.6888 - val_loss: 0.6133 - val_acc: 0.6837\n",
      "Epoch 250/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6166 - acc: 0.6888 - val_loss: 0.6130 - val_acc: 0.6837\n",
      "Epoch 251/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6163 - acc: 0.6862 - val_loss: 0.6126 - val_acc: 0.6939\n",
      "Epoch 252/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6160 - acc: 0.6862 - val_loss: 0.6122 - val_acc: 0.6939\n",
      "Epoch 253/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6158 - acc: 0.6862 - val_loss: 0.6117 - val_acc: 0.7143\n",
      "Epoch 254/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6155 - acc: 0.6837 - val_loss: 0.6113 - val_acc: 0.7143\n",
      "Epoch 255/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6152 - acc: 0.6862 - val_loss: 0.6113 - val_acc: 0.6939\n",
      "Epoch 256/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6147 - acc: 0.6888 - val_loss: 0.6112 - val_acc: 0.6837\n",
      "Epoch 257/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6143 - acc: 0.6888 - val_loss: 0.6112 - val_acc: 0.6837\n",
      "Epoch 258/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6139 - acc: 0.6837 - val_loss: 0.6114 - val_acc: 0.6837\n",
      "Epoch 259/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6139 - acc: 0.6811 - val_loss: 0.6114 - val_acc: 0.6939\n",
      "Epoch 260/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6136 - acc: 0.6811 - val_loss: 0.6112 - val_acc: 0.6939\n",
      "Epoch 261/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6133 - acc: 0.6811 - val_loss: 0.6109 - val_acc: 0.6939\n",
      "Epoch 262/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6130 - acc: 0.6811 - val_loss: 0.6105 - val_acc: 0.6939\n",
      "Epoch 263/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6126 - acc: 0.6837 - val_loss: 0.6099 - val_acc: 0.6837\n",
      "Epoch 264/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6123 - acc: 0.6862 - val_loss: 0.6094 - val_acc: 0.6837\n",
      "Epoch 265/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6119 - acc: 0.6862 - val_loss: 0.6090 - val_acc: 0.6837\n",
      "Epoch 266/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6116 - acc: 0.6837 - val_loss: 0.6085 - val_acc: 0.6837\n",
      "Epoch 267/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6113 - acc: 0.6837 - val_loss: 0.6081 - val_acc: 0.6837\n",
      "Epoch 268/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6110 - acc: 0.6862 - val_loss: 0.6078 - val_acc: 0.6837\n",
      "Epoch 269/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6107 - acc: 0.6837 - val_loss: 0.6077 - val_acc: 0.6837\n",
      "Epoch 270/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6104 - acc: 0.6837 - val_loss: 0.6077 - val_acc: 0.6837\n",
      "Epoch 271/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6102 - acc: 0.6837 - val_loss: 0.6074 - val_acc: 0.6837\n",
      "Epoch 272/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6098 - acc: 0.6837 - val_loss: 0.6069 - val_acc: 0.6837\n",
      "Epoch 273/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6096 - acc: 0.6837 - val_loss: 0.6064 - val_acc: 0.6939\n",
      "Epoch 274/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6093 - acc: 0.6837 - val_loss: 0.6062 - val_acc: 0.6939\n",
      "Epoch 275/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6090 - acc: 0.6837 - val_loss: 0.6059 - val_acc: 0.6939\n",
      "Epoch 276/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6088 - acc: 0.6837 - val_loss: 0.6058 - val_acc: 0.6837\n",
      "Epoch 277/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6085 - acc: 0.6837 - val_loss: 0.6057 - val_acc: 0.6837\n",
      "Epoch 278/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6083 - acc: 0.6837 - val_loss: 0.6056 - val_acc: 0.6837\n",
      "Epoch 279/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6080 - acc: 0.6837 - val_loss: 0.6052 - val_acc: 0.6837\n",
      "Epoch 280/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.6077 - acc: 0.6837 - val_loss: 0.6051 - val_acc: 0.6837\n",
      "Epoch 281/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6074 - acc: 0.6837 - val_loss: 0.6050 - val_acc: 0.6837\n",
      "Epoch 282/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6072 - acc: 0.6837 - val_loss: 0.6048 - val_acc: 0.6837\n",
      "Epoch 283/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6070 - acc: 0.6837 - val_loss: 0.6047 - val_acc: 0.6837\n",
      "Epoch 284/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6067 - acc: 0.6862 - val_loss: 0.6047 - val_acc: 0.6837\n",
      "Epoch 285/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6065 - acc: 0.6862 - val_loss: 0.6047 - val_acc: 0.6837\n",
      "Epoch 286/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6064 - acc: 0.6837 - val_loss: 0.6051 - val_acc: 0.6837\n",
      "Epoch 287/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6064 - acc: 0.6837 - val_loss: 0.6053 - val_acc: 0.6837\n",
      "Epoch 288/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6063 - acc: 0.6862 - val_loss: 0.6054 - val_acc: 0.6837\n",
      "Epoch 289/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6061 - acc: 0.6888 - val_loss: 0.6053 - val_acc: 0.6837\n",
      "Epoch 290/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6059 - acc: 0.6888 - val_loss: 0.6052 - val_acc: 0.6837\n",
      "Epoch 291/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6057 - acc: 0.6888 - val_loss: 0.6049 - val_acc: 0.6837\n",
      "Epoch 292/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6054 - acc: 0.6888 - val_loss: 0.6047 - val_acc: 0.6837\n",
      "Epoch 293/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6051 - acc: 0.6888 - val_loss: 0.6046 - val_acc: 0.6837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6050 - acc: 0.6888 - val_loss: 0.6047 - val_acc: 0.6837\n",
      "Epoch 295/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6048 - acc: 0.6888 - val_loss: 0.6039 - val_acc: 0.6837\n",
      "Epoch 296/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6042 - acc: 0.6913 - val_loss: 0.6032 - val_acc: 0.6837\n",
      "Epoch 297/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6039 - acc: 0.6837 - val_loss: 0.6021 - val_acc: 0.6837\n",
      "Epoch 298/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.6035 - acc: 0.6837 - val_loss: 0.6015 - val_acc: 0.6837\n",
      "Epoch 299/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6032 - acc: 0.6862 - val_loss: 0.6012 - val_acc: 0.6837\n",
      "Epoch 300/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6030 - acc: 0.6862 - val_loss: 0.6008 - val_acc: 0.6735\n",
      "Epoch 301/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6027 - acc: 0.6862 - val_loss: 0.6003 - val_acc: 0.6837\n",
      "Epoch 302/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.6025 - acc: 0.6862 - val_loss: 0.6000 - val_acc: 0.6939\n",
      "Epoch 303/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6023 - acc: 0.6888 - val_loss: 0.5999 - val_acc: 0.6939\n",
      "Epoch 304/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6021 - acc: 0.6888 - val_loss: 0.5996 - val_acc: 0.6939\n",
      "Epoch 305/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6019 - acc: 0.6888 - val_loss: 0.5991 - val_acc: 0.6939\n",
      "Epoch 306/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6017 - acc: 0.6862 - val_loss: 0.5985 - val_acc: 0.7041\n",
      "Epoch 307/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6016 - acc: 0.6837 - val_loss: 0.5982 - val_acc: 0.7041\n",
      "Epoch 308/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6014 - acc: 0.6862 - val_loss: 0.5980 - val_acc: 0.7041\n",
      "Epoch 309/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6012 - acc: 0.6862 - val_loss: 0.5978 - val_acc: 0.7041\n",
      "Epoch 310/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6009 - acc: 0.6862 - val_loss: 0.5976 - val_acc: 0.7041\n",
      "Epoch 311/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6007 - acc: 0.6862 - val_loss: 0.5976 - val_acc: 0.7041\n",
      "Epoch 312/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.6005 - acc: 0.6888 - val_loss: 0.5977 - val_acc: 0.7041\n",
      "Epoch 313/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.6002 - acc: 0.6888 - val_loss: 0.5977 - val_acc: 0.6939\n",
      "Epoch 314/1000\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.5999 - acc: 0.6888 - val_loss: 0.5977 - val_acc: 0.6837\n",
      "Epoch 315/1000\n",
      "392/392 [==============================] - 0s 27us/step - loss: 0.5998 - acc: 0.6888 - val_loss: 0.5978 - val_acc: 0.6837\n",
      "Epoch 316/1000\n",
      "392/392 [==============================] - 0s 25us/step - loss: 0.5996 - acc: 0.6862 - val_loss: 0.5976 - val_acc: 0.6837\n",
      "Epoch 317/1000\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.5994 - acc: 0.6862 - val_loss: 0.5971 - val_acc: 0.6837\n",
      "Epoch 318/1000\n",
      "392/392 [==============================] - 0s 20us/step - loss: 0.5991 - acc: 0.6888 - val_loss: 0.5966 - val_acc: 0.6939\n",
      "Epoch 319/1000\n",
      "392/392 [==============================] - 0s 21us/step - loss: 0.5989 - acc: 0.6888 - val_loss: 0.5961 - val_acc: 0.7041\n",
      "Epoch 320/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5987 - acc: 0.6913 - val_loss: 0.5955 - val_acc: 0.7041\n",
      "Epoch 321/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5987 - acc: 0.6888 - val_loss: 0.5949 - val_acc: 0.6939\n",
      "Epoch 322/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5985 - acc: 0.6837 - val_loss: 0.5945 - val_acc: 0.6939\n",
      "Epoch 323/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5984 - acc: 0.6888 - val_loss: 0.5942 - val_acc: 0.6939\n",
      "Epoch 324/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5982 - acc: 0.6888 - val_loss: 0.5940 - val_acc: 0.6939\n",
      "Epoch 325/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5979 - acc: 0.6888 - val_loss: 0.5938 - val_acc: 0.6939\n",
      "Epoch 326/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5976 - acc: 0.6888 - val_loss: 0.5937 - val_acc: 0.6939\n",
      "Epoch 327/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5973 - acc: 0.6862 - val_loss: 0.5936 - val_acc: 0.6939\n",
      "Epoch 328/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5971 - acc: 0.6862 - val_loss: 0.5935 - val_acc: 0.6939\n",
      "Epoch 329/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5968 - acc: 0.6837 - val_loss: 0.5935 - val_acc: 0.6939\n",
      "Epoch 330/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5966 - acc: 0.6862 - val_loss: 0.5935 - val_acc: 0.6939\n",
      "Epoch 331/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5963 - acc: 0.6862 - val_loss: 0.5932 - val_acc: 0.6939\n",
      "Epoch 332/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5961 - acc: 0.6837 - val_loss: 0.5929 - val_acc: 0.6939\n",
      "Epoch 333/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5959 - acc: 0.6837 - val_loss: 0.5928 - val_acc: 0.6939\n",
      "Epoch 334/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5957 - acc: 0.6888 - val_loss: 0.5931 - val_acc: 0.7041\n",
      "Epoch 335/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5954 - acc: 0.6888 - val_loss: 0.5929 - val_acc: 0.6939\n",
      "Epoch 336/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5952 - acc: 0.6888 - val_loss: 0.5929 - val_acc: 0.6939\n",
      "Epoch 337/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5950 - acc: 0.6939 - val_loss: 0.5929 - val_acc: 0.6939\n",
      "Epoch 338/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5948 - acc: 0.6939 - val_loss: 0.5925 - val_acc: 0.6837\n",
      "Epoch 339/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5946 - acc: 0.6888 - val_loss: 0.5922 - val_acc: 0.6837\n",
      "Epoch 340/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5943 - acc: 0.6888 - val_loss: 0.5920 - val_acc: 0.6837\n",
      "Epoch 341/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5941 - acc: 0.6888 - val_loss: 0.5918 - val_acc: 0.6837\n",
      "Epoch 342/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5939 - acc: 0.6888 - val_loss: 0.5914 - val_acc: 0.6837\n",
      "Epoch 343/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5937 - acc: 0.6913 - val_loss: 0.5914 - val_acc: 0.6837\n",
      "Epoch 344/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5935 - acc: 0.6888 - val_loss: 0.5916 - val_acc: 0.6939\n",
      "Epoch 345/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5934 - acc: 0.6913 - val_loss: 0.5920 - val_acc: 0.6939\n",
      "Epoch 346/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5933 - acc: 0.6913 - val_loss: 0.5922 - val_acc: 0.6837\n",
      "Epoch 347/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5931 - acc: 0.6888 - val_loss: 0.5920 - val_acc: 0.6837\n",
      "Epoch 348/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5929 - acc: 0.6888 - val_loss: 0.5915 - val_acc: 0.6939\n",
      "Epoch 349/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5926 - acc: 0.6888 - val_loss: 0.5908 - val_acc: 0.6837\n",
      "Epoch 350/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5924 - acc: 0.6913 - val_loss: 0.5900 - val_acc: 0.6837\n",
      "Epoch 351/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5921 - acc: 0.6913 - val_loss: 0.5894 - val_acc: 0.6837\n",
      "Epoch 352/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5919 - acc: 0.6888 - val_loss: 0.5891 - val_acc: 0.6939\n",
      "Epoch 353/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5917 - acc: 0.6888 - val_loss: 0.5886 - val_acc: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5915 - acc: 0.6939 - val_loss: 0.5880 - val_acc: 0.6939\n",
      "Epoch 355/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5914 - acc: 0.6913 - val_loss: 0.5876 - val_acc: 0.6939\n",
      "Epoch 356/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5912 - acc: 0.6888 - val_loss: 0.5873 - val_acc: 0.6939\n",
      "Epoch 357/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5910 - acc: 0.6888 - val_loss: 0.5870 - val_acc: 0.6939\n",
      "Epoch 358/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5908 - acc: 0.6888 - val_loss: 0.5867 - val_acc: 0.6939\n",
      "Epoch 359/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5906 - acc: 0.6939 - val_loss: 0.5865 - val_acc: 0.6939\n",
      "Epoch 360/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5904 - acc: 0.6939 - val_loss: 0.5864 - val_acc: 0.6939\n",
      "Epoch 361/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5902 - acc: 0.6913 - val_loss: 0.5864 - val_acc: 0.6939\n",
      "Epoch 362/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5899 - acc: 0.6888 - val_loss: 0.5863 - val_acc: 0.6939\n",
      "Epoch 363/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5896 - acc: 0.6913 - val_loss: 0.5861 - val_acc: 0.6939\n",
      "Epoch 364/1000\n",
      "392/392 [==============================] - 0s 11us/step - loss: 0.5894 - acc: 0.6939 - val_loss: 0.5857 - val_acc: 0.6939\n",
      "Epoch 365/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5893 - acc: 0.6939 - val_loss: 0.5854 - val_acc: 0.6939\n",
      "Epoch 366/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5891 - acc: 0.6939 - val_loss: 0.5853 - val_acc: 0.6939\n",
      "Epoch 367/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5888 - acc: 0.6939 - val_loss: 0.5854 - val_acc: 0.6939\n",
      "Epoch 368/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5886 - acc: 0.6939 - val_loss: 0.5855 - val_acc: 0.7041\n",
      "Epoch 369/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5884 - acc: 0.6939 - val_loss: 0.5855 - val_acc: 0.6939\n",
      "Epoch 370/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5881 - acc: 0.6939 - val_loss: 0.5855 - val_acc: 0.6939\n",
      "Epoch 371/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5879 - acc: 0.6939 - val_loss: 0.5857 - val_acc: 0.6837\n",
      "Epoch 372/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5878 - acc: 0.6913 - val_loss: 0.5860 - val_acc: 0.6837\n",
      "Epoch 373/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5876 - acc: 0.6837 - val_loss: 0.5860 - val_acc: 0.6939\n",
      "Epoch 374/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5875 - acc: 0.6837 - val_loss: 0.5858 - val_acc: 0.6939\n",
      "Epoch 375/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5873 - acc: 0.6837 - val_loss: 0.5855 - val_acc: 0.6837\n",
      "Epoch 376/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5870 - acc: 0.6837 - val_loss: 0.5850 - val_acc: 0.6837\n",
      "Epoch 377/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5867 - acc: 0.6939 - val_loss: 0.5843 - val_acc: 0.6837\n",
      "Epoch 378/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5864 - acc: 0.6939 - val_loss: 0.5836 - val_acc: 0.7041\n",
      "Epoch 379/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5863 - acc: 0.6964 - val_loss: 0.5830 - val_acc: 0.6939\n",
      "Epoch 380/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5860 - acc: 0.6964 - val_loss: 0.5826 - val_acc: 0.6939\n",
      "Epoch 381/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5859 - acc: 0.6964 - val_loss: 0.5822 - val_acc: 0.6939\n",
      "Epoch 382/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5857 - acc: 0.6939 - val_loss: 0.5820 - val_acc: 0.6939\n",
      "Epoch 383/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5855 - acc: 0.6964 - val_loss: 0.5820 - val_acc: 0.6939\n",
      "Epoch 384/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5853 - acc: 0.6964 - val_loss: 0.5821 - val_acc: 0.6939\n",
      "Epoch 385/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5851 - acc: 0.6990 - val_loss: 0.5820 - val_acc: 0.7041\n",
      "Epoch 386/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5848 - acc: 0.6990 - val_loss: 0.5815 - val_acc: 0.6939\n",
      "Epoch 387/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5847 - acc: 0.6964 - val_loss: 0.5810 - val_acc: 0.6939\n",
      "Epoch 388/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5845 - acc: 0.6964 - val_loss: 0.5808 - val_acc: 0.6939\n",
      "Epoch 389/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5843 - acc: 0.6964 - val_loss: 0.5806 - val_acc: 0.6939\n",
      "Epoch 390/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5842 - acc: 0.7015 - val_loss: 0.5805 - val_acc: 0.6939\n",
      "Epoch 391/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5839 - acc: 0.6964 - val_loss: 0.5806 - val_acc: 0.6939\n",
      "Epoch 392/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5837 - acc: 0.6964 - val_loss: 0.5805 - val_acc: 0.6939\n",
      "Epoch 393/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5836 - acc: 0.6939 - val_loss: 0.5808 - val_acc: 0.6837\n",
      "Epoch 394/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5834 - acc: 0.6990 - val_loss: 0.5811 - val_acc: 0.6939\n",
      "Epoch 395/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5832 - acc: 0.6913 - val_loss: 0.5812 - val_acc: 0.6939\n",
      "Epoch 396/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5831 - acc: 0.6862 - val_loss: 0.5814 - val_acc: 0.6939\n",
      "Epoch 397/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5829 - acc: 0.6862 - val_loss: 0.5816 - val_acc: 0.6939\n",
      "Epoch 398/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5828 - acc: 0.6862 - val_loss: 0.5820 - val_acc: 0.6837\n",
      "Epoch 399/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5827 - acc: 0.6862 - val_loss: 0.5824 - val_acc: 0.6837\n",
      "Epoch 400/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5828 - acc: 0.6888 - val_loss: 0.5826 - val_acc: 0.6837\n",
      "Epoch 401/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5827 - acc: 0.6888 - val_loss: 0.5823 - val_acc: 0.6837\n",
      "Epoch 402/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5824 - acc: 0.6888 - val_loss: 0.5819 - val_acc: 0.6837\n",
      "Epoch 403/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5822 - acc: 0.6888 - val_loss: 0.5813 - val_acc: 0.6837\n",
      "Epoch 404/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5819 - acc: 0.6862 - val_loss: 0.5809 - val_acc: 0.6837\n",
      "Epoch 405/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5816 - acc: 0.6862 - val_loss: 0.5805 - val_acc: 0.6837\n",
      "Epoch 406/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5814 - acc: 0.6862 - val_loss: 0.5803 - val_acc: 0.6837\n",
      "Epoch 407/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5812 - acc: 0.6862 - val_loss: 0.5804 - val_acc: 0.6837\n",
      "Epoch 408/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5811 - acc: 0.6862 - val_loss: 0.5807 - val_acc: 0.6837\n",
      "Epoch 409/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5811 - acc: 0.6913 - val_loss: 0.5810 - val_acc: 0.6837\n",
      "Epoch 410/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5811 - acc: 0.6913 - val_loss: 0.5812 - val_acc: 0.6837\n",
      "Epoch 411/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5810 - acc: 0.6888 - val_loss: 0.5812 - val_acc: 0.6837\n",
      "Epoch 412/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5809 - acc: 0.6837 - val_loss: 0.5810 - val_acc: 0.6837\n",
      "Epoch 413/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5807 - acc: 0.6837 - val_loss: 0.5808 - val_acc: 0.6837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5804 - acc: 0.6837 - val_loss: 0.5805 - val_acc: 0.6837\n",
      "Epoch 415/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5802 - acc: 0.6862 - val_loss: 0.5803 - val_acc: 0.6837\n",
      "Epoch 416/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5800 - acc: 0.6837 - val_loss: 0.5801 - val_acc: 0.6837\n",
      "Epoch 417/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5799 - acc: 0.6837 - val_loss: 0.5797 - val_acc: 0.6837\n",
      "Epoch 418/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5796 - acc: 0.6939 - val_loss: 0.5789 - val_acc: 0.6837\n",
      "Epoch 419/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5791 - acc: 0.6888 - val_loss: 0.5782 - val_acc: 0.6837\n",
      "Epoch 420/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5787 - acc: 0.6888 - val_loss: 0.5775 - val_acc: 0.6939\n",
      "Epoch 421/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5785 - acc: 0.6913 - val_loss: 0.5768 - val_acc: 0.7041\n",
      "Epoch 422/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5782 - acc: 0.6913 - val_loss: 0.5759 - val_acc: 0.6939\n",
      "Epoch 423/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5779 - acc: 0.6964 - val_loss: 0.5750 - val_acc: 0.6735\n",
      "Epoch 424/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5776 - acc: 0.6990 - val_loss: 0.5743 - val_acc: 0.6837\n",
      "Epoch 425/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5776 - acc: 0.7041 - val_loss: 0.5737 - val_acc: 0.6837\n",
      "Epoch 426/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5775 - acc: 0.7066 - val_loss: 0.5732 - val_acc: 0.6939\n",
      "Epoch 427/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5774 - acc: 0.7092 - val_loss: 0.5728 - val_acc: 0.6939\n",
      "Epoch 428/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5773 - acc: 0.7117 - val_loss: 0.5724 - val_acc: 0.6939\n",
      "Epoch 429/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5772 - acc: 0.7143 - val_loss: 0.5722 - val_acc: 0.6939\n",
      "Epoch 430/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5770 - acc: 0.7143 - val_loss: 0.5720 - val_acc: 0.6939\n",
      "Epoch 431/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5768 - acc: 0.7143 - val_loss: 0.5717 - val_acc: 0.6939\n",
      "Epoch 432/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5767 - acc: 0.7168 - val_loss: 0.5715 - val_acc: 0.6939\n",
      "Epoch 433/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5765 - acc: 0.7168 - val_loss: 0.5714 - val_acc: 0.6939\n",
      "Epoch 434/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5764 - acc: 0.7168 - val_loss: 0.5712 - val_acc: 0.6939\n",
      "Epoch 435/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5762 - acc: 0.7168 - val_loss: 0.5711 - val_acc: 0.6939\n",
      "Epoch 436/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5760 - acc: 0.7168 - val_loss: 0.5710 - val_acc: 0.6939\n",
      "Epoch 437/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5757 - acc: 0.7143 - val_loss: 0.5710 - val_acc: 0.6939\n",
      "Epoch 438/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5754 - acc: 0.7117 - val_loss: 0.5710 - val_acc: 0.6939\n",
      "Epoch 439/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5752 - acc: 0.7117 - val_loss: 0.5710 - val_acc: 0.6939\n",
      "Epoch 440/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5750 - acc: 0.7092 - val_loss: 0.5710 - val_acc: 0.6939\n",
      "Epoch 441/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5748 - acc: 0.7066 - val_loss: 0.5710 - val_acc: 0.6939\n",
      "Epoch 442/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5746 - acc: 0.7015 - val_loss: 0.5712 - val_acc: 0.6837\n",
      "Epoch 443/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5743 - acc: 0.7015 - val_loss: 0.5714 - val_acc: 0.6837\n",
      "Epoch 444/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5742 - acc: 0.7041 - val_loss: 0.5715 - val_acc: 0.6735\n",
      "Epoch 445/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5740 - acc: 0.7041 - val_loss: 0.5714 - val_acc: 0.6837\n",
      "Epoch 446/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5738 - acc: 0.7041 - val_loss: 0.5713 - val_acc: 0.6837\n",
      "Epoch 447/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5736 - acc: 0.7041 - val_loss: 0.5711 - val_acc: 0.6837\n",
      "Epoch 448/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5735 - acc: 0.7041 - val_loss: 0.5711 - val_acc: 0.6939\n",
      "Epoch 449/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5733 - acc: 0.7041 - val_loss: 0.5707 - val_acc: 0.6837\n",
      "Epoch 450/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5731 - acc: 0.7041 - val_loss: 0.5704 - val_acc: 0.6837\n",
      "Epoch 451/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5729 - acc: 0.7041 - val_loss: 0.5698 - val_acc: 0.6837\n",
      "Epoch 452/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5727 - acc: 0.7041 - val_loss: 0.5695 - val_acc: 0.6837\n",
      "Epoch 453/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5725 - acc: 0.7015 - val_loss: 0.5693 - val_acc: 0.6837\n",
      "Epoch 454/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5723 - acc: 0.7015 - val_loss: 0.5691 - val_acc: 0.6837\n",
      "Epoch 455/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5721 - acc: 0.7015 - val_loss: 0.5688 - val_acc: 0.6837\n",
      "Epoch 456/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5719 - acc: 0.7015 - val_loss: 0.5686 - val_acc: 0.6837\n",
      "Epoch 457/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5717 - acc: 0.7015 - val_loss: 0.5681 - val_acc: 0.6939\n",
      "Epoch 458/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5716 - acc: 0.7041 - val_loss: 0.5678 - val_acc: 0.6939\n",
      "Epoch 459/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5714 - acc: 0.7041 - val_loss: 0.5677 - val_acc: 0.6939\n",
      "Epoch 460/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5713 - acc: 0.7041 - val_loss: 0.5679 - val_acc: 0.6837\n",
      "Epoch 461/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5711 - acc: 0.7015 - val_loss: 0.5681 - val_acc: 0.6837\n",
      "Epoch 462/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5709 - acc: 0.7041 - val_loss: 0.5683 - val_acc: 0.6837\n",
      "Epoch 463/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5707 - acc: 0.7041 - val_loss: 0.5685 - val_acc: 0.6939\n",
      "Epoch 464/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5707 - acc: 0.7041 - val_loss: 0.5691 - val_acc: 0.6837\n",
      "Epoch 465/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5706 - acc: 0.6990 - val_loss: 0.5696 - val_acc: 0.6837\n",
      "Epoch 466/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5706 - acc: 0.6990 - val_loss: 0.5699 - val_acc: 0.6837\n",
      "Epoch 467/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5707 - acc: 0.6964 - val_loss: 0.5700 - val_acc: 0.6837\n",
      "Epoch 468/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5705 - acc: 0.6964 - val_loss: 0.5696 - val_acc: 0.6837\n",
      "Epoch 469/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5703 - acc: 0.6990 - val_loss: 0.5695 - val_acc: 0.6837\n",
      "Epoch 470/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5701 - acc: 0.6990 - val_loss: 0.5692 - val_acc: 0.6837\n",
      "Epoch 471/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5699 - acc: 0.6990 - val_loss: 0.5690 - val_acc: 0.6837\n",
      "Epoch 472/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5697 - acc: 0.6990 - val_loss: 0.5684 - val_acc: 0.6837\n",
      "Epoch 473/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5694 - acc: 0.6990 - val_loss: 0.5677 - val_acc: 0.6837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5691 - acc: 0.7041 - val_loss: 0.5670 - val_acc: 0.6939\n",
      "Epoch 475/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5689 - acc: 0.7041 - val_loss: 0.5663 - val_acc: 0.6837\n",
      "Epoch 476/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5686 - acc: 0.7041 - val_loss: 0.5659 - val_acc: 0.7041\n",
      "Epoch 477/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5684 - acc: 0.7066 - val_loss: 0.5654 - val_acc: 0.6939\n",
      "Epoch 478/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5683 - acc: 0.7041 - val_loss: 0.5648 - val_acc: 0.6939\n",
      "Epoch 479/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5681 - acc: 0.7092 - val_loss: 0.5644 - val_acc: 0.6939\n",
      "Epoch 480/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5679 - acc: 0.7092 - val_loss: 0.5642 - val_acc: 0.6939\n",
      "Epoch 481/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5677 - acc: 0.7117 - val_loss: 0.5639 - val_acc: 0.6939\n",
      "Epoch 482/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5676 - acc: 0.7117 - val_loss: 0.5637 - val_acc: 0.6939\n",
      "Epoch 483/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5674 - acc: 0.7117 - val_loss: 0.5635 - val_acc: 0.6939\n",
      "Epoch 484/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5672 - acc: 0.7143 - val_loss: 0.5631 - val_acc: 0.6837\n",
      "Epoch 485/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5671 - acc: 0.7143 - val_loss: 0.5628 - val_acc: 0.6837\n",
      "Epoch 486/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5669 - acc: 0.7194 - val_loss: 0.5626 - val_acc: 0.6837\n",
      "Epoch 487/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5668 - acc: 0.7219 - val_loss: 0.5623 - val_acc: 0.6939\n",
      "Epoch 488/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5666 - acc: 0.7219 - val_loss: 0.5620 - val_acc: 0.6939\n",
      "Epoch 489/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5666 - acc: 0.7245 - val_loss: 0.5616 - val_acc: 0.6939\n",
      "Epoch 490/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5664 - acc: 0.7245 - val_loss: 0.5615 - val_acc: 0.6939\n",
      "Epoch 491/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5662 - acc: 0.7245 - val_loss: 0.5617 - val_acc: 0.6939\n",
      "Epoch 492/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5660 - acc: 0.7245 - val_loss: 0.5618 - val_acc: 0.6939\n",
      "Epoch 493/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5657 - acc: 0.7194 - val_loss: 0.5618 - val_acc: 0.6939\n",
      "Epoch 494/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5655 - acc: 0.7143 - val_loss: 0.5616 - val_acc: 0.6939\n",
      "Epoch 495/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5654 - acc: 0.7168 - val_loss: 0.5614 - val_acc: 0.6939\n",
      "Epoch 496/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5652 - acc: 0.7194 - val_loss: 0.5613 - val_acc: 0.6939\n",
      "Epoch 497/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5650 - acc: 0.7143 - val_loss: 0.5613 - val_acc: 0.6837\n",
      "Epoch 498/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5648 - acc: 0.7143 - val_loss: 0.5613 - val_acc: 0.6837\n",
      "Epoch 499/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5647 - acc: 0.7117 - val_loss: 0.5611 - val_acc: 0.6837\n",
      "Epoch 500/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5645 - acc: 0.7143 - val_loss: 0.5607 - val_acc: 0.6939\n",
      "Epoch 501/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5643 - acc: 0.7245 - val_loss: 0.5602 - val_acc: 0.6939\n",
      "Epoch 502/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5643 - acc: 0.7245 - val_loss: 0.5600 - val_acc: 0.6939\n",
      "Epoch 503/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5641 - acc: 0.7245 - val_loss: 0.5599 - val_acc: 0.6939\n",
      "Epoch 504/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5639 - acc: 0.7245 - val_loss: 0.5599 - val_acc: 0.6939\n",
      "Epoch 505/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5637 - acc: 0.7245 - val_loss: 0.5599 - val_acc: 0.6939\n",
      "Epoch 506/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5635 - acc: 0.7245 - val_loss: 0.5600 - val_acc: 0.6939\n",
      "Epoch 507/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5633 - acc: 0.7194 - val_loss: 0.5599 - val_acc: 0.6939\n",
      "Epoch 508/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5631 - acc: 0.7168 - val_loss: 0.5598 - val_acc: 0.6939\n",
      "Epoch 509/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5629 - acc: 0.7117 - val_loss: 0.5600 - val_acc: 0.6837\n",
      "Epoch 510/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5628 - acc: 0.7117 - val_loss: 0.5604 - val_acc: 0.6939\n",
      "Epoch 511/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5627 - acc: 0.7092 - val_loss: 0.5602 - val_acc: 0.6837\n",
      "Epoch 512/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5626 - acc: 0.7092 - val_loss: 0.5597 - val_acc: 0.6837\n",
      "Epoch 513/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5624 - acc: 0.7092 - val_loss: 0.5592 - val_acc: 0.6939\n",
      "Epoch 514/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5621 - acc: 0.7194 - val_loss: 0.5589 - val_acc: 0.6939\n",
      "Epoch 515/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5620 - acc: 0.7245 - val_loss: 0.5586 - val_acc: 0.6939\n",
      "Epoch 516/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5619 - acc: 0.7245 - val_loss: 0.5585 - val_acc: 0.6939\n",
      "Epoch 517/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5617 - acc: 0.7219 - val_loss: 0.5586 - val_acc: 0.6939\n",
      "Epoch 518/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5615 - acc: 0.7194 - val_loss: 0.5585 - val_acc: 0.6939\n",
      "Epoch 519/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5614 - acc: 0.7194 - val_loss: 0.5587 - val_acc: 0.6837\n",
      "Epoch 520/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5612 - acc: 0.7117 - val_loss: 0.5589 - val_acc: 0.6837\n",
      "Epoch 521/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5611 - acc: 0.7092 - val_loss: 0.5591 - val_acc: 0.6837\n",
      "Epoch 522/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5610 - acc: 0.7092 - val_loss: 0.5593 - val_acc: 0.7041\n",
      "Epoch 523/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5610 - acc: 0.7092 - val_loss: 0.5594 - val_acc: 0.7041\n",
      "Epoch 524/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5608 - acc: 0.7092 - val_loss: 0.5589 - val_acc: 0.7041\n",
      "Epoch 525/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5607 - acc: 0.7092 - val_loss: 0.5584 - val_acc: 0.6837\n",
      "Epoch 526/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5604 - acc: 0.7092 - val_loss: 0.5581 - val_acc: 0.6837\n",
      "Epoch 527/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5602 - acc: 0.7117 - val_loss: 0.5579 - val_acc: 0.6837\n",
      "Epoch 528/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5600 - acc: 0.7143 - val_loss: 0.5576 - val_acc: 0.6837\n",
      "Epoch 529/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5598 - acc: 0.7143 - val_loss: 0.5577 - val_acc: 0.6837\n",
      "Epoch 530/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5598 - acc: 0.7117 - val_loss: 0.5579 - val_acc: 0.6939\n",
      "Epoch 531/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5596 - acc: 0.7092 - val_loss: 0.5577 - val_acc: 0.6939\n",
      "Epoch 532/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5594 - acc: 0.7092 - val_loss: 0.5575 - val_acc: 0.6939\n",
      "Epoch 533/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5593 - acc: 0.7092 - val_loss: 0.5576 - val_acc: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5592 - acc: 0.7092 - val_loss: 0.5580 - val_acc: 0.7041\n",
      "Epoch 535/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5592 - acc: 0.7092 - val_loss: 0.5584 - val_acc: 0.6939\n",
      "Epoch 536/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5594 - acc: 0.7066 - val_loss: 0.5588 - val_acc: 0.6837\n",
      "Epoch 537/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5591 - acc: 0.7041 - val_loss: 0.5587 - val_acc: 0.6837\n",
      "Epoch 538/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5590 - acc: 0.7041 - val_loss: 0.5585 - val_acc: 0.6837\n",
      "Epoch 539/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5588 - acc: 0.7041 - val_loss: 0.5581 - val_acc: 0.6837\n",
      "Epoch 540/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5585 - acc: 0.7066 - val_loss: 0.5576 - val_acc: 0.6939\n",
      "Epoch 541/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5583 - acc: 0.7092 - val_loss: 0.5568 - val_acc: 0.7041\n",
      "Epoch 542/1000\n",
      "392/392 [==============================] - ETA: 0s - loss: 0.5505 - acc: 0.742 - 0s 14us/step - loss: 0.5581 - acc: 0.7143 - val_loss: 0.5561 - val_acc: 0.6939\n",
      "Epoch 543/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5578 - acc: 0.7143 - val_loss: 0.5560 - val_acc: 0.6939\n",
      "Epoch 544/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5576 - acc: 0.7143 - val_loss: 0.5559 - val_acc: 0.6939\n",
      "Epoch 545/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5575 - acc: 0.7143 - val_loss: 0.5558 - val_acc: 0.6939\n",
      "Epoch 546/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5573 - acc: 0.7143 - val_loss: 0.5557 - val_acc: 0.6939\n",
      "Epoch 547/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5571 - acc: 0.7168 - val_loss: 0.5554 - val_acc: 0.6939\n",
      "Epoch 548/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5570 - acc: 0.7168 - val_loss: 0.5548 - val_acc: 0.6939\n",
      "Epoch 549/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5567 - acc: 0.7219 - val_loss: 0.5541 - val_acc: 0.6939\n",
      "Epoch 550/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5565 - acc: 0.7270 - val_loss: 0.5534 - val_acc: 0.6939\n",
      "Epoch 551/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5564 - acc: 0.7296 - val_loss: 0.5528 - val_acc: 0.6837\n",
      "Epoch 552/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5564 - acc: 0.7372 - val_loss: 0.5522 - val_acc: 0.6837\n",
      "Epoch 553/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5565 - acc: 0.7347 - val_loss: 0.5519 - val_acc: 0.6939\n",
      "Epoch 554/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5566 - acc: 0.7372 - val_loss: 0.5517 - val_acc: 0.6939\n",
      "Epoch 555/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5565 - acc: 0.7372 - val_loss: 0.5517 - val_acc: 0.6939\n",
      "Epoch 556/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5563 - acc: 0.7372 - val_loss: 0.5517 - val_acc: 0.6837\n",
      "Epoch 557/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5560 - acc: 0.7347 - val_loss: 0.5518 - val_acc: 0.6837\n",
      "Epoch 558/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5557 - acc: 0.7347 - val_loss: 0.5518 - val_acc: 0.6837\n",
      "Epoch 559/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5556 - acc: 0.7347 - val_loss: 0.5517 - val_acc: 0.6837\n",
      "Epoch 560/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5554 - acc: 0.7347 - val_loss: 0.5517 - val_acc: 0.6837\n",
      "Epoch 561/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5551 - acc: 0.7296 - val_loss: 0.5517 - val_acc: 0.6837\n",
      "Epoch 562/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5549 - acc: 0.7347 - val_loss: 0.5518 - val_acc: 0.6837\n",
      "Epoch 563/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5547 - acc: 0.7321 - val_loss: 0.5518 - val_acc: 0.6939\n",
      "Epoch 564/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5546 - acc: 0.7321 - val_loss: 0.5517 - val_acc: 0.6939\n",
      "Epoch 565/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5544 - acc: 0.7296 - val_loss: 0.5517 - val_acc: 0.6939\n",
      "Epoch 566/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5543 - acc: 0.7270 - val_loss: 0.5517 - val_acc: 0.6939\n",
      "Epoch 567/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5541 - acc: 0.7270 - val_loss: 0.5514 - val_acc: 0.6939\n",
      "Epoch 568/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5540 - acc: 0.7270 - val_loss: 0.5514 - val_acc: 0.6939\n",
      "Epoch 569/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5538 - acc: 0.7245 - val_loss: 0.5515 - val_acc: 0.6939\n",
      "Epoch 570/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5537 - acc: 0.7245 - val_loss: 0.5512 - val_acc: 0.6939\n",
      "Epoch 571/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5535 - acc: 0.7270 - val_loss: 0.5508 - val_acc: 0.6939\n",
      "Epoch 572/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5534 - acc: 0.7270 - val_loss: 0.5505 - val_acc: 0.6939\n",
      "Epoch 573/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5533 - acc: 0.7296 - val_loss: 0.5503 - val_acc: 0.6939\n",
      "Epoch 574/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5531 - acc: 0.7296 - val_loss: 0.5500 - val_acc: 0.6837\n",
      "Epoch 575/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5531 - acc: 0.7372 - val_loss: 0.5495 - val_acc: 0.6837\n",
      "Epoch 576/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5530 - acc: 0.7372 - val_loss: 0.5495 - val_acc: 0.6837\n",
      "Epoch 577/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5529 - acc: 0.7372 - val_loss: 0.5493 - val_acc: 0.6837\n",
      "Epoch 578/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5528 - acc: 0.7372 - val_loss: 0.5493 - val_acc: 0.6837\n",
      "Epoch 579/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5526 - acc: 0.7347 - val_loss: 0.5493 - val_acc: 0.6837\n",
      "Epoch 580/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5524 - acc: 0.7347 - val_loss: 0.5491 - val_acc: 0.6837\n",
      "Epoch 581/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5523 - acc: 0.7347 - val_loss: 0.5489 - val_acc: 0.6837\n",
      "Epoch 582/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5522 - acc: 0.7347 - val_loss: 0.5487 - val_acc: 0.6837\n",
      "Epoch 583/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5520 - acc: 0.7372 - val_loss: 0.5487 - val_acc: 0.6837\n",
      "Epoch 584/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5518 - acc: 0.7347 - val_loss: 0.5488 - val_acc: 0.6837\n",
      "Epoch 585/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5516 - acc: 0.7372 - val_loss: 0.5488 - val_acc: 0.6837\n",
      "Epoch 586/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5514 - acc: 0.7321 - val_loss: 0.5489 - val_acc: 0.6837\n",
      "Epoch 587/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5513 - acc: 0.7296 - val_loss: 0.5488 - val_acc: 0.6837\n",
      "Epoch 588/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5511 - acc: 0.7321 - val_loss: 0.5483 - val_acc: 0.6837\n",
      "Epoch 589/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5510 - acc: 0.7372 - val_loss: 0.5481 - val_acc: 0.6837\n",
      "Epoch 590/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5508 - acc: 0.7372 - val_loss: 0.5482 - val_acc: 0.6837\n",
      "Epoch 591/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5507 - acc: 0.7321 - val_loss: 0.5485 - val_acc: 0.6837\n",
      "Epoch 592/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5505 - acc: 0.7270 - val_loss: 0.5486 - val_acc: 0.6837\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 0s 14us/step - loss: 0.5504 - acc: 0.7296 - val_loss: 0.5487 - val_acc: 0.6939\n",
      "Epoch 594/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5503 - acc: 0.7296 - val_loss: 0.5485 - val_acc: 0.6939\n",
      "Epoch 595/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5501 - acc: 0.7296 - val_loss: 0.5485 - val_acc: 0.6939\n",
      "Epoch 596/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5499 - acc: 0.7245 - val_loss: 0.5487 - val_acc: 0.7041\n",
      "Epoch 597/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5499 - acc: 0.7245 - val_loss: 0.5490 - val_acc: 0.7041\n",
      "Epoch 598/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5498 - acc: 0.7245 - val_loss: 0.5491 - val_acc: 0.7041\n",
      "Epoch 599/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5497 - acc: 0.7245 - val_loss: 0.5490 - val_acc: 0.7041\n",
      "Epoch 600/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5496 - acc: 0.7270 - val_loss: 0.5491 - val_acc: 0.7041\n",
      "Epoch 601/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5495 - acc: 0.7245 - val_loss: 0.5490 - val_acc: 0.7041\n",
      "Epoch 602/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5493 - acc: 0.7245 - val_loss: 0.5488 - val_acc: 0.7041\n",
      "Epoch 603/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5492 - acc: 0.7270 - val_loss: 0.5485 - val_acc: 0.7041\n",
      "Epoch 604/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5489 - acc: 0.7245 - val_loss: 0.5478 - val_acc: 0.7041\n",
      "Epoch 605/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5488 - acc: 0.7245 - val_loss: 0.5473 - val_acc: 0.6939\n",
      "Epoch 606/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5486 - acc: 0.7270 - val_loss: 0.5471 - val_acc: 0.6837\n",
      "Epoch 607/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5485 - acc: 0.7296 - val_loss: 0.5470 - val_acc: 0.6837\n",
      "Epoch 608/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5484 - acc: 0.7296 - val_loss: 0.5468 - val_acc: 0.6837\n",
      "Epoch 609/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5482 - acc: 0.7270 - val_loss: 0.5463 - val_acc: 0.6837\n",
      "Epoch 610/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5481 - acc: 0.7321 - val_loss: 0.5461 - val_acc: 0.6837\n",
      "Epoch 611/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5480 - acc: 0.7321 - val_loss: 0.5462 - val_acc: 0.6837\n",
      "Epoch 612/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5479 - acc: 0.7270 - val_loss: 0.5462 - val_acc: 0.6837\n",
      "Epoch 613/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5477 - acc: 0.7321 - val_loss: 0.5459 - val_acc: 0.6837\n",
      "Epoch 614/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5477 - acc: 0.7321 - val_loss: 0.5456 - val_acc: 0.6837\n",
      "Epoch 615/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5475 - acc: 0.7321 - val_loss: 0.5456 - val_acc: 0.6837\n",
      "Epoch 616/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5474 - acc: 0.7321 - val_loss: 0.5452 - val_acc: 0.6837\n",
      "Epoch 617/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5472 - acc: 0.7347 - val_loss: 0.5450 - val_acc: 0.6837\n",
      "Epoch 618/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5471 - acc: 0.7321 - val_loss: 0.5451 - val_acc: 0.6837\n",
      "Epoch 619/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5470 - acc: 0.7347 - val_loss: 0.5452 - val_acc: 0.6837\n",
      "Epoch 620/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5468 - acc: 0.7321 - val_loss: 0.5453 - val_acc: 0.6837\n",
      "Epoch 621/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5467 - acc: 0.7321 - val_loss: 0.5452 - val_acc: 0.6837\n",
      "Epoch 622/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5465 - acc: 0.7321 - val_loss: 0.5449 - val_acc: 0.6837\n",
      "Epoch 623/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5465 - acc: 0.7321 - val_loss: 0.5447 - val_acc: 0.6837\n",
      "Epoch 624/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5463 - acc: 0.7321 - val_loss: 0.5446 - val_acc: 0.6837\n",
      "Epoch 625/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5462 - acc: 0.7321 - val_loss: 0.5447 - val_acc: 0.6837\n",
      "Epoch 626/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5460 - acc: 0.7296 - val_loss: 0.5450 - val_acc: 0.6939\n",
      "Epoch 627/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5460 - acc: 0.7296 - val_loss: 0.5452 - val_acc: 0.6939\n",
      "Epoch 628/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5458 - acc: 0.7245 - val_loss: 0.5455 - val_acc: 0.6939\n",
      "Epoch 629/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5460 - acc: 0.7270 - val_loss: 0.5462 - val_acc: 0.6939\n",
      "Epoch 630/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5459 - acc: 0.7245 - val_loss: 0.5464 - val_acc: 0.6939\n",
      "Epoch 631/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5459 - acc: 0.7270 - val_loss: 0.5465 - val_acc: 0.6939\n",
      "Epoch 632/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5458 - acc: 0.7270 - val_loss: 0.5462 - val_acc: 0.6939\n",
      "Epoch 633/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5455 - acc: 0.7270 - val_loss: 0.5457 - val_acc: 0.6837\n",
      "Epoch 634/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5453 - acc: 0.7245 - val_loss: 0.5456 - val_acc: 0.6939\n",
      "Epoch 635/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5452 - acc: 0.7245 - val_loss: 0.5454 - val_acc: 0.6939\n",
      "Epoch 636/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5451 - acc: 0.7245 - val_loss: 0.5454 - val_acc: 0.6939\n",
      "Epoch 637/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5450 - acc: 0.7245 - val_loss: 0.5455 - val_acc: 0.6939\n",
      "Epoch 638/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5449 - acc: 0.7245 - val_loss: 0.5453 - val_acc: 0.6939\n",
      "Epoch 639/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5446 - acc: 0.7245 - val_loss: 0.5447 - val_acc: 0.6939\n",
      "Epoch 640/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5444 - acc: 0.7219 - val_loss: 0.5443 - val_acc: 0.6939\n",
      "Epoch 641/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5443 - acc: 0.7245 - val_loss: 0.5441 - val_acc: 0.6939\n",
      "Epoch 642/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5442 - acc: 0.7270 - val_loss: 0.5437 - val_acc: 0.6939\n",
      "Epoch 643/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5440 - acc: 0.7296 - val_loss: 0.5435 - val_acc: 0.6939\n",
      "Epoch 644/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5439 - acc: 0.7296 - val_loss: 0.5436 - val_acc: 0.6939\n",
      "Epoch 645/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5437 - acc: 0.7270 - val_loss: 0.5436 - val_acc: 0.6939\n",
      "Epoch 646/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5437 - acc: 0.7245 - val_loss: 0.5433 - val_acc: 0.6939\n",
      "Epoch 647/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5434 - acc: 0.7321 - val_loss: 0.5428 - val_acc: 0.6939\n",
      "Epoch 648/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5433 - acc: 0.7321 - val_loss: 0.5424 - val_acc: 0.6837\n",
      "Epoch 649/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5432 - acc: 0.7321 - val_loss: 0.5421 - val_acc: 0.6837\n",
      "Epoch 650/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5431 - acc: 0.7321 - val_loss: 0.5418 - val_acc: 0.6837\n",
      "Epoch 651/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5429 - acc: 0.7321 - val_loss: 0.5416 - val_acc: 0.6837\n",
      "Epoch 652/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5428 - acc: 0.7347 - val_loss: 0.5415 - val_acc: 0.6837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 653/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5427 - acc: 0.7347 - val_loss: 0.5415 - val_acc: 0.6837\n",
      "Epoch 654/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5425 - acc: 0.7321 - val_loss: 0.5417 - val_acc: 0.6837\n",
      "Epoch 655/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5424 - acc: 0.7296 - val_loss: 0.5419 - val_acc: 0.6837\n",
      "Epoch 656/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5423 - acc: 0.7321 - val_loss: 0.5418 - val_acc: 0.6837\n",
      "Epoch 657/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5422 - acc: 0.7321 - val_loss: 0.5415 - val_acc: 0.6837\n",
      "Epoch 658/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5420 - acc: 0.7270 - val_loss: 0.5411 - val_acc: 0.6837\n",
      "Epoch 659/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5420 - acc: 0.7347 - val_loss: 0.5407 - val_acc: 0.6837\n",
      "Epoch 660/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5419 - acc: 0.7347 - val_loss: 0.5409 - val_acc: 0.6837\n",
      "Epoch 661/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5416 - acc: 0.7347 - val_loss: 0.5412 - val_acc: 0.6837\n",
      "Epoch 662/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5415 - acc: 0.7296 - val_loss: 0.5416 - val_acc: 0.6939\n",
      "Epoch 663/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5416 - acc: 0.7296 - val_loss: 0.5419 - val_acc: 0.6939\n",
      "Epoch 664/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5415 - acc: 0.7270 - val_loss: 0.5419 - val_acc: 0.6939\n",
      "Epoch 665/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5414 - acc: 0.7219 - val_loss: 0.5422 - val_acc: 0.6939\n",
      "Epoch 666/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5415 - acc: 0.7270 - val_loss: 0.5425 - val_acc: 0.6837\n",
      "Epoch 667/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5414 - acc: 0.7270 - val_loss: 0.5426 - val_acc: 0.6837\n",
      "Epoch 668/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5413 - acc: 0.7270 - val_loss: 0.5423 - val_acc: 0.6837\n",
      "Epoch 669/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5412 - acc: 0.7270 - val_loss: 0.5416 - val_acc: 0.6939\n",
      "Epoch 670/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5409 - acc: 0.7245 - val_loss: 0.5409 - val_acc: 0.6939\n",
      "Epoch 671/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5406 - acc: 0.7296 - val_loss: 0.5403 - val_acc: 0.6939\n",
      "Epoch 672/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5404 - acc: 0.7372 - val_loss: 0.5393 - val_acc: 0.6837\n",
      "Epoch 673/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5403 - acc: 0.7372 - val_loss: 0.5385 - val_acc: 0.6939\n",
      "Epoch 674/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5402 - acc: 0.7423 - val_loss: 0.5380 - val_acc: 0.6939\n",
      "Epoch 675/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5402 - acc: 0.7423 - val_loss: 0.5379 - val_acc: 0.6939\n",
      "Epoch 676/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5400 - acc: 0.7423 - val_loss: 0.5376 - val_acc: 0.6939\n",
      "Epoch 677/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5400 - acc: 0.7423 - val_loss: 0.5376 - val_acc: 0.6939\n",
      "Epoch 678/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5398 - acc: 0.7449 - val_loss: 0.5378 - val_acc: 0.6939\n",
      "Epoch 679/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5397 - acc: 0.7398 - val_loss: 0.5382 - val_acc: 0.6939\n",
      "Epoch 680/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5395 - acc: 0.7372 - val_loss: 0.5383 - val_acc: 0.6837\n",
      "Epoch 681/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5395 - acc: 0.7372 - val_loss: 0.5383 - val_acc: 0.6837\n",
      "Epoch 682/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5393 - acc: 0.7372 - val_loss: 0.5384 - val_acc: 0.6939\n",
      "Epoch 683/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5393 - acc: 0.7398 - val_loss: 0.5386 - val_acc: 0.6939\n",
      "Epoch 684/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5391 - acc: 0.7398 - val_loss: 0.5386 - val_acc: 0.6939\n",
      "Epoch 685/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5390 - acc: 0.7423 - val_loss: 0.5382 - val_acc: 0.6939\n",
      "Epoch 686/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5389 - acc: 0.7398 - val_loss: 0.5378 - val_acc: 0.6939\n",
      "Epoch 687/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5387 - acc: 0.7372 - val_loss: 0.5377 - val_acc: 0.6939\n",
      "Epoch 688/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5386 - acc: 0.7372 - val_loss: 0.5378 - val_acc: 0.6939\n",
      "Epoch 689/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5385 - acc: 0.7423 - val_loss: 0.5381 - val_acc: 0.6939\n",
      "Epoch 690/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5384 - acc: 0.7423 - val_loss: 0.5381 - val_acc: 0.6939\n",
      "Epoch 691/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5383 - acc: 0.7423 - val_loss: 0.5380 - val_acc: 0.6939\n",
      "Epoch 692/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5382 - acc: 0.7423 - val_loss: 0.5379 - val_acc: 0.6939\n",
      "Epoch 693/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5380 - acc: 0.7423 - val_loss: 0.5374 - val_acc: 0.6939\n",
      "Epoch 694/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5378 - acc: 0.7398 - val_loss: 0.5366 - val_acc: 0.6939\n",
      "Epoch 695/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5377 - acc: 0.7398 - val_loss: 0.5361 - val_acc: 0.6939\n",
      "Epoch 696/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5377 - acc: 0.7474 - val_loss: 0.5355 - val_acc: 0.6939\n",
      "Epoch 697/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5378 - acc: 0.7372 - val_loss: 0.5351 - val_acc: 0.6939\n",
      "Epoch 698/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5377 - acc: 0.7347 - val_loss: 0.5349 - val_acc: 0.6939\n",
      "Epoch 699/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5378 - acc: 0.7372 - val_loss: 0.5346 - val_acc: 0.6939\n",
      "Epoch 700/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5377 - acc: 0.7423 - val_loss: 0.5344 - val_acc: 0.6939\n",
      "Epoch 701/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5377 - acc: 0.7423 - val_loss: 0.5343 - val_acc: 0.6939\n",
      "Epoch 702/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5376 - acc: 0.7423 - val_loss: 0.5341 - val_acc: 0.6939\n",
      "Epoch 703/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5375 - acc: 0.7372 - val_loss: 0.5339 - val_acc: 0.6939\n",
      "Epoch 704/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5374 - acc: 0.7372 - val_loss: 0.5338 - val_acc: 0.6939\n",
      "Epoch 705/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5373 - acc: 0.7372 - val_loss: 0.5338 - val_acc: 0.6939\n",
      "Epoch 706/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5370 - acc: 0.7423 - val_loss: 0.5338 - val_acc: 0.6939\n",
      "Epoch 707/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5368 - acc: 0.7423 - val_loss: 0.5338 - val_acc: 0.6939\n",
      "Epoch 708/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5365 - acc: 0.7372 - val_loss: 0.5339 - val_acc: 0.6939\n",
      "Epoch 709/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5363 - acc: 0.7372 - val_loss: 0.5339 - val_acc: 0.6939\n",
      "Epoch 710/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5362 - acc: 0.7372 - val_loss: 0.5338 - val_acc: 0.6939\n",
      "Epoch 711/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5361 - acc: 0.7372 - val_loss: 0.5338 - val_acc: 0.6939\n",
      "Epoch 712/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5359 - acc: 0.7398 - val_loss: 0.5338 - val_acc: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5357 - acc: 0.7398 - val_loss: 0.5335 - val_acc: 0.6939\n",
      "Epoch 714/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5356 - acc: 0.7347 - val_loss: 0.5332 - val_acc: 0.6939\n",
      "Epoch 715/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5357 - acc: 0.7398 - val_loss: 0.5329 - val_acc: 0.6939\n",
      "Epoch 716/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5357 - acc: 0.7423 - val_loss: 0.5327 - val_acc: 0.6939\n",
      "Epoch 717/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5356 - acc: 0.7398 - val_loss: 0.5326 - val_acc: 0.6939\n",
      "Epoch 718/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5355 - acc: 0.7398 - val_loss: 0.5325 - val_acc: 0.6939\n",
      "Epoch 719/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5354 - acc: 0.7398 - val_loss: 0.5324 - val_acc: 0.6939\n",
      "Epoch 720/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5353 - acc: 0.7398 - val_loss: 0.5324 - val_acc: 0.6939\n",
      "Epoch 721/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5350 - acc: 0.7398 - val_loss: 0.5325 - val_acc: 0.6939\n",
      "Epoch 722/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5348 - acc: 0.7372 - val_loss: 0.5327 - val_acc: 0.6939\n",
      "Epoch 723/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5346 - acc: 0.7423 - val_loss: 0.5329 - val_acc: 0.6939\n",
      "Epoch 724/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5344 - acc: 0.7474 - val_loss: 0.5331 - val_acc: 0.6939\n",
      "Epoch 725/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5342 - acc: 0.7474 - val_loss: 0.5333 - val_acc: 0.6939\n",
      "Epoch 726/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5341 - acc: 0.7474 - val_loss: 0.5335 - val_acc: 0.7041\n",
      "Epoch 727/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5340 - acc: 0.7423 - val_loss: 0.5338 - val_acc: 0.7041\n",
      "Epoch 728/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5339 - acc: 0.7423 - val_loss: 0.5338 - val_acc: 0.6939\n",
      "Epoch 729/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5339 - acc: 0.7449 - val_loss: 0.5341 - val_acc: 0.6939\n",
      "Epoch 730/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5337 - acc: 0.7449 - val_loss: 0.5341 - val_acc: 0.6939\n",
      "Epoch 731/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5336 - acc: 0.7449 - val_loss: 0.5337 - val_acc: 0.6939\n",
      "Epoch 732/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5334 - acc: 0.7423 - val_loss: 0.5330 - val_acc: 0.7041\n",
      "Epoch 733/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5332 - acc: 0.7423 - val_loss: 0.5323 - val_acc: 0.6939\n",
      "Epoch 734/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5331 - acc: 0.7449 - val_loss: 0.5317 - val_acc: 0.6939\n",
      "Epoch 735/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5331 - acc: 0.7423 - val_loss: 0.5315 - val_acc: 0.6939\n",
      "Epoch 736/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5330 - acc: 0.7423 - val_loss: 0.5316 - val_acc: 0.6939\n",
      "Epoch 737/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5329 - acc: 0.7423 - val_loss: 0.5319 - val_acc: 0.6939\n",
      "Epoch 738/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5327 - acc: 0.7474 - val_loss: 0.5323 - val_acc: 0.7041\n",
      "Epoch 739/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5326 - acc: 0.7423 - val_loss: 0.5323 - val_acc: 0.7041\n",
      "Epoch 740/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5324 - acc: 0.7423 - val_loss: 0.5322 - val_acc: 0.7041\n",
      "Epoch 741/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5323 - acc: 0.7423 - val_loss: 0.5322 - val_acc: 0.7041\n",
      "Epoch 742/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5322 - acc: 0.7449 - val_loss: 0.5319 - val_acc: 0.7041\n",
      "Epoch 743/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5321 - acc: 0.7449 - val_loss: 0.5318 - val_acc: 0.7041\n",
      "Epoch 744/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5320 - acc: 0.7449 - val_loss: 0.5320 - val_acc: 0.7041\n",
      "Epoch 745/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5319 - acc: 0.7449 - val_loss: 0.5322 - val_acc: 0.7041\n",
      "Epoch 746/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5318 - acc: 0.7449 - val_loss: 0.5323 - val_acc: 0.6837\n",
      "Epoch 747/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5317 - acc: 0.7449 - val_loss: 0.5320 - val_acc: 0.6939\n",
      "Epoch 748/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5315 - acc: 0.7474 - val_loss: 0.5314 - val_acc: 0.7041\n",
      "Epoch 749/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5314 - acc: 0.7474 - val_loss: 0.5309 - val_acc: 0.7041\n",
      "Epoch 750/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5312 - acc: 0.7449 - val_loss: 0.5307 - val_acc: 0.7041\n",
      "Epoch 751/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5311 - acc: 0.7423 - val_loss: 0.5304 - val_acc: 0.6939\n",
      "Epoch 752/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5310 - acc: 0.7423 - val_loss: 0.5302 - val_acc: 0.6939\n",
      "Epoch 753/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5308 - acc: 0.7423 - val_loss: 0.5302 - val_acc: 0.7041\n",
      "Epoch 754/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5307 - acc: 0.7423 - val_loss: 0.5306 - val_acc: 0.7041\n",
      "Epoch 755/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5307 - acc: 0.7449 - val_loss: 0.5317 - val_acc: 0.6837\n",
      "Epoch 756/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5309 - acc: 0.7500 - val_loss: 0.5323 - val_acc: 0.6939\n",
      "Epoch 757/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5308 - acc: 0.7500 - val_loss: 0.5319 - val_acc: 0.6939\n",
      "Epoch 758/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5306 - acc: 0.7474 - val_loss: 0.5314 - val_acc: 0.6837\n",
      "Epoch 759/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5305 - acc: 0.7500 - val_loss: 0.5315 - val_acc: 0.6939\n",
      "Epoch 760/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5303 - acc: 0.7500 - val_loss: 0.5313 - val_acc: 0.6939\n",
      "Epoch 761/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5302 - acc: 0.7500 - val_loss: 0.5314 - val_acc: 0.6939\n",
      "Epoch 762/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5301 - acc: 0.7500 - val_loss: 0.5314 - val_acc: 0.6939\n",
      "Epoch 763/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5301 - acc: 0.7449 - val_loss: 0.5315 - val_acc: 0.6939\n",
      "Epoch 764/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5300 - acc: 0.7449 - val_loss: 0.5312 - val_acc: 0.6939\n",
      "Epoch 765/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5298 - acc: 0.7500 - val_loss: 0.5310 - val_acc: 0.6939\n",
      "Epoch 766/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5297 - acc: 0.7500 - val_loss: 0.5310 - val_acc: 0.6939\n",
      "Epoch 767/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5296 - acc: 0.7474 - val_loss: 0.5310 - val_acc: 0.6939\n",
      "Epoch 768/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5295 - acc: 0.7474 - val_loss: 0.5308 - val_acc: 0.6939\n",
      "Epoch 769/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5293 - acc: 0.7500 - val_loss: 0.5303 - val_acc: 0.6939\n",
      "Epoch 770/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5291 - acc: 0.7526 - val_loss: 0.5295 - val_acc: 0.6939\n",
      "Epoch 771/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5289 - acc: 0.7551 - val_loss: 0.5291 - val_acc: 0.6939\n",
      "Epoch 772/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5288 - acc: 0.7474 - val_loss: 0.5294 - val_acc: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 773/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5287 - acc: 0.7526 - val_loss: 0.5298 - val_acc: 0.6939\n",
      "Epoch 774/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5287 - acc: 0.7526 - val_loss: 0.5300 - val_acc: 0.6939\n",
      "Epoch 775/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5286 - acc: 0.7526 - val_loss: 0.5299 - val_acc: 0.6939\n",
      "Epoch 776/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5284 - acc: 0.7526 - val_loss: 0.5293 - val_acc: 0.7041\n",
      "Epoch 777/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5281 - acc: 0.7526 - val_loss: 0.5283 - val_acc: 0.6939\n",
      "Epoch 778/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5281 - acc: 0.7423 - val_loss: 0.5271 - val_acc: 0.6939\n",
      "Epoch 779/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5279 - acc: 0.7398 - val_loss: 0.5264 - val_acc: 0.6939\n",
      "Epoch 780/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5280 - acc: 0.7449 - val_loss: 0.5260 - val_acc: 0.6939\n",
      "Epoch 781/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5281 - acc: 0.7449 - val_loss: 0.5256 - val_acc: 0.6939\n",
      "Epoch 782/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5280 - acc: 0.7423 - val_loss: 0.5254 - val_acc: 0.6939\n",
      "Epoch 783/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5280 - acc: 0.7449 - val_loss: 0.5252 - val_acc: 0.6939\n",
      "Epoch 784/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5280 - acc: 0.7474 - val_loss: 0.5249 - val_acc: 0.6939\n",
      "Epoch 785/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5280 - acc: 0.7449 - val_loss: 0.5248 - val_acc: 0.6939\n",
      "Epoch 786/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5278 - acc: 0.7449 - val_loss: 0.5248 - val_acc: 0.6939\n",
      "Epoch 787/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5277 - acc: 0.7449 - val_loss: 0.5248 - val_acc: 0.6939\n",
      "Epoch 788/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5275 - acc: 0.7449 - val_loss: 0.5247 - val_acc: 0.6939\n",
      "Epoch 789/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5274 - acc: 0.7449 - val_loss: 0.5247 - val_acc: 0.6939\n",
      "Epoch 790/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5271 - acc: 0.7449 - val_loss: 0.5249 - val_acc: 0.6939\n",
      "Epoch 791/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5269 - acc: 0.7449 - val_loss: 0.5250 - val_acc: 0.6939\n",
      "Epoch 792/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5267 - acc: 0.7449 - val_loss: 0.5250 - val_acc: 0.6939\n",
      "Epoch 793/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5265 - acc: 0.7423 - val_loss: 0.5250 - val_acc: 0.6939\n",
      "Epoch 794/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5264 - acc: 0.7423 - val_loss: 0.5249 - val_acc: 0.6939\n",
      "Epoch 795/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5264 - acc: 0.7449 - val_loss: 0.5245 - val_acc: 0.6939\n",
      "Epoch 796/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5263 - acc: 0.7449 - val_loss: 0.5243 - val_acc: 0.6939\n",
      "Epoch 797/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5263 - acc: 0.7449 - val_loss: 0.5241 - val_acc: 0.6939\n",
      "Epoch 798/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5262 - acc: 0.7449 - val_loss: 0.5241 - val_acc: 0.6939\n",
      "Epoch 799/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5260 - acc: 0.7449 - val_loss: 0.5241 - val_acc: 0.6939\n",
      "Epoch 800/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5258 - acc: 0.7449 - val_loss: 0.5242 - val_acc: 0.6939\n",
      "Epoch 801/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5256 - acc: 0.7449 - val_loss: 0.5243 - val_acc: 0.6939\n",
      "Epoch 802/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5255 - acc: 0.7474 - val_loss: 0.5244 - val_acc: 0.6939\n",
      "Epoch 803/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5253 - acc: 0.7449 - val_loss: 0.5244 - val_acc: 0.6939\n",
      "Epoch 804/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5252 - acc: 0.7449 - val_loss: 0.5245 - val_acc: 0.6939\n",
      "Epoch 805/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5251 - acc: 0.7449 - val_loss: 0.5246 - val_acc: 0.6939\n",
      "Epoch 806/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5249 - acc: 0.7423 - val_loss: 0.5250 - val_acc: 0.6939\n",
      "Epoch 807/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5249 - acc: 0.7423 - val_loss: 0.5254 - val_acc: 0.7041\n",
      "Epoch 808/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5248 - acc: 0.7449 - val_loss: 0.5254 - val_acc: 0.7041\n",
      "Epoch 809/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5247 - acc: 0.7423 - val_loss: 0.5254 - val_acc: 0.7041\n",
      "Epoch 810/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5246 - acc: 0.7474 - val_loss: 0.5254 - val_acc: 0.7041\n",
      "Epoch 811/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5245 - acc: 0.7500 - val_loss: 0.5253 - val_acc: 0.7041\n",
      "Epoch 812/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5244 - acc: 0.7449 - val_loss: 0.5258 - val_acc: 0.7041\n",
      "Epoch 813/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5245 - acc: 0.7474 - val_loss: 0.5265 - val_acc: 0.7041\n",
      "Epoch 814/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5245 - acc: 0.7474 - val_loss: 0.5266 - val_acc: 0.7041\n",
      "Epoch 815/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5244 - acc: 0.7474 - val_loss: 0.5268 - val_acc: 0.6939\n",
      "Epoch 816/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5243 - acc: 0.7474 - val_loss: 0.5272 - val_acc: 0.6939\n",
      "Epoch 817/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5245 - acc: 0.7449 - val_loss: 0.5279 - val_acc: 0.6939\n",
      "Epoch 818/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5245 - acc: 0.7449 - val_loss: 0.5280 - val_acc: 0.7041\n",
      "Epoch 819/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5246 - acc: 0.7449 - val_loss: 0.5280 - val_acc: 0.7041\n",
      "Epoch 820/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5244 - acc: 0.7449 - val_loss: 0.5277 - val_acc: 0.7041\n",
      "Epoch 821/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5242 - acc: 0.7474 - val_loss: 0.5272 - val_acc: 0.6939\n",
      "Epoch 822/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5240 - acc: 0.7449 - val_loss: 0.5264 - val_acc: 0.6939\n",
      "Epoch 823/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5236 - acc: 0.7449 - val_loss: 0.5260 - val_acc: 0.7041\n",
      "Epoch 824/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5234 - acc: 0.7449 - val_loss: 0.5259 - val_acc: 0.7041\n",
      "Epoch 825/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5233 - acc: 0.7449 - val_loss: 0.5256 - val_acc: 0.7041\n",
      "Epoch 826/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5230 - acc: 0.7449 - val_loss: 0.5249 - val_acc: 0.7041\n",
      "Epoch 827/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5229 - acc: 0.7423 - val_loss: 0.5243 - val_acc: 0.7041\n",
      "Epoch 828/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5227 - acc: 0.7500 - val_loss: 0.5240 - val_acc: 0.7041\n",
      "Epoch 829/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5226 - acc: 0.7526 - val_loss: 0.5238 - val_acc: 0.7041\n",
      "Epoch 830/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5225 - acc: 0.7500 - val_loss: 0.5235 - val_acc: 0.7041\n",
      "Epoch 831/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5223 - acc: 0.7500 - val_loss: 0.5233 - val_acc: 0.7041\n",
      "Epoch 832/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5222 - acc: 0.7500 - val_loss: 0.5231 - val_acc: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5221 - acc: 0.7500 - val_loss: 0.5234 - val_acc: 0.7041\n",
      "Epoch 834/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5221 - acc: 0.7526 - val_loss: 0.5236 - val_acc: 0.7041\n",
      "Epoch 835/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5220 - acc: 0.7500 - val_loss: 0.5236 - val_acc: 0.7041\n",
      "Epoch 836/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5219 - acc: 0.7500 - val_loss: 0.5237 - val_acc: 0.7041\n",
      "Epoch 837/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5218 - acc: 0.7474 - val_loss: 0.5238 - val_acc: 0.7041\n",
      "Epoch 838/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5217 - acc: 0.7474 - val_loss: 0.5240 - val_acc: 0.7041\n",
      "Epoch 839/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5217 - acc: 0.7398 - val_loss: 0.5240 - val_acc: 0.7041\n",
      "Epoch 840/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5215 - acc: 0.7449 - val_loss: 0.5236 - val_acc: 0.7041\n",
      "Epoch 841/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5214 - acc: 0.7474 - val_loss: 0.5235 - val_acc: 0.7041\n",
      "Epoch 842/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5213 - acc: 0.7500 - val_loss: 0.5229 - val_acc: 0.7041\n",
      "Epoch 843/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5211 - acc: 0.7474 - val_loss: 0.5225 - val_acc: 0.7041\n",
      "Epoch 844/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5210 - acc: 0.7474 - val_loss: 0.5222 - val_acc: 0.7041\n",
      "Epoch 845/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5208 - acc: 0.7500 - val_loss: 0.5219 - val_acc: 0.7041\n",
      "Epoch 846/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5207 - acc: 0.7526 - val_loss: 0.5215 - val_acc: 0.7041\n",
      "Epoch 847/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5205 - acc: 0.7577 - val_loss: 0.5209 - val_acc: 0.7041\n",
      "Epoch 848/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5205 - acc: 0.7551 - val_loss: 0.5207 - val_acc: 0.7041\n",
      "Epoch 849/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5204 - acc: 0.7526 - val_loss: 0.5208 - val_acc: 0.7041\n",
      "Epoch 850/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5203 - acc: 0.7551 - val_loss: 0.5212 - val_acc: 0.7041\n",
      "Epoch 851/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5202 - acc: 0.7526 - val_loss: 0.5217 - val_acc: 0.7041\n",
      "Epoch 852/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5202 - acc: 0.7474 - val_loss: 0.5218 - val_acc: 0.7041\n",
      "Epoch 853/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5201 - acc: 0.7500 - val_loss: 0.5213 - val_acc: 0.7041\n",
      "Epoch 854/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5199 - acc: 0.7526 - val_loss: 0.5208 - val_acc: 0.7041\n",
      "Epoch 855/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5199 - acc: 0.7551 - val_loss: 0.5204 - val_acc: 0.7041\n",
      "Epoch 856/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5197 - acc: 0.7551 - val_loss: 0.5202 - val_acc: 0.7041\n",
      "Epoch 857/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5196 - acc: 0.7551 - val_loss: 0.5203 - val_acc: 0.7041\n",
      "Epoch 858/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5195 - acc: 0.7577 - val_loss: 0.5206 - val_acc: 0.7041\n",
      "Epoch 859/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5194 - acc: 0.7551 - val_loss: 0.5210 - val_acc: 0.7041\n",
      "Epoch 860/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5194 - acc: 0.7500 - val_loss: 0.5213 - val_acc: 0.7041\n",
      "Epoch 861/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5194 - acc: 0.7474 - val_loss: 0.5214 - val_acc: 0.7041\n",
      "Epoch 862/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5193 - acc: 0.7474 - val_loss: 0.5212 - val_acc: 0.7041\n",
      "Epoch 863/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5192 - acc: 0.7500 - val_loss: 0.5212 - val_acc: 0.7041\n",
      "Epoch 864/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5190 - acc: 0.7500 - val_loss: 0.5209 - val_acc: 0.7041\n",
      "Epoch 865/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5189 - acc: 0.7474 - val_loss: 0.5204 - val_acc: 0.7041\n",
      "Epoch 866/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5187 - acc: 0.7551 - val_loss: 0.5201 - val_acc: 0.7041\n",
      "Epoch 867/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5186 - acc: 0.7551 - val_loss: 0.5199 - val_acc: 0.7041\n",
      "Epoch 868/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5185 - acc: 0.7551 - val_loss: 0.5197 - val_acc: 0.7041\n",
      "Epoch 869/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5184 - acc: 0.7551 - val_loss: 0.5197 - val_acc: 0.7041\n",
      "Epoch 870/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5184 - acc: 0.7551 - val_loss: 0.5199 - val_acc: 0.7041\n",
      "Epoch 871/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5183 - acc: 0.7577 - val_loss: 0.5198 - val_acc: 0.7041\n",
      "Epoch 872/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5181 - acc: 0.7551 - val_loss: 0.5198 - val_acc: 0.7041\n",
      "Epoch 873/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5181 - acc: 0.7474 - val_loss: 0.5198 - val_acc: 0.7041\n",
      "Epoch 874/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5180 - acc: 0.7474 - val_loss: 0.5197 - val_acc: 0.7041\n",
      "Epoch 875/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5179 - acc: 0.7474 - val_loss: 0.5196 - val_acc: 0.7041\n",
      "Epoch 876/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5178 - acc: 0.7500 - val_loss: 0.5195 - val_acc: 0.7041\n",
      "Epoch 877/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5177 - acc: 0.7500 - val_loss: 0.5195 - val_acc: 0.7041\n",
      "Epoch 878/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5176 - acc: 0.7500 - val_loss: 0.5194 - val_acc: 0.7041\n",
      "Epoch 879/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5175 - acc: 0.7500 - val_loss: 0.5192 - val_acc: 0.7041\n",
      "Epoch 880/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5174 - acc: 0.7577 - val_loss: 0.5189 - val_acc: 0.7041\n",
      "Epoch 881/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5172 - acc: 0.7577 - val_loss: 0.5190 - val_acc: 0.7041\n",
      "Epoch 882/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5172 - acc: 0.7551 - val_loss: 0.5192 - val_acc: 0.7041\n",
      "Epoch 883/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5171 - acc: 0.7474 - val_loss: 0.5196 - val_acc: 0.7041\n",
      "Epoch 884/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5171 - acc: 0.7474 - val_loss: 0.5198 - val_acc: 0.7041\n",
      "Epoch 885/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5172 - acc: 0.7474 - val_loss: 0.5194 - val_acc: 0.7041\n",
      "Epoch 886/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5169 - acc: 0.7474 - val_loss: 0.5189 - val_acc: 0.7041\n",
      "Epoch 887/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5168 - acc: 0.7526 - val_loss: 0.5187 - val_acc: 0.7041\n",
      "Epoch 888/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5167 - acc: 0.7526 - val_loss: 0.5186 - val_acc: 0.7041\n",
      "Epoch 889/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5166 - acc: 0.7526 - val_loss: 0.5185 - val_acc: 0.7041\n",
      "Epoch 890/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5165 - acc: 0.7526 - val_loss: 0.5184 - val_acc: 0.7041\n",
      "Epoch 891/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5164 - acc: 0.7526 - val_loss: 0.5183 - val_acc: 0.7041\n",
      "Epoch 892/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5163 - acc: 0.7551 - val_loss: 0.5178 - val_acc: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5162 - acc: 0.7526 - val_loss: 0.5173 - val_acc: 0.7041\n",
      "Epoch 894/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5160 - acc: 0.7526 - val_loss: 0.5169 - val_acc: 0.7041\n",
      "Epoch 895/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5159 - acc: 0.7577 - val_loss: 0.5165 - val_acc: 0.7041\n",
      "Epoch 896/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5157 - acc: 0.7577 - val_loss: 0.5161 - val_acc: 0.7041\n",
      "Epoch 897/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5157 - acc: 0.7577 - val_loss: 0.5157 - val_acc: 0.7041\n",
      "Epoch 898/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5158 - acc: 0.7551 - val_loss: 0.5154 - val_acc: 0.6939\n",
      "Epoch 899/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5156 - acc: 0.7551 - val_loss: 0.5152 - val_acc: 0.6939\n",
      "Epoch 900/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5156 - acc: 0.7551 - val_loss: 0.5150 - val_acc: 0.6939\n",
      "Epoch 901/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5155 - acc: 0.7551 - val_loss: 0.5148 - val_acc: 0.6939\n",
      "Epoch 902/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5155 - acc: 0.7500 - val_loss: 0.5146 - val_acc: 0.7041\n",
      "Epoch 903/1000\n",
      "392/392 [==============================] - 0s 18us/step - loss: 0.5155 - acc: 0.7526 - val_loss: 0.5145 - val_acc: 0.7041\n",
      "Epoch 904/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5155 - acc: 0.7551 - val_loss: 0.5142 - val_acc: 0.6939\n",
      "Epoch 905/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5156 - acc: 0.7500 - val_loss: 0.5140 - val_acc: 0.6939\n",
      "Epoch 906/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5155 - acc: 0.7551 - val_loss: 0.5139 - val_acc: 0.6939\n",
      "Epoch 907/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5154 - acc: 0.7526 - val_loss: 0.5140 - val_acc: 0.7041\n",
      "Epoch 908/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5150 - acc: 0.7526 - val_loss: 0.5146 - val_acc: 0.6939\n",
      "Epoch 909/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5147 - acc: 0.7577 - val_loss: 0.5152 - val_acc: 0.7041\n",
      "Epoch 910/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5147 - acc: 0.7551 - val_loss: 0.5156 - val_acc: 0.7041\n",
      "Epoch 911/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5144 - acc: 0.7577 - val_loss: 0.5159 - val_acc: 0.7041\n",
      "Epoch 912/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5144 - acc: 0.7551 - val_loss: 0.5159 - val_acc: 0.7041\n",
      "Epoch 913/1000\n",
      "392/392 [==============================] - 0s 17us/step - loss: 0.5143 - acc: 0.7551 - val_loss: 0.5158 - val_acc: 0.7041\n",
      "Epoch 914/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5142 - acc: 0.7551 - val_loss: 0.5158 - val_acc: 0.7041\n",
      "Epoch 915/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5141 - acc: 0.7551 - val_loss: 0.5159 - val_acc: 0.7041\n",
      "Epoch 916/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5140 - acc: 0.7551 - val_loss: 0.5155 - val_acc: 0.7041\n",
      "Epoch 917/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5139 - acc: 0.7551 - val_loss: 0.5150 - val_acc: 0.7041\n",
      "Epoch 918/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5138 - acc: 0.7577 - val_loss: 0.5145 - val_acc: 0.7041\n",
      "Epoch 919/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5137 - acc: 0.7577 - val_loss: 0.5140 - val_acc: 0.6939\n",
      "Epoch 920/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5137 - acc: 0.7602 - val_loss: 0.5139 - val_acc: 0.6939\n",
      "Epoch 921/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5136 - acc: 0.7577 - val_loss: 0.5138 - val_acc: 0.6939\n",
      "Epoch 922/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5135 - acc: 0.7577 - val_loss: 0.5137 - val_acc: 0.6939\n",
      "Epoch 923/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5134 - acc: 0.7577 - val_loss: 0.5135 - val_acc: 0.6939\n",
      "Epoch 924/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5133 - acc: 0.7577 - val_loss: 0.5132 - val_acc: 0.6939\n",
      "Epoch 925/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5134 - acc: 0.7551 - val_loss: 0.5129 - val_acc: 0.6939\n",
      "Epoch 926/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5133 - acc: 0.7551 - val_loss: 0.5128 - val_acc: 0.6939\n",
      "Epoch 927/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5132 - acc: 0.7577 - val_loss: 0.5128 - val_acc: 0.6939\n",
      "Epoch 928/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5132 - acc: 0.7577 - val_loss: 0.5124 - val_acc: 0.6939\n",
      "Epoch 929/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5133 - acc: 0.7577 - val_loss: 0.5120 - val_acc: 0.7143\n",
      "Epoch 930/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5134 - acc: 0.7577 - val_loss: 0.5119 - val_acc: 0.7143\n",
      "Epoch 931/1000\n",
      "392/392 [==============================] - 0s 19us/step - loss: 0.5132 - acc: 0.7602 - val_loss: 0.5119 - val_acc: 0.7143\n",
      "Epoch 932/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5132 - acc: 0.7577 - val_loss: 0.5119 - val_acc: 0.7143\n",
      "Epoch 933/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5129 - acc: 0.7577 - val_loss: 0.5119 - val_acc: 0.6939\n",
      "Epoch 934/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5127 - acc: 0.7577 - val_loss: 0.5122 - val_acc: 0.6939\n",
      "Epoch 935/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5124 - acc: 0.7577 - val_loss: 0.5125 - val_acc: 0.6939\n",
      "Epoch 936/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5123 - acc: 0.7628 - val_loss: 0.5127 - val_acc: 0.7041\n",
      "Epoch 937/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5122 - acc: 0.7577 - val_loss: 0.5127 - val_acc: 0.7041\n",
      "Epoch 938/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5120 - acc: 0.7602 - val_loss: 0.5124 - val_acc: 0.7041\n",
      "Epoch 939/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5119 - acc: 0.7602 - val_loss: 0.5123 - val_acc: 0.7041\n",
      "Epoch 940/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5119 - acc: 0.7602 - val_loss: 0.5122 - val_acc: 0.7041\n",
      "Epoch 941/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5118 - acc: 0.7602 - val_loss: 0.5120 - val_acc: 0.7041\n",
      "Epoch 942/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5117 - acc: 0.7577 - val_loss: 0.5117 - val_acc: 0.6939\n",
      "Epoch 943/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5117 - acc: 0.7551 - val_loss: 0.5114 - val_acc: 0.6939\n",
      "Epoch 944/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5117 - acc: 0.7577 - val_loss: 0.5112 - val_acc: 0.6939\n",
      "Epoch 945/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5117 - acc: 0.7577 - val_loss: 0.5111 - val_acc: 0.6939\n",
      "Epoch 946/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5115 - acc: 0.7577 - val_loss: 0.5111 - val_acc: 0.6939\n",
      "Epoch 947/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5114 - acc: 0.7577 - val_loss: 0.5111 - val_acc: 0.6939\n",
      "Epoch 948/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5113 - acc: 0.7602 - val_loss: 0.5112 - val_acc: 0.7041\n",
      "Epoch 949/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5112 - acc: 0.7577 - val_loss: 0.5113 - val_acc: 0.7041\n",
      "Epoch 950/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5111 - acc: 0.7628 - val_loss: 0.5113 - val_acc: 0.7041\n",
      "Epoch 951/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5110 - acc: 0.7602 - val_loss: 0.5113 - val_acc: 0.7041\n",
      "Epoch 952/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5109 - acc: 0.7628 - val_loss: 0.5113 - val_acc: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5108 - acc: 0.7628 - val_loss: 0.5111 - val_acc: 0.7041\n",
      "Epoch 954/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5107 - acc: 0.7628 - val_loss: 0.5108 - val_acc: 0.6939\n",
      "Epoch 955/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5107 - acc: 0.7577 - val_loss: 0.5103 - val_acc: 0.7041\n",
      "Epoch 956/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5109 - acc: 0.7602 - val_loss: 0.5099 - val_acc: 0.7041\n",
      "Epoch 957/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5111 - acc: 0.7628 - val_loss: 0.5097 - val_acc: 0.7143\n",
      "Epoch 958/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5111 - acc: 0.7653 - val_loss: 0.5097 - val_acc: 0.7347\n",
      "Epoch 959/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5110 - acc: 0.7679 - val_loss: 0.5095 - val_acc: 0.7347\n",
      "Epoch 960/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5112 - acc: 0.7653 - val_loss: 0.5094 - val_acc: 0.7347\n",
      "Epoch 961/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5111 - acc: 0.7679 - val_loss: 0.5092 - val_acc: 0.7347\n",
      "Epoch 962/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5113 - acc: 0.7679 - val_loss: 0.5091 - val_acc: 0.7347\n",
      "Epoch 963/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5111 - acc: 0.7679 - val_loss: 0.5092 - val_acc: 0.7347\n",
      "Epoch 964/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5107 - acc: 0.7679 - val_loss: 0.5096 - val_acc: 0.7143\n",
      "Epoch 965/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5104 - acc: 0.7602 - val_loss: 0.5101 - val_acc: 0.6939\n",
      "Epoch 966/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5097 - acc: 0.7628 - val_loss: 0.5105 - val_acc: 0.7041\n",
      "Epoch 967/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5098 - acc: 0.7602 - val_loss: 0.5109 - val_acc: 0.7041\n",
      "Epoch 968/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5096 - acc: 0.7602 - val_loss: 0.5110 - val_acc: 0.7041\n",
      "Epoch 969/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5095 - acc: 0.7602 - val_loss: 0.5109 - val_acc: 0.7041\n",
      "Epoch 970/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5094 - acc: 0.7602 - val_loss: 0.5109 - val_acc: 0.7041\n",
      "Epoch 971/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5093 - acc: 0.7602 - val_loss: 0.5109 - val_acc: 0.7041\n",
      "Epoch 972/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5092 - acc: 0.7602 - val_loss: 0.5108 - val_acc: 0.7041\n",
      "Epoch 973/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5091 - acc: 0.7602 - val_loss: 0.5110 - val_acc: 0.7041\n",
      "Epoch 974/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5091 - acc: 0.7602 - val_loss: 0.5111 - val_acc: 0.7041\n",
      "Epoch 975/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5090 - acc: 0.7602 - val_loss: 0.5108 - val_acc: 0.7041\n",
      "Epoch 976/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5089 - acc: 0.7602 - val_loss: 0.5108 - val_acc: 0.7041\n",
      "Epoch 977/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5088 - acc: 0.7628 - val_loss: 0.5106 - val_acc: 0.7041\n",
      "Epoch 978/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5087 - acc: 0.7602 - val_loss: 0.5103 - val_acc: 0.7041\n",
      "Epoch 979/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5086 - acc: 0.7602 - val_loss: 0.5102 - val_acc: 0.7041\n",
      "Epoch 980/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5086 - acc: 0.7602 - val_loss: 0.5101 - val_acc: 0.7041\n",
      "Epoch 981/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5085 - acc: 0.7602 - val_loss: 0.5101 - val_acc: 0.7041\n",
      "Epoch 982/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5084 - acc: 0.7602 - val_loss: 0.5101 - val_acc: 0.7041\n",
      "Epoch 983/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5084 - acc: 0.7602 - val_loss: 0.5097 - val_acc: 0.7041\n",
      "Epoch 984/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5082 - acc: 0.7602 - val_loss: 0.5093 - val_acc: 0.7041\n",
      "Epoch 985/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5082 - acc: 0.7653 - val_loss: 0.5089 - val_acc: 0.7041\n",
      "Epoch 986/1000\n",
      "392/392 [==============================] - 0s 12us/step - loss: 0.5082 - acc: 0.7679 - val_loss: 0.5087 - val_acc: 0.6939\n",
      "Epoch 987/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5082 - acc: 0.7628 - val_loss: 0.5084 - val_acc: 0.7041\n",
      "Epoch 988/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5083 - acc: 0.7653 - val_loss: 0.5080 - val_acc: 0.7143\n",
      "Epoch 989/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5085 - acc: 0.7653 - val_loss: 0.5079 - val_acc: 0.7143\n",
      "Epoch 990/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5085 - acc: 0.7653 - val_loss: 0.5080 - val_acc: 0.7143\n",
      "Epoch 991/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5082 - acc: 0.7653 - val_loss: 0.5082 - val_acc: 0.7143\n",
      "Epoch 992/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5081 - acc: 0.7653 - val_loss: 0.5082 - val_acc: 0.7041\n",
      "Epoch 993/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5079 - acc: 0.7679 - val_loss: 0.5082 - val_acc: 0.7041\n",
      "Epoch 994/1000\n",
      "392/392 [==============================] - 0s 14us/step - loss: 0.5078 - acc: 0.7653 - val_loss: 0.5082 - val_acc: 0.7041\n",
      "Epoch 995/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5078 - acc: 0.7679 - val_loss: 0.5081 - val_acc: 0.7143\n",
      "Epoch 996/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5079 - acc: 0.7653 - val_loss: 0.5079 - val_acc: 0.7143\n",
      "Epoch 997/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5078 - acc: 0.7653 - val_loss: 0.5081 - val_acc: 0.7041\n",
      "Epoch 998/1000\n",
      "392/392 [==============================] - 0s 15us/step - loss: 0.5075 - acc: 0.7679 - val_loss: 0.5082 - val_acc: 0.6939\n",
      "Epoch 999/1000\n",
      "392/392 [==============================] - 0s 13us/step - loss: 0.5073 - acc: 0.7704 - val_loss: 0.5084 - val_acc: 0.7041\n",
      "Epoch 1000/1000\n",
      "392/392 [==============================] - 0s 16us/step - loss: 0.5072 - acc: 0.7679 - val_loss: 0.5084 - val_acc: 0.7041\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val,y_val),epochs=100,batch_size=128,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 24us/step\n",
      "[0.5084305594162065, 0.7040816326530612]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model on validation data\n",
    "evaluate = model.evaluate(X_val,y_val)\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
